# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    cnrm.cloud.google.com/version: 1.137.0
  creationTimestamp: null
  labels:
    cnrm.cloud.google.com/managed-by-kcc: "true"
    cnrm.cloud.google.com/system: "true"
  name: aiplatformmodels.aiplatform.cnrm.cloud.google.com
spec:
  group: aiplatform.cnrm.cloud.google.com
  names:
    categories:
    - gcp
    kind: AIPlatformModel
    listKind: AIPlatformModelList
    plural: aiplatformmodels
    shortNames:
    - gcpaiplatformmodel
    - gcpaiplatformmodels
    singular: aiplatformmodel
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    - description: When 'True', the most recent reconcile of the resource succeeded
      jsonPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - description: The reason for the value in 'Ready'
      jsonPath: .status.conditions[?(@.type=='Ready')].reason
      name: Status
      type: string
    - description: The last transition time for the value in 'Status'
      jsonPath: .status.conditions[?(@.type=='Ready')].lastTransitionTime
      name: Status Age
      type: date
    name: v1alpha1
    schema:
      openAPIV3Schema:
        description: AIPlatformModel is the Schema for the AIPlatformModel API
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: AIPlatformModelSpec defines the desired state of AIPlatformModel
            properties:
              artifactURI:
                description: Immutable. The path to the directory containing the Model
                  artifact and any of its supporting files. Not required for AutoML
                  Models.
                type: string
              baseModelSource:
                description: Optional. User input field to specify the base model
                  source. Currently it only supports specifying the Model Garden models
                  and Genie models.
                properties:
                  genieSource:
                    description: Information about the base model of Genie models.
                    properties:
                      baseModelURI:
                        description: Required. The public base model URI.
                        type: string
                    type: object
                  modelGardenSource:
                    description: Source information of Model Garden models.
                    properties:
                      publicModelName:
                        description: Required. The model garden source model resource
                          name.
                        type: string
                    type: object
                type: object
              containerSpec:
                description: Input only. The specification of the container that is
                  to be used when deploying this Model. The specification is ingested
                  upon [ModelService.UploadModel][google.cloud.aiplatform.v1.ModelService.UploadModel],
                  and all binaries it contains are copied and stored internally by
                  Vertex AI. Not required for AutoML Models.
                properties:
                  args:
                    description: |-
                      Immutable. Specifies arguments for the command that runs when the container
                       starts. This overrides the container's
                       [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
                       this field as an array of executable and arguments, similar to a Docker
                       `CMD`'s "default parameters" form.

                       If you don't specify this field but do specify the
                       [command][google.cloud.aiplatform.v1.ModelContainerSpec.command] field,
                       then the command from the `command` field runs without any additional
                       arguments. See the [Kubernetes documentation about how the `command` and
                       `args` fields interact with a container's `ENTRYPOINT` and
                       `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).

                       If you don't specify this field and don't specify the `command` field,
                       then the container's
                       [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
                       `CMD` determine what runs based on their default behavior. See the Docker
                       documentation about [how `CMD` and `ENTRYPOINT`
                       interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).

                       In this field, you can reference [environment variables
                       set by Vertex
                       AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
                       and environment variables set in the
                       [env][google.cloud.aiplatform.v1.ModelContainerSpec.env] field. You cannot
                       reference environment variables set in the Docker image. In order for
                       environment variables to be expanded, reference them by using the following
                       syntax: <code>$(<var>VARIABLE_NAME</var>)</code> Note that this differs
                       from Bash variable expansion, which does not use parentheses. If a variable
                       cannot be resolved, the reference in the input string is used unchanged. To
                       avoid variable expansion, you can escape this syntax with `$$`; for
                       example: <code>$$(<var>VARIABLE_NAME</var>)</code> This field corresponds
                       to the `args` field of the Kubernetes Containers [v1 core
                       API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
                    items:
                      type: string
                    type: array
                  command:
                    description: |-
                      Immutable. Specifies the command that runs when the container starts. This
                       overrides the container's
                       [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
                       Specify this field as an array of executable and arguments, similar to a
                       Docker `ENTRYPOINT`'s "exec" form, not its "shell" form.

                       If you do not specify this field, then the container's `ENTRYPOINT` runs,
                       in conjunction with the
                       [args][google.cloud.aiplatform.v1.ModelContainerSpec.args] field or the
                       container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
                       if either exists. If this field is not specified and the container does not
                       have an `ENTRYPOINT`, then refer to the Docker documentation about [how
                       `CMD` and `ENTRYPOINT`
                       interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).

                       If you specify this field, then you can also specify the `args` field to
                       provide additional arguments for this command. However, if you specify this
                       field, then the container's `CMD` is ignored. See the
                       [Kubernetes documentation about how the
                       `command` and `args` fields interact with a container's `ENTRYPOINT` and
                       `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).

                       In this field, you can reference [environment variables set by Vertex
                       AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
                       and environment variables set in the
                       [env][google.cloud.aiplatform.v1.ModelContainerSpec.env] field. You cannot
                       reference environment variables set in the Docker image. In order for
                       environment variables to be expanded, reference them by using the following
                       syntax: <code>$(<var>VARIABLE_NAME</var>)</code> Note that this differs
                       from Bash variable expansion, which does not use parentheses. If a variable
                       cannot be resolved, the reference in the input string is used unchanged. To
                       avoid variable expansion, you can escape this syntax with `$$`; for
                       example: <code>$$(<var>VARIABLE_NAME</var>)</code> This field corresponds
                       to the `command` field of the Kubernetes Containers [v1 core
                       API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
                    items:
                      type: string
                    type: array
                  deploymentTimeout:
                    description: Immutable. Deployment timeout. Limit for deployment
                      timeout is 2 hours.
                    type: string
                  env:
                    description: |-
                      Immutable. List of environment variables to set in the container. After the
                       container starts running, code running in the container can read these
                       environment variables.

                       Additionally, the
                       [command][google.cloud.aiplatform.v1.ModelContainerSpec.command] and
                       [args][google.cloud.aiplatform.v1.ModelContainerSpec.args] fields can
                       reference these variables. Later entries in this list can also reference
                       earlier entries. For example, the following example sets the variable
                       `VAR_2` to have the value `foo bar`:

                       ```json
                       [
                         {
                           "name": "VAR_1",
                           "value": "foo"
                         },
                         {
                           "name": "VAR_2",
                           "value": "$(VAR_1) bar"
                         }
                       ]
                       ```

                       If you switch the order of the variables in the example, then the expansion
                       does not occur.

                       This field corresponds to the `env` field of the Kubernetes Containers
                       [v1 core
                       API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
                    items:
                      properties:
                        name:
                          description: Required. Name of the environment variable.
                            Must be a valid C identifier.
                          type: string
                        value:
                          description: 'Required. Variables that reference a $(VAR_NAME)
                            are expanded using the previous defined environment variables
                            in the container and any service environment variables.
                            If a variable cannot be resolved, the reference in the
                            input string will be unchanged. The $(VAR_NAME) syntax
                            can be escaped with a double $$, ie: $$(VAR_NAME). Escaped
                            references will never be expanded, regardless of whether
                            the variable exists or not.'
                          type: string
                      type: object
                    type: array
                  grpcPorts:
                    description: |-
                      Immutable. List of ports to expose from the container. Vertex AI sends gRPC
                       prediction requests that it receives to the first port on this list. Vertex
                       AI also sends liveness and health checks to this port.

                       If you do not specify this field, gRPC requests to the container will be
                       disabled.

                       Vertex AI does not use ports other than the first one listed. This field
                       corresponds to the `ports` field of the Kubernetes Containers v1 core API.
                    items:
                      properties:
                        containerPort:
                          description: The number of the port to expose on the pod's
                            IP address. Must be a valid port number, between 1 and
                            65535 inclusive.
                          format: int32
                          type: integer
                      type: object
                    type: array
                  healthProbe:
                    description: Immutable. Specification for Kubernetes readiness
                      probe.
                    properties:
                      exec:
                        description: ExecAction probes the health of a container by
                          executing a command.
                        properties:
                          command:
                            description: Command is the command line to execute inside
                              the container, the working directory for the command
                              is root ('/') in the container's filesystem. The command
                              is simply exec'd, it is not run inside a shell, so traditional
                              shell instructions ('|', etc) won't work. To use a shell,
                              you need to explicitly call out to that shell. Exit
                              status of 0 is treated as live/healthy and non-zero
                              is unhealthy.
                            items:
                              type: string
                            type: array
                        type: object
                      periodSeconds:
                        description: |-
                          How often (in seconds) to perform the probe. Default to 10 seconds.
                           Minimum value is 1. Must be less than timeout_seconds.

                           Maps to Kubernetes probe argument 'periodSeconds'.
                        format: int32
                        type: integer
                      timeoutSeconds:
                        description: |-
                          Number of seconds after which the probe times out. Defaults to 1 second.
                           Minimum value is 1. Must be greater or equal to period_seconds.

                           Maps to Kubernetes probe argument 'timeoutSeconds'.
                        format: int32
                        type: integer
                    type: object
                  healthRoute:
                    description: |-
                      Immutable. HTTP path on the container to send health checks to. Vertex AI
                       intermittently sends GET requests to this path on the container's IP
                       address and port to check that the container is healthy. Read more about
                       [health
                       checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).

                       For example, if you set this field to `/bar`, then Vertex AI
                       intermittently sends a GET request to the `/bar` path on the port of your
                       container specified by the first value of this `ModelContainerSpec`'s
                       [ports][google.cloud.aiplatform.v1.ModelContainerSpec.ports] field.

                       If you don't specify this field, it defaults to the following value when
                       you [deploy this Model to an
                       Endpoint][google.cloud.aiplatform.v1.EndpointService.DeployModel]:
                       <code>/v1/endpoints/<var>ENDPOINT</var>/deployedModels/<var>DEPLOYED_MODEL</var>:predict</code>
                       The placeholders in this value are replaced as follows:

                       * <var>ENDPOINT</var>: The last segment (following `endpoints/`)of the
                         Endpoint.name][] field of the Endpoint where this Model has been
                         deployed. (Vertex AI makes this value available to your container code
                         as the [`AIP_ENDPOINT_ID` environment
                         variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)

                       * <var>DEPLOYED_MODEL</var>:
                       [DeployedModel.id][google.cloud.aiplatform.v1.DeployedModel.id] of the
                       `DeployedModel`.
                         (Vertex AI makes this value available to your container code as the
                         [`AIP_DEPLOYED_MODEL_ID` environment
                         variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
                    type: string
                  imageURI:
                    description: |-
                      Required. Immutable. URI of the Docker image to be used as the custom
                       container for serving predictions. This URI must identify an image in
                       Artifact Registry or Container Registry. Learn more about the [container
                       publishing
                       requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
                       including permissions requirements for the Vertex AI Service Agent.

                       The container image is ingested upon
                       [ModelService.UploadModel][google.cloud.aiplatform.v1.ModelService.UploadModel],
                       stored internally, and this original path is afterwards not used.

                       To learn about the requirements for the Docker image itself, see
                       [Custom container
                       requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).

                       You can use the URI to one of Vertex AI's [pre-built container images for
                       prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
                       in this field.
                    type: string
                  ports:
                    description: |-
                      Immutable. List of ports to expose from the container. Vertex AI sends any
                       prediction requests that it receives to the first port on this list. Vertex
                       AI also sends
                       [liveness and health
                       checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
                       to this port.

                       If you do not specify this field, it defaults to following value:

                       ```json
                       [
                         {
                           "containerPort": 8080
                         }
                       ]
                       ```

                       Vertex AI does not use ports other than the first one listed. This field
                       corresponds to the `ports` field of the Kubernetes Containers
                       [v1 core
                       API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).
                    items:
                      properties:
                        containerPort:
                          description: The number of the port to expose on the pod's
                            IP address. Must be a valid port number, between 1 and
                            65535 inclusive.
                          format: int32
                          type: integer
                      type: object
                    type: array
                  predictRoute:
                    description: |-
                      Immutable. HTTP path on the container to send prediction requests to.
                       Vertex AI forwards requests sent using
                       [projects.locations.endpoints.predict][google.cloud.aiplatform.v1.PredictionService.Predict]
                       to this path on the container's IP address and port. Vertex AI then returns
                       the container's response in the API response.

                       For example, if you set this field to `/foo`, then when Vertex AI
                       receives a prediction request, it forwards the request body in a POST
                       request to the `/foo` path on the port of your container specified by the
                       first value of this `ModelContainerSpec`'s
                       [ports][google.cloud.aiplatform.v1.ModelContainerSpec.ports] field.

                       If you don't specify this field, it defaults to the following value when
                       you [deploy this Model to an
                       Endpoint][google.cloud.aiplatform.v1.EndpointService.DeployModel]:
                       <code>/v1/endpoints/<var>ENDPOINT</var>/deployedModels/<var>DEPLOYED_MODEL</var>:predict</code>
                       The placeholders in this value are replaced as follows:

                       * <var>ENDPOINT</var>: The last segment (following `endpoints/`)of the
                         Endpoint.name][] field of the Endpoint where this Model has been
                         deployed. (Vertex AI makes this value available to your container code
                         as the [`AIP_ENDPOINT_ID` environment
                        variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)

                       * <var>DEPLOYED_MODEL</var>:
                       [DeployedModel.id][google.cloud.aiplatform.v1.DeployedModel.id] of the
                       `DeployedModel`.
                         (Vertex AI makes this value available to your container code
                         as the [`AIP_DEPLOYED_MODEL_ID` environment
                         variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)
                    type: string
                  sharedMemorySizeMb:
                    description: Immutable. The amount of the VM memory to reserve
                      as the shared memory for the model in megabytes.
                    format: int64
                    type: integer
                  startupProbe:
                    description: Immutable. Specification for Kubernetes startup probe.
                    properties:
                      exec:
                        description: ExecAction probes the health of a container by
                          executing a command.
                        properties:
                          command:
                            description: Command is the command line to execute inside
                              the container, the working directory for the command
                              is root ('/') in the container's filesystem. The command
                              is simply exec'd, it is not run inside a shell, so traditional
                              shell instructions ('|', etc) won't work. To use a shell,
                              you need to explicitly call out to that shell. Exit
                              status of 0 is treated as live/healthy and non-zero
                              is unhealthy.
                            items:
                              type: string
                            type: array
                        type: object
                      periodSeconds:
                        description: |-
                          How often (in seconds) to perform the probe. Default to 10 seconds.
                           Minimum value is 1. Must be less than timeout_seconds.

                           Maps to Kubernetes probe argument 'periodSeconds'.
                        format: int32
                        type: integer
                      timeoutSeconds:
                        description: |-
                          Number of seconds after which the probe times out. Defaults to 1 second.
                           Minimum value is 1. Must be greater or equal to period_seconds.

                           Maps to Kubernetes probe argument 'timeoutSeconds'.
                        format: int32
                        type: integer
                    type: object
                type: object
              dataStats:
                description: |-
                  Stats of data used for training or evaluating the Model.

                   Only populated when the Model is trained by a TrainingPipeline with
                   [data_input_config][google.cloud.aiplatform.v1.TrainingPipeline.input_data_config].
                properties:
                  testAnnotationsCount:
                    description: Number of Annotations that are used for evaluating
                      this Model. If the Model is evaluated multiple times, this will
                      be the number of test Annotations used by the first evaluation.
                      If the Model is not evaluated, the number is 0.
                    format: int64
                    type: integer
                  testDataItemsCount:
                    description: Number of DataItems that were used for evaluating
                      this Model. If the Model is evaluated multiple times, this will
                      be the number of test DataItems used by the first evaluation.
                      If the Model is not evaluated, the number is 0.
                    format: int64
                    type: integer
                  trainingAnnotationsCount:
                    description: Number of Annotations that are used for training
                      this Model.
                    format: int64
                    type: integer
                  trainingDataItemsCount:
                    description: Number of DataItems that were used for training this
                      Model.
                    format: int64
                    type: integer
                  validationAnnotationsCount:
                    description: Number of Annotations that are used for validating
                      this Model during training.
                    format: int64
                    type: integer
                  validationDataItemsCount:
                    description: Number of DataItems that were used for validating
                      this Model during training.
                    format: int64
                    type: integer
                type: object
              description:
                description: The description of the Model.
                type: string
              displayName:
                description: Required. The display name of the Model. The name can
                  be up to 128 characters long and can consist of any UTF-8 characters.
                type: string
              encryptionSpec:
                description: Customer-managed encryption key spec for a Model. If
                  set, this Model and all sub-resources of this Model will be secured
                  by this key.
                properties:
                  kmsKeyName:
                    description: 'Required. The Cloud KMS resource identifier of the
                      customer managed encryption key used to protect a resource.
                      Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`.
                      The key needs to be in the same region as where the compute
                      resource is created.'
                    type: string
                type: object
              explanationSpec:
                description: |-
                  The default explanation specification for this Model.

                   The Model can be used for
                   [requesting
                   explanation][google.cloud.aiplatform.v1.PredictionService.Explain] after
                   being [deployed][google.cloud.aiplatform.v1.EndpointService.DeployModel] if
                   it is populated. The Model can be used for [batch
                   explanation][google.cloud.aiplatform.v1.BatchPredictionJob.generate_explanation]
                   if it is populated.

                   All fields of the explanation_spec can be overridden by
                   [explanation_spec][google.cloud.aiplatform.v1.DeployedModel.explanation_spec]
                   of
                   [DeployModelRequest.deployed_model][google.cloud.aiplatform.v1.DeployModelRequest.deployed_model],
                   or
                   [explanation_spec][google.cloud.aiplatform.v1.BatchPredictionJob.explanation_spec]
                   of [BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob].

                   If the default explanation specification is not set for this Model, this
                   Model can still be used for
                   [requesting
                   explanation][google.cloud.aiplatform.v1.PredictionService.Explain] by
                   setting
                   [explanation_spec][google.cloud.aiplatform.v1.DeployedModel.explanation_spec]
                   of
                   [DeployModelRequest.deployed_model][google.cloud.aiplatform.v1.DeployModelRequest.deployed_model]
                   and for [batch
                   explanation][google.cloud.aiplatform.v1.BatchPredictionJob.generate_explanation]
                   by setting
                   [explanation_spec][google.cloud.aiplatform.v1.BatchPredictionJob.explanation_spec]
                   of [BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob].
                properties:
                  metadata:
                    description: Optional. Metadata describing the Model's input and
                      output for explanation.
                    properties:
                      featureAttributionsSchemaURI:
                        description: 'Points to a YAML file stored on Google Cloud
                          Storage describing the format of the [feature attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions].
                          The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
                          AutoML tabular Models always have this field populated by
                          Vertex AI. Note: The URI given on output may be different,
                          including the URI scheme, than the one given on input. The
                          output URI will point to a location where the user only
                          has a read access.'
                        type: string
                      inputs:
                        additionalProperties:
                          properties:
                            denseShapeTensorName:
                              description: 'Specifies the shape of the values of the
                                input if the input is a sparse representation. Refer
                                to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.'
                              type: string
                            encodedBaselines:
                              description: |-
                                A list of baselines for the encoded tensor.

                                 The shape of each baseline should match the shape of the encoded tensor.
                                 If a scalar is provided, Vertex AI broadcasts to the same shape as the
                                 encoded tensor.
                              items:
                                properties:
                                  boolValue:
                                    description: Represents a boolean value.
                                    type: boolean
                                  nullValue:
                                    description: Represents a null value.
                                    type: string
                                  numberValue:
                                    description: Represents a double value.
                                    type: number
                                  stringValue:
                                    description: Represents a string value.
                                    type: string
                                  structValue:
                                    additionalProperties:
                                      type: string
                                    description: Represents a structured value.
                                    type: object
                                type: object
                              type: array
                            encodedTensorName:
                              description: |-
                                Encoded tensor is a transformation of the input tensor. Must be provided
                                 if choosing
                                 [Integrated Gradients
                                 attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution]
                                 or [XRAI
                                 attribution][google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution]
                                 and the input tensor is not differentiable.

                                 An encoded tensor is generated if the input tensor is encoded by a lookup
                                 table.
                              type: string
                            encoding:
                              description: Defines how the feature is encoded into
                                the input tensor. Defaults to IDENTITY.
                              type: string
                            featureValueDomain:
                              description: The domain details of the input feature
                                value. Like min/max, original mean or standard deviation
                                if normalized.
                              properties:
                                maxValue:
                                  description: The maximum permissible value for this
                                    feature.
                                  type: number
                                minValue:
                                  description: The minimum permissible value for this
                                    feature.
                                  type: number
                                originalMean:
                                  description: If this input feature has been normalized
                                    to a mean value of 0, the original_mean specifies
                                    the mean value of the domain prior to normalization.
                                  type: number
                                originalStddev:
                                  description: If this input feature has been normalized
                                    to a standard deviation of 1.0, the original_stddev
                                    specifies the standard deviation of the domain
                                    prior to normalization.
                                  type: number
                              type: object
                            groupName:
                              description: Name of the group that the input belongs
                                to. Features with the same group name will be treated
                                as one feature when computing attributions. Features
                                grouped together can have different shapes in value.
                                If provided, there will be one single attribution
                                generated in [Attribution.feature_attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions],
                                keyed by the group name.
                              type: string
                            indexFeatureMapping:
                              description: A list of feature names for each index
                                in the input tensor. Required when the input [InputMetadata.encoding][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.encoding]
                                is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.
                              items:
                                type: string
                              type: array
                            indicesTensorName:
                              description: 'Specifies the index of the values of the
                                input tensor. Required when the input tensor is a
                                sparse representation. Refer to Tensorflow documentation
                                for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.'
                              type: string
                            inputBaselines:
                              description: |-
                                Baseline inputs for this feature.

                                 If no baseline is specified, Vertex AI chooses the baseline for this
                                 feature. If multiple baselines are specified, Vertex AI returns the
                                 average attributions across them in
                                 [Attribution.feature_attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions].

                                 For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape
                                 of each baseline must match the shape of the input tensor. If a scalar is
                                 provided, we broadcast to the same shape as the input tensor.

                                 For custom images, the element of the baselines must be in the same
                                 format as the feature's input in the
                                 [instance][google.cloud.aiplatform.v1.ExplainRequest.instances][]. The
                                 schema of any single instance may be specified via Endpoint's
                                 DeployedModels' [Model's][google.cloud.aiplatform.v1.DeployedModel.model]
                                 [PredictSchemata's][google.cloud.aiplatform.v1.Model.predict_schemata]
                                 [instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri].
                              items:
                                properties:
                                  boolValue:
                                    description: Represents a boolean value.
                                    type: boolean
                                  nullValue:
                                    description: Represents a null value.
                                    type: string
                                  numberValue:
                                    description: Represents a double value.
                                    type: number
                                  stringValue:
                                    description: Represents a string value.
                                    type: string
                                  structValue:
                                    additionalProperties:
                                      type: string
                                    description: Represents a structured value.
                                    type: object
                                type: object
                              type: array
                            inputTensorName:
                              description: Name of the input tensor for this feature.
                                Required and is only applicable to Vertex AI-provided
                                images for Tensorflow.
                              type: string
                            modality:
                              description: 'Modality of the feature. Valid values
                                are: numeric, image. Defaults to numeric.'
                              type: string
                            visualization:
                              description: Visualization configurations for image
                                explanation.
                              properties:
                                clipPercentLowerbound:
                                  description: Excludes attributions below the specified
                                    percentile, from the highlighted areas. Defaults
                                    to 62.
                                  type: number
                                clipPercentUpperbound:
                                  description: Excludes attributions above the specified
                                    percentile from the highlighted areas. Using the
                                    clip_percent_upperbound and clip_percent_lowerbound
                                    together can be useful for filtering out noise
                                    and making it easier to see areas of strong attribution.
                                    Defaults to 99.9.
                                  type: number
                                colorMap:
                                  description: |-
                                    The color scheme used for the highlighted areas.

                                     Defaults to PINK_GREEN for
                                     [Integrated Gradients
                                     attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution],
                                     which shows positive attributions in green and negative in pink.

                                     Defaults to VIRIDIS for
                                     [XRAI
                                     attribution][google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution],
                                     which highlights the most influential regions in yellow and the least
                                     influential in blue.
                                  type: string
                                overlayType:
                                  description: How the original image is displayed
                                    in the visualization. Adjusting the overlay can
                                    help increase visual clarity if the original image
                                    makes it difficult to view the visualization.
                                    Defaults to NONE.
                                  type: string
                                polarity:
                                  description: Whether to only highlight pixels with
                                    positive contributions, negative or both. Defaults
                                    to POSITIVE.
                                  type: string
                                type:
                                  description: Type of the image visualization. Only
                                    applicable to [Integrated Gradients attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution].
                                    OUTLINES shows regions of attribution, while PIXELS
                                    shows per-pixel attribution. Defaults to OUTLINES.
                                  type: string
                              type: object
                          type: object
                        description: |-
                          Required. Map from feature names to feature input metadata. Keys are the
                          name of the features. Values are the specification of the feature.

                          An empty InputMetadata is valid. It describes a text feature which has the
                          name specified as the key in
                          [ExplanationMetadata.inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
                          The baseline of the empty feature is chosen by Vertex AI.

                          For Vertex AI-provided Tensorflow images, the key can be any friendly
                          name of the feature. Once specified,
                          [featureAttributions][google.cloud.aiplatform.v1.Attribution.feature_attributions]
                          are keyed by this key (if not grouped with another feature).

                          For custom images, the key must match with the key in
                          [instance][google.cloud.aiplatform.v1.ExplainRequest.instances].
                        type: object
                      latentSpaceSource:
                        description: Name of the source to generate embeddings for
                          example based explanations.
                        type: string
                      outputs:
                        additionalProperties:
                          properties:
                            displayNameMappingKey:
                              description: |-
                                Specify a field name in the prediction to look for the display name.

                                 Use this if the prediction contains the display names for the outputs.

                                 The display names in the prediction must have the same shape of the
                                 outputs, so that it can be located by
                                 [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
                                 for a specific output.
                              type: string
                            indexDisplayNameMapping:
                              description: |-
                                Static mapping between the index and display name.

                                 Use this if the outputs are a deterministic n-dimensional array, e.g. a
                                 list of scores of all the classes in a pre-defined order for a
                                 multi-classification Model. It's not feasible if the outputs are
                                 non-deterministic, e.g. the Model produces top-k classes or sort the
                                 outputs by their values.

                                 The shape of the value must be an n-dimensional array of strings. The
                                 number of dimensions must match that of the outputs to be explained.
                                 The
                                 [Attribution.output_display_name][google.cloud.aiplatform.v1.Attribution.output_display_name]
                                 is populated by locating in the mapping with
                                 [Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index].
                              properties:
                                boolValue:
                                  description: Represents a boolean value.
                                  type: boolean
                                nullValue:
                                  description: Represents a null value.
                                  type: string
                                numberValue:
                                  description: Represents a double value.
                                  type: number
                                stringValue:
                                  description: Represents a string value.
                                  type: string
                                structValue:
                                  additionalProperties:
                                    type: string
                                  description: Represents a structured value.
                                  type: object
                              type: object
                            outputTensorName:
                              description: Name of the output tensor. Required and
                                is only applicable to Vertex AI provided images for
                                Tensorflow.
                              type: string
                          type: object
                        description: |-
                          Required. Map from output names to output metadata.

                          For Vertex AI-provided Tensorflow images, keys can be any user defined
                          string that consists of any UTF-8 characters.

                          For custom images, keys are the name of the output field in the prediction
                          to be explained.

                          Currently only one key is allowed.
                        type: object
                    type: object
                  parameters:
                    description: Required. Parameters that configure explaining of
                      the Model's predictions.
                    properties:
                      examples:
                        description: Example-based explanations that returns the nearest
                          neighbors from the provided dataset.
                        properties:
                          exampleGCSSource:
                            description: The Cloud Storage input instances.
                            properties:
                              dataFormat:
                                description: The format in which instances are given,
                                  if not specified, assume it's JSONL format. Currently
                                  only JSONL format is supported.
                                type: string
                              gcsSource:
                                description: The Cloud Storage location for the input
                                  instances.
                                properties:
                                  uris:
                                    description: Required. Google Cloud Storage URI(-s)
                                      to the input file(s). May contain wildcards.
                                      For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
                                    items:
                                      type: string
                                    type: array
                                type: object
                            type: object
                          nearestNeighborSearchConfig:
                            description: The full configuration for the generated
                              index, the semantics are the same as [metadata][google.cloud.aiplatform.v1.Index.metadata]
                              and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config).
                            properties:
                              boolValue:
                                description: Represents a boolean value.
                                type: boolean
                              nullValue:
                                description: Represents a null value.
                                type: string
                              numberValue:
                                description: Represents a double value.
                                type: number
                              stringValue:
                                description: Represents a string value.
                                type: string
                              structValue:
                                additionalProperties:
                                  type: string
                                description: Represents a structured value.
                                type: object
                            type: object
                          neighborCount:
                            description: The number of neighbors to return when querying
                              for examples.
                            format: int32
                            type: integer
                          presets:
                            description: Simplified preset configuration, which automatically
                              sets configuration values based on the desired query
                              speed-precision trade-off and modality.
                            properties:
                              modality:
                                description: The modality of the uploaded model, which
                                  automatically configures the distance measurement
                                  and feature normalization for the underlying example
                                  index and queries. If your model does not precisely
                                  fit one of these types, it is okay to choose the
                                  closest type.
                                type: string
                              query:
                                description: Preset option controlling parameters
                                  for speed-precision trade-off when querying for
                                  examples. If omitted, defaults to `PRECISE`.
                                type: string
                            type: object
                        type: object
                      integratedGradientsAttribution:
                        description: 'An attribution method that computes Aumann-Shapley
                          values taking advantage of the model''s fully differentiable
                          structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365'
                        properties:
                          blurBaselineConfig:
                            description: |-
                              Config for IG with blur baseline.

                               When enabled, a linear path from the maximally blurred image to the input
                               image is created. Using a blurred baseline instead of zero (black image) is
                               motivated by the BlurIG approach explained here:
                               https://arxiv.org/abs/2004.03383
                            properties:
                              maxBlurSigma:
                                description: The standard deviation of the blur kernel
                                  for the blurred baseline. The same blurring parameter
                                  is used for both the height and the width dimension.
                                  If not set, the method defaults to the zero (i.e.
                                  black for images) baseline.
                                type: number
                            type: object
                          smoothGradConfig:
                            description: |-
                              Config for SmoothGrad approximation of gradients.

                               When enabled, the gradients are approximated by averaging the gradients
                               from noisy samples in the vicinity of the inputs. Adding
                               noise can help improve the computed gradients. Refer to this paper for more
                               details: https://arxiv.org/pdf/1706.03825.pdf
                            properties:
                              featureNoiseSigma:
                                description: This is similar to [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma],
                                  but provides additional flexibility. A separate
                                  noise sigma can be provided for each feature, which
                                  is useful if their distributions are different.
                                  No noise is added to features that are not set.
                                  If this field is unset, [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma]
                                  will be used for all features.
                                properties:
                                  noiseSigma:
                                    description: Noise sigma per feature. No noise
                                      is added to features that are not set.
                                    items:
                                      properties:
                                        name:
                                          description: The name of the input feature
                                            for which noise sigma is provided. The
                                            features are defined in [explanation metadata
                                            inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
                                          type: string
                                        sigma:
                                          description: This represents the standard
                                            deviation of the Gaussian kernel that
                                            will be used to add noise to the feature
                                            prior to computing gradients. Similar
                                            to [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma]
                                            but represents the noise added to the
                                            current feature. Defaults to 0.1.
                                          type: number
                                      type: object
                                    type: array
                                type: object
                              noiseSigma:
                                description: |-
                                  This is a single float value and will be used to add noise to all the
                                   features. Use this field when all features are normalized to have the
                                   same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where
                                   features are normalized to have 0-mean and 1-variance. Learn more about
                                   [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization).

                                   For best results the recommended value is about 10% - 20% of the standard
                                   deviation of the input feature. Refer to section 3.2 of the SmoothGrad
                                   paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1.

                                   If the distribution is different per feature, set
                                   [feature_noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.feature_noise_sigma]
                                   instead for each feature.
                                type: number
                              noisySampleCount:
                                description: The number of gradient samples to use
                                  for approximation. The higher this number, the more
                                  accurate the gradient is, but the runtime complexity
                                  increases by this factor as well. Valid range of
                                  its value is [1, 50]. Defaults to 3.
                                format: int32
                                type: integer
                            type: object
                          stepCount:
                            description: |-
                              Required. The number of steps for approximating the path integral.
                               A good value to start is 50 and gradually increase until the
                               sum to diff property is within the desired error range.

                               Valid range of its value is [1, 100], inclusively.
                            format: int32
                            type: integer
                        type: object
                      sampledShapleyAttribution:
                        description: 'An attribution method that approximates Shapley
                          values for features that contribute to the label being predicted.
                          A sampling strategy is used to approximate the value rather
                          than considering all subsets of features. Refer to this
                          paper for model details: https://arxiv.org/abs/1306.4265.'
                        properties:
                          pathCount:
                            description: |-
                              Required. The number of feature permutations to consider when approximating
                               the Shapley values.

                               Valid range of its value is [1, 50], inclusively.
                            format: int32
                            type: integer
                        type: object
                      topK:
                        description: If populated, returns attributions for top K
                          indices of outputs (defaults to 1). Only applies to Models
                          that predicts more than one outputs (e,g, multi-class Models).
                          When set to -1, returns explanations for all outputs.
                        format: int32
                        type: integer
                      xraiAttribution:
                        description: |-
                          An attribution method that redistributes Integrated Gradients
                           attribution to segmented regions, taking advantage of the model's fully
                           differentiable structure. Refer to this paper for
                           more details: https://arxiv.org/abs/1906.02825

                           XRAI currently performs better on natural images, like a picture of a
                           house or an animal. If the images are taken in artificial environments,
                           like a lab or manufacturing line, or from diagnostic equipment, like
                           x-rays or quality-control cameras, use Integrated Gradients instead.
                        properties:
                          blurBaselineConfig:
                            description: |-
                              Config for XRAI with blur baseline.

                               When enabled, a linear path from the maximally blurred image to the input
                               image is created. Using a blurred baseline instead of zero (black image) is
                               motivated by the BlurIG approach explained here:
                               https://arxiv.org/abs/2004.03383
                            properties:
                              maxBlurSigma:
                                description: The standard deviation of the blur kernel
                                  for the blurred baseline. The same blurring parameter
                                  is used for both the height and the width dimension.
                                  If not set, the method defaults to the zero (i.e.
                                  black for images) baseline.
                                type: number
                            type: object
                          smoothGradConfig:
                            description: |-
                              Config for SmoothGrad approximation of gradients.

                               When enabled, the gradients are approximated by averaging the gradients
                               from noisy samples in the vicinity of the inputs. Adding
                               noise can help improve the computed gradients. Refer to this paper for more
                               details: https://arxiv.org/pdf/1706.03825.pdf
                            properties:
                              featureNoiseSigma:
                                description: This is similar to [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma],
                                  but provides additional flexibility. A separate
                                  noise sigma can be provided for each feature, which
                                  is useful if their distributions are different.
                                  No noise is added to features that are not set.
                                  If this field is unset, [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma]
                                  will be used for all features.
                                properties:
                                  noiseSigma:
                                    description: Noise sigma per feature. No noise
                                      is added to features that are not set.
                                    items:
                                      properties:
                                        name:
                                          description: The name of the input feature
                                            for which noise sigma is provided. The
                                            features are defined in [explanation metadata
                                            inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs].
                                          type: string
                                        sigma:
                                          description: This represents the standard
                                            deviation of the Gaussian kernel that
                                            will be used to add noise to the feature
                                            prior to computing gradients. Similar
                                            to [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma]
                                            but represents the noise added to the
                                            current feature. Defaults to 0.1.
                                          type: number
                                      type: object
                                    type: array
                                type: object
                              noiseSigma:
                                description: |-
                                  This is a single float value and will be used to add noise to all the
                                   features. Use this field when all features are normalized to have the
                                   same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where
                                   features are normalized to have 0-mean and 1-variance. Learn more about
                                   [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization).

                                   For best results the recommended value is about 10% - 20% of the standard
                                   deviation of the input feature. Refer to section 3.2 of the SmoothGrad
                                   paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1.

                                   If the distribution is different per feature, set
                                   [feature_noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.feature_noise_sigma]
                                   instead for each feature.
                                type: number
                              noisySampleCount:
                                description: The number of gradient samples to use
                                  for approximation. The higher this number, the more
                                  accurate the gradient is, but the runtime complexity
                                  increases by this factor as well. Valid range of
                                  its value is [1, 50]. Defaults to 3.
                                format: int32
                                type: integer
                            type: object
                          stepCount:
                            description: |-
                              Required. The number of steps for approximating the path integral.
                               A good value to start is 50 and gradually increase until the
                               sum to diff property is met within the desired error range.

                               Valid range of its value is [1, 100], inclusively.
                            format: int32
                            type: integer
                        type: object
                    type: object
                type: object
              labels:
                additionalProperties:
                  type: string
                description: |-
                  The labels with user-defined metadata to organize your Models.

                   Label keys and values can be no longer than 64 characters
                   (Unicode codepoints), can only contain lowercase letters, numeric
                   characters, underscores and dashes. International characters are allowed.

                   See https://goo.gl/xmQnxf for more information and examples of labels.
                type: object
              location:
                description: Immutable. The location where the model should reside.
                type: string
              metadata:
                description: Immutable. An additional information about the Model;
                  the schema of the metadata can be found in [metadata_schema][google.cloud.aiplatform.v1.Model.metadata_schema_uri].
                  Unset if the Model does not have any additional information.
                properties:
                  boolValue:
                    description: Represents a boolean value.
                    type: boolean
                  nullValue:
                    description: Represents a null value.
                    type: string
                  numberValue:
                    description: Represents a double value.
                    type: number
                  stringValue:
                    description: Represents a string value.
                    type: string
                  structValue:
                    additionalProperties:
                      type: string
                    description: Represents a structured value.
                    type: object
                type: object
              metadataSchemaURI:
                description: 'Immutable. Points to a YAML file stored on Google Cloud
                  Storage describing additional information about the Model, that
                  is specific to it. Unset if the Model does not have any additional
                  information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
                  AutoML Models always have this field populated by Vertex AI, if
                  no additional metadata is needed, this field is set to an empty
                  string. Note: The URI given on output will be immutable and probably
                  different, including the URI scheme, than the one given on input.
                  The output URI will point to a location where the user only has
                  a read access.'
                type: string
              pipelineJob:
                description: Optional. This field is populated if the model is produced
                  by a pipeline job.
                type: string
              predictSchemata:
                description: The schemata that describe formats of the Model's predictions
                  and explanations as given and returned via [PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict]
                  and [PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain].
                properties:
                  instanceSchemaURI:
                    description: 'Immutable. Points to a YAML file stored on Google
                      Cloud Storage describing the format of a single instance, which
                      are used in [PredictRequest.instances][google.cloud.aiplatform.v1.PredictRequest.instances],
                      [ExplainRequest.instances][google.cloud.aiplatform.v1.ExplainRequest.instances]
                      and [BatchPredictionJob.input_config][google.cloud.aiplatform.v1.BatchPredictionJob.input_config].
                      The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
                      AutoML Models always have this field populated by Vertex AI.
                      Note: The URI given on output will be immutable and probably
                      different, including the URI scheme, than the one given on input.
                      The output URI will point to a location where the user only
                      has a read access.'
                    type: string
                  parametersSchemaURI:
                    description: 'Immutable. Points to a YAML file stored on Google
                      Cloud Storage describing the parameters of prediction and explanation
                      via [PredictRequest.parameters][google.cloud.aiplatform.v1.PredictRequest.parameters],
                      [ExplainRequest.parameters][google.cloud.aiplatform.v1.ExplainRequest.parameters]
                      and [BatchPredictionJob.model_parameters][google.cloud.aiplatform.v1.BatchPredictionJob.model_parameters].
                      The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
                      AutoML Models always have this field populated by Vertex AI,
                      if no parameters are supported, then it is set to an empty string.
                      Note: The URI given on output will be immutable and probably
                      different, including the URI scheme, than the one given on input.
                      The output URI will point to a location where the user only
                      has a read access.'
                    type: string
                  predictionSchemaURI:
                    description: 'Immutable. Points to a YAML file stored on Google
                      Cloud Storage describing the format of a single prediction produced
                      by this Model, which are returned via [PredictResponse.predictions][google.cloud.aiplatform.v1.PredictResponse.predictions],
                      [ExplainResponse.explanations][google.cloud.aiplatform.v1.ExplainResponse.explanations],
                      and [BatchPredictionJob.output_config][google.cloud.aiplatform.v1.BatchPredictionJob.output_config].
                      The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
                      AutoML Models always have this field populated by Vertex AI.
                      Note: The URI given on output will be immutable and probably
                      different, including the URI scheme, than the one given on input.
                      The output URI will point to a location where the user only
                      has a read access.'
                    type: string
                type: object
              projectRef:
                description: The project that this resource belongs to.
                oneOf:
                - not:
                    required:
                    - external
                  required:
                  - name
                - not:
                    anyOf:
                    - required:
                      - name
                    - required:
                      - namespace
                  required:
                  - external
                properties:
                  external:
                    description: The `projectID` field of a project, when not managed
                      by Config Connector.
                    type: string
                  kind:
                    description: The kind of the Project resource; optional but must
                      be `Project` if provided.
                    type: string
                  name:
                    description: The `name` field of a `Project` resource.
                    type: string
                  namespace:
                    description: The `namespace` field of a `Project` resource.
                    type: string
                type: object
              resourceID:
                description: The AIPlatformModel name. If not given, the metadata.name
                  will be used.
                type: string
              versionAliases:
                description: User provided version aliases so that a model version
                  can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}`
                  instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`.
                  The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9] to distinguish from
                  version_id. A default version alias will be created for the first
                  version of the model, and there must be exactly one default version
                  alias for a model.
                items:
                  type: string
                type: array
              versionDescription:
                description: The description of this version.
                type: string
            required:
            - location
            - projectRef
            type: object
          status:
            description: AIPlatformModelStatus defines the config connector machine
              state of AIPlatformModel
            properties:
              conditions:
                description: Conditions represent the latest available observations
                  of the object's current state.
                items:
                  properties:
                    lastTransitionTime:
                      description: Last time the condition transitioned from one status
                        to another.
                      type: string
                    message:
                      description: Human-readable message indicating details about
                        last transition.
                      type: string
                    reason:
                      description: Unique, one-word, CamelCase reason for the condition's
                        last transition.
                      type: string
                    status:
                      description: Status is the status of the condition. Can be True,
                        False, Unknown.
                      type: string
                    type:
                      description: Type is the type of the condition.
                      type: string
                  type: object
                type: array
              externalRef:
                description: A unique specifier for the AIPlatformModel resource in
                  GCP.
                type: string
              observedGeneration:
                description: ObservedGeneration is the generation of the resource
                  that was most recently observed by the Config Connector controller.
                  If this is equal to metadata.generation, then that means that the
                  current reported status reflects the most recent desired state of
                  the resource.
                format: int64
                type: integer
              observedState:
                description: ObservedState is the state of the resource as most recently
                  observed in GCP.
                properties:
                  createTime:
                    description: Output only. Timestamp when this Model was uploaded
                      into Vertex AI.
                    type: string
                  deployedModels:
                    description: Output only. The pointers to DeployedModels created
                      from this Model. Note that Model could have been deployed to
                      Endpoints in different Locations.
                    items:
                      properties:
                        deployedModelID:
                          description: Immutable. An ID of a DeployedModel in the
                            above Endpoint.
                          type: string
                        endpoint:
                          description: Immutable. A resource name of an Endpoint.
                          type: string
                      type: object
                    type: array
                  metadataArtifact:
                    description: Output only. The resource name of the Artifact that
                      was created in MetadataStore when creating the Model. The Artifact
                      resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.
                    type: string
                  modelSourceInfo:
                    description: Output only. Source of a model. It can either be
                      automl training pipeline, custom training pipeline, BigQuery
                      ML, or saved and tuned from Genie or Model Garden.
                    properties:
                      copy:
                        description: If this Model is copy of another Model. If true
                          then [source_type][google.cloud.aiplatform.v1.ModelSourceInfo.source_type]
                          pertains to the original.
                        type: boolean
                      sourceType:
                        description: Type of the model source.
                        type: string
                    type: object
                  originalModelInfo:
                    description: Output only. If this Model is a copy of another Model,
                      this contains info about the original.
                    type: object
                  satisfiesPzi:
                    description: Output only. Reserved for future use.
                    type: boolean
                  satisfiesPzs:
                    description: Output only. Reserved for future use.
                    type: boolean
                  supportedDeploymentResourcesTypes:
                    description: Output only. When this Model is deployed, its prediction
                      resources are described by the `prediction_resources` field
                      of the [Endpoint.deployed_models][google.cloud.aiplatform.v1.Endpoint.deployed_models]
                      object. Because not all Models support all resource configuration
                      types, the configuration types this Model supports are listed
                      here. If no configuration types are listed, the Model cannot
                      be deployed to an [Endpoint][google.cloud.aiplatform.v1.Endpoint]
                      and does not support online predictions ([PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict]
                      or [PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain]).
                      Such a Model can serve predictions by using a [BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob],
                      if it has at least one entry each in [supported_input_storage_formats][google.cloud.aiplatform.v1.Model.supported_input_storage_formats]
                      and [supported_output_storage_formats][google.cloud.aiplatform.v1.Model.supported_output_storage_formats].
                    items:
                      type: string
                    type: array
                  supportedExportFormats:
                    description: Output only. The formats in which this Model may
                      be exported. If empty, this Model is not available for export.
                    items:
                      type: object
                    type: array
                  supportedInputStorageFormats:
                    description: |-
                      Output only. The formats this Model supports in
                       [BatchPredictionJob.input_config][google.cloud.aiplatform.v1.BatchPredictionJob.input_config].
                       If
                       [PredictSchemata.instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri]
                       exists, the instances should be given as per that schema.

                       The possible formats are:

                       * `jsonl`
                       The JSON Lines format, where each instance is a single line. Uses
                       [GcsSource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.gcs_source].

                       * `csv`
                       The CSV format, where each instance is a single comma-separated line.
                       The first line in the file is the header, containing comma-separated field
                       names. Uses
                       [GcsSource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.gcs_source].

                       * `tf-record`
                       The TFRecord format, where each instance is a single record in tfrecord
                       syntax. Uses
                       [GcsSource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.gcs_source].

                       * `tf-record-gzip`
                       Similar to `tf-record`, but the file is gzipped. Uses
                       [GcsSource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.gcs_source].

                       * `bigquery`
                       Each instance is a single row in BigQuery. Uses
                       [BigQuerySource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.bigquery_source].

                       * `file-list`
                       Each line of the file is the location of an instance to process, uses
                       `gcs_source` field of the
                       [InputConfig][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig]
                       object.

                       If this Model doesn't support any of these formats it means it cannot be
                       used with a
                       [BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob].
                       However, if it has
                       [supported_deployment_resources_types][google.cloud.aiplatform.v1.Model.supported_deployment_resources_types],
                       it could serve online predictions by using
                       [PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict]
                       or
                       [PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain].
                    items:
                      type: string
                    type: array
                  supportedOutputStorageFormats:
                    description: |-
                      Output only. The formats this Model supports in
                       [BatchPredictionJob.output_config][google.cloud.aiplatform.v1.BatchPredictionJob.output_config].
                       If both
                       [PredictSchemata.instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri]
                       and
                       [PredictSchemata.prediction_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.prediction_schema_uri]
                       exist, the predictions are returned together with their instances. In other
                       words, the prediction has the original instance data first, followed by the
                       actual prediction content (as per the schema).

                       The possible formats are:

                       * `jsonl`
                       The JSON Lines format, where each prediction is a single line. Uses
                       [GcsDestination][google.cloud.aiplatform.v1.BatchPredictionJob.OutputConfig.gcs_destination].

                       * `csv`
                       The CSV format, where each prediction is a single comma-separated line.
                       The first line in the file is the header, containing comma-separated field
                       names. Uses
                       [GcsDestination][google.cloud.aiplatform.v1.BatchPredictionJob.OutputConfig.gcs_destination].

                       * `bigquery`
                       Each prediction is a single row in a BigQuery table, uses
                       [BigQueryDestination][google.cloud.aiplatform.v1.BatchPredictionJob.OutputConfig.bigquery_destination]
                       .

                       If this Model doesn't support any of these formats it means it cannot be
                       used with a
                       [BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob].
                       However, if it has
                       [supported_deployment_resources_types][google.cloud.aiplatform.v1.Model.supported_deployment_resources_types],
                       it could serve online predictions by using
                       [PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict]
                       or
                       [PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain].
                    items:
                      type: string
                    type: array
                  trainingPipeline:
                    description: Output only. The resource name of the TrainingPipeline
                      that uploaded this Model, if any.
                    type: string
                  updateTime:
                    description: Output only. Timestamp when this Model was most recently
                      updated.
                    type: string
                  versionCreateTime:
                    description: Output only. Timestamp when this version was created.
                    type: string
                  versionID:
                    description: Output only. Immutable. The version ID of the model.
                      A new version is committed when a new model version is uploaded
                      or trained under an existing model id. It is an auto-incrementing
                      decimal number in string representation.
                    type: string
                  versionUpdateTime:
                    description: Output only. Timestamp when this version was most
                      recently updated.
                    type: string
                type: object
            type: object
        required:
        - spec
        type: object
    served: true
    storage: true
    subresources:
      status: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: null
  storedVersions: null
