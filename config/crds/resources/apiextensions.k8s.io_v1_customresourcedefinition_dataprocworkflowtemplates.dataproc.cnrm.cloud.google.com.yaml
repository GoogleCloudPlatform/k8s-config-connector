apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    cnrm.cloud.google.com/version: 0.0.0-dev
  creationTimestamp: null
  labels:
    cnrm.cloud.google.com/managed-by-kcc: "true"
    cnrm.cloud.google.com/system: "true"
  name: dataprocworkflowtemplates.dataproc.cnrm.cloud.google.com
spec:
  group: dataproc.cnrm.cloud.google.com
  names:
    categories:
    - gcp
    kind: DataprocWorkflowTemplate
    listKind: DataprocWorkflowTemplateList
    plural: dataprocworkflowtemplates
    shortNames:
    - gcpdataprocworkflowtemplate
    - gcpdataprocworkflowtemplates
    singular: dataprocworkflowtemplate
  preserveUnknownFields: false
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    - description: When 'True', the most recent reconcile of the resource succeeded
      jsonPath: .status.conditions[?(@.type=='Ready')].status
      name: Ready
      type: string
    - description: The reason for the value in 'Ready'
      jsonPath: .status.conditions[?(@.type=='Ready')].reason
      name: Status
      type: string
    - description: The last transition time for the value in 'Status'
      jsonPath: .status.conditions[?(@.type=='Ready')].lastTransitionTime
      name: Status Age
      type: date
    name: v1beta1
    schema:
      openAPIV3Schema:
        description: DataprocWorkflowTemplate is the Schema for the DataprocWorkflowTemplate
          API
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: DataprocWorkflowTemplateSpec defines the desired state of
              DataprocWorkflowTemplate
            properties:
              dagTimeout:
                description: Optional. Timeout duration for the DAG of jobs, expressed
                  in seconds (see [JSON representation of duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).
                  The timeout duration must be from 10 minutes ("600s") to 24 hours
                  ("86400s"). The timer begins when the first job is submitted. If
                  the workflow is running at the end of the timeout period, any remaining
                  jobs are cancelled, the workflow is ended, and if the workflow was
                  running on a [managed cluster](/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
                  the cluster is deleted.
                type: string
              encryptionConfig:
                description: Optional. Encryption settings for encrypting workflow
                  template job arguments.
                properties:
                  kmsKeyRef:
                    description: |-
                      Optional. The Cloud KMS key name to use for encrypting
                       workflow template job arguments.

                       When this this key is provided, the following workflow template
                       [job arguments]
                       (https://cloud.google.com/dataproc/docs/concepts/workflows/use-workflows#adding_jobs_to_a_template),
                       if present, are
                       [CMEK
                       encrypted](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption#use_cmek_with_workflow_template_data):

                       * [FlinkJob
                       args](https://cloud.google.com/dataproc/docs/reference/rest/v1/FlinkJob)
                       * [HadoopJob
                       args](https://cloud.google.com/dataproc/docs/reference/rest/v1/HadoopJob)
                       * [SparkJob
                       args](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkJob)
                       * [SparkRJob
                       args](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkRJob)
                       * [PySparkJob
                       args](https://cloud.google.com/dataproc/docs/reference/rest/v1/PySparkJob)
                       * [SparkSqlJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkSqlJob)
                         scriptVariables and queryList.queries
                       * [HiveJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/HiveJob)
                         scriptVariables and queryList.queries
                       * [PigJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/PigJob)
                         scriptVariables and queryList.queries
                       * [PrestoJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/PrestoJob)
                         scriptVariables and queryList.queries
                    oneOf:
                    - not:
                        required:
                        - external
                      required:
                      - name
                    - not:
                        anyOf:
                        - required:
                          - name
                        - required:
                          - namespace
                      required:
                      - external
                    properties:
                      external:
                        description: A reference to an externally managed KMSCryptoKey.
                          Should be in the format `projects/[kms_project_id]/locations/[region]/keyRings/[key_ring_id]/cryptoKeys/[key]`.
                        type: string
                      name:
                        description: The `name` of a `KMSCryptoKey` resource.
                        type: string
                      namespace:
                        description: The `namespace` of a `KMSCryptoKey` resource.
                        type: string
                    type: object
                type: object
              id:
                type: string
              jobs:
                description: Required. The Directed Acyclic Graph of Jobs to submit.
                items:
                  properties:
                    flinkJob:
                      description: Optional. Job is a Flink job.
                      properties:
                        args:
                          description: Optional. The arguments to pass to the driver.
                            Do not include arguments, such as `--conf`, that can be
                            set as job properties, since a collision might occur that
                            causes an incorrect job submission.
                          items:
                            type: string
                          type: array
                        jarFileURIs:
                          description: Optional. HCFS URIs of jar files to add to
                            the CLASSPATHs of the Flink driver and tasks.
                          items:
                            type: string
                          type: array
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        mainClass:
                          description: The name of the driver's main class. The jar
                            file that contains the class must be in the default CLASSPATH
                            or specified in [jarFileURIs][google.cloud.dataproc.v1.FlinkJob.jar_file_uris].
                          type: string
                        mainJarFileURI:
                          description: The HCFS URI of the jar file that contains
                            the main class.
                          type: string
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values,
                            used to configure Flink. Properties that conflict with
                            values set by the Dataproc API might be overwritten. Can
                            include properties set in `/etc/flink/conf/flink-defaults.conf`
                            and classes in user code.
                          type: object
                        savepointURI:
                          description: Optional. HCFS URI of the savepoint, which
                            contains the last saved progress for starting the current
                            job.
                          type: string
                      type: object
                    hadoopJob:
                      description: Optional. Job is a Hadoop job.
                      properties:
                        archiveURIs:
                          description: 'Optional. HCFS URIs of archives to be extracted
                            in the working directory of Hadoop drivers and tasks.
                            Supported file types: .jar, .tar, .tar.gz, .tgz, or .zip.'
                          items:
                            type: string
                          type: array
                        args:
                          description: Optional. The arguments to pass to the driver.
                            Do not include arguments, such as `-libjars` or `-Dfoo=bar`,
                            that can be set as job properties, since a collision might
                            occur that causes an incorrect job submission.
                          items:
                            type: string
                          type: array
                        fileURIs:
                          description: Optional. HCFS (Hadoop Compatible Filesystem)
                            URIs of files to be copied to the working directory of
                            Hadoop drivers and distributed tasks. Useful for naively
                            parallel tasks.
                          items:
                            type: string
                          type: array
                        jarFileURIs:
                          description: Optional. Jar file URIs to add to the CLASSPATHs
                            of the Hadoop driver and tasks.
                          items:
                            type: string
                          type: array
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        mainClass:
                          description: The name of the driver's main class. The jar
                            file containing the class must be in the default CLASSPATH
                            or specified in `jar_file_uris`.
                          type: string
                        mainJarFileURI:
                          description: 'The HCFS URI of the jar file containing the
                            main class. Examples: ''gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar''
                            ''hdfs:/tmp/test-samples/custom-wordcount.jar'' ''file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'''
                          type: string
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values,
                            used to configure Hadoop. Properties that conflict with
                            values set by the Dataproc API might be overwritten. Can
                            include properties set in `/etc/hadoop/conf/*-site` and
                            classes in user code.
                          type: object
                      type: object
                    hiveJob:
                      description: Optional. Job is a Hive job.
                      properties:
                        continueOnFailure:
                          description: Optional. Whether to continue executing queries
                            if a query fails. The default value is `false`. Setting
                            to `true` can be useful when executing independent parallel
                            queries.
                          type: boolean
                        jarFileURIs:
                          description: Optional. HCFS URIs of jar files to add to
                            the CLASSPATH of the Hive server and Hadoop MapReduce
                            (MR) tasks. Can contain Hive SerDes and UDFs.
                          items:
                            type: string
                          type: array
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names and values,
                            used to configure Hive. Properties that conflict with
                            values set by the Dataproc API might be overwritten. Can
                            include properties set in `/etc/hadoop/conf/*-site.xml`,
                            /etc/hive/conf/hive-site.xml, and classes in user code.
                          type: object
                        queryFileURI:
                          description: The HCFS URI of the script that contains Hive
                            queries.
                          type: string
                        queryList:
                          description: A list of queries.
                          properties:
                            queries:
                              description: |-
                                Required. The queries to execute. You do not need to end a query expression
                                 with a semicolon. Multiple queries can be specified in one
                                 string by separating each with a semicolon. Here is an example of a
                                 Dataproc API snippet that uses a QueryList to specify a HiveJob:

                                     "hiveJob": {
                                       "queryList": {
                                         "queries": [
                                           "query1",
                                           "query2",
                                           "query3;query4",
                                         ]
                                       }
                                     }
                              items:
                                type: string
                              type: array
                          type: object
                        scriptVariables:
                          additionalProperties:
                            type: string
                          description: 'Optional. Mapping of query variable names
                            to values (equivalent to the Hive command: `SET name="value";`).'
                          type: object
                      type: object
                    labels:
                      additionalProperties:
                        type: string
                      description: |-
                        Optional. The labels to associate with this job.

                         Label keys must be between 1 and 63 characters long, and must conform to
                         the following regular expression:
                         [\p{Ll}\p{Lo}][\p{Ll}\p{Lo}\p{N}_-]{0,62}

                         Label values must be between 1 and 63 characters long, and must conform to
                         the following regular expression: [\p{Ll}\p{Lo}\p{N}_-]{0,63}

                         No more than 32 labels can be associated with a given job.
                      type: object
                    pigJob:
                      description: Optional. Job is a Pig job.
                      properties:
                        continueOnFailure:
                          description: Optional. Whether to continue executing queries
                            if a query fails. The default value is `false`. Setting
                            to `true` can be useful when executing independent parallel
                            queries.
                          type: boolean
                        jarFileURIs:
                          description: Optional. HCFS URIs of jar files to add to
                            the CLASSPATH of the Pig Client and Hadoop MapReduce (MR)
                            tasks. Can contain Pig UDFs.
                          items:
                            type: string
                          type: array
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values,
                            used to configure Pig. Properties that conflict with values
                            set by the Dataproc API might be overwritten. Can include
                            properties set in `/etc/hadoop/conf/*-site.xml`, /etc/pig/conf/pig.properties,
                            and classes in user code.
                          type: object
                        queryFileURI:
                          description: The HCFS URI of the script that contains the
                            Pig queries.
                          type: string
                        queryList:
                          description: A list of queries.
                          properties:
                            queries:
                              description: |-
                                Required. The queries to execute. You do not need to end a query expression
                                 with a semicolon. Multiple queries can be specified in one
                                 string by separating each with a semicolon. Here is an example of a
                                 Dataproc API snippet that uses a QueryList to specify a HiveJob:

                                     "hiveJob": {
                                       "queryList": {
                                         "queries": [
                                           "query1",
                                           "query2",
                                           "query3;query4",
                                         ]
                                       }
                                     }
                              items:
                                type: string
                              type: array
                          type: object
                        scriptVariables:
                          additionalProperties:
                            type: string
                          description: 'Optional. Mapping of query variable names
                            to values (equivalent to the Pig command: `name=[value]`).'
                          type: object
                      type: object
                    prerequisiteStepIDs:
                      description: Optional. The optional list of prerequisite job
                        step_ids. If not specified, the job will start at the beginning
                        of workflow.
                      items:
                        type: string
                      type: array
                    prestoJob:
                      description: Optional. Job is a Presto job.
                      properties:
                        clientTags:
                          description: Optional. Presto client tags to attach to this
                            query
                          items:
                            type: string
                          type: array
                        continueOnFailure:
                          description: Optional. Whether to continue executing queries
                            if a query fails. The default value is `false`. Setting
                            to `true` can be useful when executing independent parallel
                            queries.
                          type: boolean
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        outputFormat:
                          description: Optional. The format in which query output
                            will be displayed. See the Presto documentation for supported
                            output formats
                          type: string
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values.
                            Used to set Presto [session properties](https://prestodb.io/docs/current/sql/set-session.html)
                            Equivalent to using the --session flag in the Presto CLI
                          type: object
                        queryFileURI:
                          description: The HCFS URI of the script that contains SQL
                            queries.
                          type: string
                        queryList:
                          description: A list of queries.
                          properties:
                            queries:
                              description: |-
                                Required. The queries to execute. You do not need to end a query expression
                                 with a semicolon. Multiple queries can be specified in one
                                 string by separating each with a semicolon. Here is an example of a
                                 Dataproc API snippet that uses a QueryList to specify a HiveJob:

                                     "hiveJob": {
                                       "queryList": {
                                         "queries": [
                                           "query1",
                                           "query2",
                                           "query3;query4",
                                         ]
                                       }
                                     }
                              items:
                                type: string
                              type: array
                          type: object
                      type: object
                    pysparkJob:
                      description: Optional. Job is a PySpark job.
                      properties:
                        archiveURIs:
                          description: 'Optional. HCFS URIs of archives to be extracted
                            into the working directory of each executor. Supported
                            file types: .jar, .tar, .tar.gz, .tgz, and .zip.'
                          items:
                            type: string
                          type: array
                        args:
                          description: Optional. The arguments to pass to the driver.  Do
                            not include arguments, such as `--conf`, that can be set
                            as job properties, since a collision may occur that causes
                            an incorrect job submission.
                          items:
                            type: string
                          type: array
                        fileURIs:
                          description: Optional. HCFS URIs of files to be placed in
                            the working directory of each executor. Useful for naively
                            parallel tasks.
                          items:
                            type: string
                          type: array
                        jarFileURIs:
                          description: Optional. HCFS URIs of jar files to add to
                            the CLASSPATHs of the Python driver and tasks.
                          items:
                            type: string
                          type: array
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        mainPythonFileURI:
                          description: Required. The HCFS URI of the main Python file
                            to use as the driver. Must be a .py file.
                          type: string
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values,
                            used to configure PySpark. Properties that conflict with
                            values set by the Dataproc API might be overwritten. Can
                            include properties set in /etc/spark/conf/spark-defaults.conf
                            and classes in user code.
                          type: object
                        pythonFileURIs:
                          description: 'Optional. HCFS file URIs of Python files to
                            pass to the PySpark framework. Supported file types: .py,
                            .egg, and .zip.'
                          items:
                            type: string
                          type: array
                      type: object
                    scheduling:
                      description: Optional. Job scheduling configuration.
                      properties:
                        maxFailuresPerHour:
                          description: |-
                            Optional. Maximum number of times per hour a driver can be restarted as
                             a result of driver exiting with non-zero code before job is
                             reported failed.

                             A job might be reported as thrashing if the driver exits with a non-zero
                             code four times within a 10-minute window.

                             Maximum value is 10.

                             **Note:** This restartable job option is not supported in Dataproc
                             [workflow templates]
                             (https://cloud.google.com/dataproc/docs/concepts/workflows/using-workflows#adding_jobs_to_a_template).
                          format: int32
                          type: integer
                        maxFailuresTotal:
                          description: |-
                            Optional. Maximum total number of times a driver can be restarted as a
                             result of the driver exiting with a non-zero code. After the maximum number
                             is reached, the job will be reported as failed.

                             Maximum value is 240.

                             **Note:** Currently, this restartable job option is
                             not supported in Dataproc
                             [workflow
                             templates](https://cloud.google.com/dataproc/docs/concepts/workflows/using-workflows#adding_jobs_to_a_template).
                          format: int32
                          type: integer
                      type: object
                    sparkJob:
                      description: Optional. Job is a Spark job.
                      properties:
                        archiveURIs:
                          description: 'Optional. HCFS URIs of archives to be extracted
                            into the working directory of each executor. Supported
                            file types: .jar, .tar, .tar.gz, .tgz, and .zip.'
                          items:
                            type: string
                          type: array
                        args:
                          description: Optional. The arguments to pass to the driver.
                            Do not include arguments, such as `--conf`, that can be
                            set as job properties, since a collision may occur that
                            causes an incorrect job submission.
                          items:
                            type: string
                          type: array
                        fileURIs:
                          description: Optional. HCFS URIs of files to be placed in
                            the working directory of each executor. Useful for naively
                            parallel tasks.
                          items:
                            type: string
                          type: array
                        jarFileURIs:
                          description: Optional. HCFS URIs of jar files to add to
                            the CLASSPATHs of the Spark driver and tasks.
                          items:
                            type: string
                          type: array
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        mainClass:
                          description: The name of the driver's main class. The jar
                            file that contains the class must be in the default CLASSPATH
                            or specified in SparkJob.jar_file_uris.
                          type: string
                        mainJarFileURI:
                          description: The HCFS URI of the jar file that contains
                            the main class.
                          type: string
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values,
                            used to configure Spark. Properties that conflict with
                            values set by the Dataproc API might be overwritten. Can
                            include properties set in /etc/spark/conf/spark-defaults.conf
                            and classes in user code.
                          type: object
                      type: object
                    sparkRJob:
                      description: Optional. Job is a SparkR job.
                      properties:
                        archiveURIs:
                          description: 'Optional. HCFS URIs of archives to be extracted
                            into the working directory of each executor. Supported
                            file types: .jar, .tar, .tar.gz, .tgz, and .zip.'
                          items:
                            type: string
                          type: array
                        args:
                          description: Optional. The arguments to pass to the driver.  Do
                            not include arguments, such as `--conf`, that can be set
                            as job properties, since a collision may occur that causes
                            an incorrect job submission.
                          items:
                            type: string
                          type: array
                        fileURIs:
                          description: Optional. HCFS URIs of files to be placed in
                            the working directory of each executor. Useful for naively
                            parallel tasks.
                          items:
                            type: string
                          type: array
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        mainRFileURI:
                          description: Required. The HCFS URI of the main R file to
                            use as the driver. Must be a .R file.
                          type: string
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values,
                            used to configure SparkR. Properties that conflict with
                            values set by the Dataproc API might be overwritten. Can
                            include properties set in /etc/spark/conf/spark-defaults.conf
                            and classes in user code.
                          type: object
                      type: object
                    sparkSQLJob:
                      description: Optional. Job is a SparkSql job.
                      properties:
                        jarFileURIs:
                          description: Optional. HCFS URIs of jar files to be added
                            to the Spark CLASSPATH.
                          items:
                            type: string
                          type: array
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values,
                            used to configure Spark SQL's SparkConf. Properties that
                            conflict with values set by the Dataproc API might be
                            overwritten.
                          type: object
                        queryFileURI:
                          description: The HCFS URI of the script that contains SQL
                            queries.
                          type: string
                        queryList:
                          description: A list of queries.
                          properties:
                            queries:
                              description: |-
                                Required. The queries to execute. You do not need to end a query expression
                                 with a semicolon. Multiple queries can be specified in one
                                 string by separating each with a semicolon. Here is an example of a
                                 Dataproc API snippet that uses a QueryList to specify a HiveJob:

                                     "hiveJob": {
                                       "queryList": {
                                         "queries": [
                                           "query1",
                                           "query2",
                                           "query3;query4",
                                         ]
                                       }
                                     }
                              items:
                                type: string
                              type: array
                          type: object
                        scriptVariables:
                          additionalProperties:
                            type: string
                          description: 'Optional. Mapping of query variable names
                            to values (equivalent to the Spark SQL command: SET `name="value";`).'
                          type: object
                      type: object
                    stepID:
                      description: |-
                        Required. The step id. The id must be unique among all jobs
                         within the template.

                         The step id is used as prefix for job id, as job
                         `goog-dataproc-workflow-step-id` label, and in
                         [prerequisiteStepIds][google.cloud.dataproc.v1.OrderedJob.prerequisite_step_ids]
                         field from other steps.

                         The id must contain only letters (a-z, A-Z), numbers (0-9),
                         underscores (_), and hyphens (-). Cannot begin or end with underscore
                         or hyphen. Must consist of between 3 and 50 characters.
                      type: string
                    trinoJob:
                      description: Optional. Job is a Trino job.
                      properties:
                        clientTags:
                          description: Optional. Trino client tags to attach to this
                            query
                          items:
                            type: string
                          type: array
                        continueOnFailure:
                          description: Optional. Whether to continue executing queries
                            if a query fails. The default value is `false`. Setting
                            to `true` can be useful when executing independent parallel
                            queries.
                          type: boolean
                        loggingConfig:
                          description: Optional. The runtime log config for job execution.
                          type: object
                        outputFormat:
                          description: Optional. The format in which query output
                            will be displayed. See the Trino documentation for supported
                            output formats
                          type: string
                        properties:
                          additionalProperties:
                            type: string
                          description: Optional. A mapping of property names to values.
                            Used to set Trino [session properties](https://trino.io/docs/current/sql/set-session.html)
                            Equivalent to using the --session flag in the Trino CLI
                          type: object
                        queryFileURI:
                          description: The HCFS URI of the script that contains SQL
                            queries.
                          type: string
                        queryList:
                          description: A list of queries.
                          properties:
                            queries:
                              description: |-
                                Required. The queries to execute. You do not need to end a query expression
                                 with a semicolon. Multiple queries can be specified in one
                                 string by separating each with a semicolon. Here is an example of a
                                 Dataproc API snippet that uses a QueryList to specify a HiveJob:

                                     "hiveJob": {
                                       "queryList": {
                                         "queries": [
                                           "query1",
                                           "query2",
                                           "query3;query4",
                                         ]
                                       }
                                     }
                              items:
                                type: string
                              type: array
                          type: object
                      type: object
                  type: object
                type: array
              labels:
                additionalProperties:
                  type: string
                description: |-
                  Optional. The labels to associate with this template. These labels
                   will be propagated to all jobs and clusters created by the workflow
                   instance.

                   Label **keys** must contain 1 to 63 characters, and must conform to
                   [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt).

                   Label **values** may be empty, but, if present, must contain 1 to 63
                   characters, and must conform to
                   [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt).

                   No more than 32 labels can be associated with a template.
                type: object
              location:
                description: Required.
                type: string
              parameters:
                description: Optional. Template parameters whose values are substituted
                  into the template. Values for parameters must be provided when the
                  template is instantiated.
                items:
                  properties:
                    description:
                      description: Optional. Brief description of the parameter. Must
                        not exceed 1024 characters.
                      type: string
                    fields:
                      description: |-
                        Required. Paths to all fields that the parameter replaces.
                         A field is allowed to appear in at most one parameter's list of field
                         paths.

                         A field path is similar in syntax to a
                         [google.protobuf.FieldMask][google.protobuf.FieldMask]. For example, a
                         field path that references the zone field of a workflow template's cluster
                         selector would be specified as `placement.clusterSelector.zone`.

                         Also, field paths can reference fields using the following syntax:

                         * Values in maps can be referenced by key:
                             * labels['key']
                             * placement.clusterSelector.clusterLabels['key']
                             * placement.managedCluster.labels['key']
                             * placement.clusterSelector.clusterLabels['key']
                             * jobs['step-id'].labels['key']

                         * Jobs in the jobs list can be referenced by step-id:
                             * jobs['step-id'].hadoopJob.mainJarFileURI
                             * jobs['step-id'].hiveJob.queryFileURI
                             * jobs['step-id'].pySparkJob.mainPythonFileURI
                             * jobs['step-id'].hadoopJob.jarFileURIs[0]
                             * jobs['step-id'].hadoopJob.archiveURIs[0]
                             * jobs['step-id'].hadoopJob.fileURIs[0]
                             * jobs['step-id'].pySparkJob.pythonFileURIs[0]

                         * Items in repeated fields can be referenced by a zero-based index:
                             * jobs['step-id'].sparkJob.args[0]

                         * Other examples:
                             * jobs['step-id'].hadoopJob.properties['key']
                             * jobs['step-id'].hadoopJob.args[0]
                             * jobs['step-id'].hiveJob.scriptVariables['key']
                             * jobs['step-id'].hadoopJob.mainJarFileURI
                             * placement.clusterSelector.zone

                         It may not be possible to parameterize maps and repeated fields in their
                         entirety since only individual map values and individual items in repeated
                         fields can be referenced. For example, the following field paths are
                         invalid:

                         - placement.clusterSelector.clusterLabels
                         - jobs['step-id'].sparkJob.args
                      items:
                        type: string
                      type: array
                    name:
                      description: Required. Parameter name. The parameter name is
                        used as the key, and paired with the parameter value, which
                        are passed to the template when the template is instantiated.
                        The name must contain only capital letters (A-Z), numbers
                        (0-9), and underscores (_), and must not start with a number.
                        The maximum length is 40 characters.
                      type: string
                    validation:
                      description: Optional. Validation rules to be applied to this
                        parameter's value.
                      properties:
                        regex:
                          description: Validation based on regular expressions.
                          properties:
                            regexes:
                              description: Required. RE2 regular expressions used
                                to validate the parameter's value. The value must
                                match the regex in its entirety (substring matches
                                are not sufficient).
                              items:
                                type: string
                              type: array
                          type: object
                        values:
                          description: Validation based on a list of allowed values.
                          properties:
                            values:
                              description: Required. List of allowed values for the
                                parameter.
                              items:
                                type: string
                              type: array
                          type: object
                      type: object
                  type: object
                type: array
              placement:
                description: Required. WorkflowTemplate scheduling information.
                properties:
                  clusterSelector:
                    description: |-
                      Optional. A selector that chooses target cluster for jobs based
                       on metadata.

                       The selector is evaluated at the time each job is submitted.
                    properties:
                      clusterLabels:
                        additionalProperties:
                          type: string
                        description: Required. The cluster labels. Cluster must have
                          all labels to match.
                        type: object
                      zone:
                        description: |-
                          Optional. The zone where workflow process executes. This parameter does not
                           affect the selection of the cluster.

                           If unspecified, the zone of the first cluster matching the selector
                           is used.
                        type: string
                    type: object
                  managedCluster:
                    description: A cluster that is managed by the workflow.
                    properties:
                      clusterName:
                        description: |-
                          Required. The cluster name prefix. A unique cluster name will be formed by
                           appending a random suffix.

                           The name must contain only lower-case letters (a-z), numbers (0-9),
                           and hyphens (-). Must begin with a letter. Cannot begin or end with
                           hyphen. Must consist of between 2 and 35 characters.
                        type: string
                      config:
                        description: Required. The cluster configuration.
                        properties:
                          autoscalingConfig:
                            description: Optional. Autoscaling config for the policy
                              associated with the cluster. Cluster does not autoscale
                              if this field is unset.
                            properties:
                              policyURI:
                                description: |-
                                  Optional. The autoscaling policy used by the cluster.

                                   Only resource names including projectid and location (region) are valid.
                                   Examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]`
                                   * `projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]`

                                   Note that the policy must be in the same project and Dataproc region.
                                type: string
                            type: object
                          auxiliaryNodeGroups:
                            description: Optional. The node group settings.
                            items:
                              properties:
                                nodeGroup:
                                  description: Required. Node group configuration.
                                  properties:
                                    labels:
                                      additionalProperties:
                                        type: string
                                      description: |-
                                        Optional. Node group labels.

                                         * Label **keys** must consist of from 1 to 63 characters and conform to
                                           [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt).
                                         * Label **values** can be empty. If specified, they must consist of from
                                           1 to 63 characters and conform to [RFC 1035]
                                           (https://www.ietf.org/rfc/rfc1035.txt).
                                         * The node group must have no more than 32 labels.
                                      type: object
                                    name:
                                      description: The Node group [resource name](https://aip.dev/122).
                                      type: string
                                    nodeGroupConfig:
                                      description: Optional. The node group instance
                                        group configuration.
                                      properties:
                                        accelerators:
                                          description: Optional. The Compute Engine
                                            accelerator configuration for these instances.
                                          items:
                                            properties:
                                              acceleratorCount:
                                                description: The number of the accelerator
                                                  cards of this type exposed to this
                                                  instance.
                                                format: int32
                                                type: integer
                                              acceleratorTypeURI:
                                                description: |-
                                                  Full URL, partial URI, or short name of the accelerator type resource to
                                                   expose to this instance. See
                                                   [Compute Engine
                                                   AcceleratorTypes](https://cloud.google.com/compute/docs/reference/v1/acceleratorTypes).

                                                   Examples:

                                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/acceleratorTypes/nvidia-tesla-t4`
                                                   * `projects/[project_id]/zones/[zone]/acceleratorTypes/nvidia-tesla-t4`
                                                   * `nvidia-tesla-t4`

                                                   **Auto Zone Exception**: If you are using the Dataproc
                                                   [Auto Zone
                                                   Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                                   feature, you must use the short name of the accelerator type
                                                   resource, for example, `nvidia-tesla-t4`.
                                                type: string
                                            type: object
                                          type: array
                                        diskConfig:
                                          description: Optional. Disk option config
                                            settings.
                                          properties:
                                            bootDiskProvisionedIops:
                                              description: 'Optional. Indicates how
                                                many IOPS to provision for the disk.
                                                This sets the number of I/O operations
                                                per second that the disk can handle.
                                                Note: This field is only supported
                                                if boot_disk_type is hyperdisk-balanced.'
                                              format: int64
                                              type: integer
                                            bootDiskProvisionedThroughput:
                                              description: 'Optional. Indicates how
                                                much throughput to provision for the
                                                disk. This sets the number of throughput
                                                mb per second that the disk can handle.
                                                Values must be greater than or equal
                                                to 1. Note: This field is only supported
                                                if boot_disk_type is hyperdisk-balanced.'
                                              format: int64
                                              type: integer
                                            bootDiskSizeGB:
                                              description: Optional. Size in GB of
                                                the boot disk (default is 500GB).
                                              format: int32
                                              type: integer
                                            bootDiskType:
                                              description: 'Optional. Type of the
                                                boot disk (default is "pd-standard").
                                                Valid values: "pd-balanced" (Persistent
                                                Disk Balanced Solid State Drive),
                                                "pd-ssd" (Persistent Disk Solid State
                                                Drive), or "pd-standard" (Persistent
                                                Disk Hard Disk Drive). See [Disk types](https://cloud.google.com/compute/docs/disks#disk-types).'
                                              type: string
                                            localSsdInterface:
                                              description: 'Optional. Interface type
                                                of local SSDs (default is "scsi").
                                                Valid values: "scsi" (Small Computer
                                                System Interface), "nvme" (Non-Volatile
                                                Memory Express). See [local SSD performance](https://cloud.google.com/compute/docs/disks/local-ssd#performance).'
                                              type: string
                                            numLocalSsds:
                                              description: |-
                                                Optional. Number of attached SSDs, from 0 to 8 (default is 0).
                                                 If SSDs are not attached, the boot disk is used to store runtime logs and
                                                 [HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data.
                                                 If one or more SSDs are attached, this runtime bulk
                                                 data is spread across them, and the boot disk contains only basic
                                                 config and installed binaries.

                                                 Note: Local SSD options may vary by machine type and number of vCPUs
                                                 selected.
                                              format: int32
                                              type: integer
                                          type: object
                                        imageURI:
                                          description: |-
                                            Optional. The Compute Engine image resource used for cluster instances.

                                             The URI can represent an image or image family.

                                             Image examples:

                                             * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/images/[image-id]`
                                             * `projects/[project_id]/global/images/[image-id]`
                                             * `image-id`

                                             Image family examples. Dataproc will use the most recent
                                             image from the family:

                                             * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/images/family/[custom-image-family-name]`
                                             * `projects/[project_id]/global/images/family/[custom-image-family-name]`

                                             If the URI is unspecified, it will be inferred from
                                             `SoftwareConfig.image_version` or the system default.
                                          type: string
                                        instanceFlexibilityPolicy:
                                          description: Optional. Instance flexibility
                                            Policy allowing a mixture of VM shapes
                                            and provisioning models.
                                          properties:
                                            instanceSelectionList:
                                              description: Optional. List of instance
                                                selection options that the group will
                                                use when creating new VMs.
                                              items:
                                                properties:
                                                  machineTypes:
                                                    description: Optional. Full machine-type
                                                      names, e.g. "n1-standard-16".
                                                    items:
                                                      type: string
                                                    type: array
                                                  rank:
                                                    description: Optional. Preference
                                                      of this instance selection.
                                                      Lower number means higher preference.
                                                      Dataproc will first try to create
                                                      a VM based on the machine-type
                                                      with priority rank and fallback
                                                      to next rank based on availability.
                                                      Machine types and instance selections
                                                      with the same priority have
                                                      the same preference.
                                                    format: int32
                                                    type: integer
                                                type: object
                                              type: array
                                            provisioningModelMix:
                                              description: Optional. Defines how the
                                                Group selects the provisioning model
                                                to ensure required reliability.
                                              properties:
                                                standardCapacityBase:
                                                  description: Optional. The base
                                                    capacity that will always use
                                                    Standard VMs to avoid risk of
                                                    more preemption than the minimum
                                                    capacity you need. Dataproc will
                                                    create only standard VMs until
                                                    it reaches standard_capacity_base,
                                                    then it will start using standard_capacity_percent_above_base
                                                    to mix Spot with Standard VMs.
                                                    eg. If 15 instances are requested
                                                    and standard_capacity_base is
                                                    5, Dataproc will create 5 standard
                                                    VMs and then start mixing spot
                                                    and standard VMs for remaining
                                                    10 instances.
                                                  format: int32
                                                  type: integer
                                                standardCapacityPercentAboveBase:
                                                  description: Optional. The percentage
                                                    of target capacity that should
                                                    use Standard VM. The remaining
                                                    percentage will use Spot VMs.
                                                    The percentage applies only to
                                                    the capacity above standard_capacity_base.
                                                    eg. If 15 instances are requested
                                                    and standard_capacity_base is
                                                    5 and standard_capacity_percent_above_base
                                                    is 30, Dataproc will create 5
                                                    standard VMs and then start mixing
                                                    spot and standard VMs for remaining
                                                    10 instances. The mix will be
                                                    30% standard and 70% spot.
                                                  format: int32
                                                  type: integer
                                              type: object
                                          type: object
                                        machineTypeURI:
                                          description: |-
                                            Optional. The Compute Engine machine type used for cluster instances.

                                             A full URL, partial URI, or short name are valid. Examples:

                                             * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/machineTypes/n1-standard-2`
                                             * `projects/[project_id]/zones/[zone]/machineTypes/n1-standard-2`
                                             * `n1-standard-2`

                                             **Auto Zone Exception**: If you are using the Dataproc
                                             [Auto Zone
                                             Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                             feature, you must use the short name of the machine type
                                             resource, for example, `n1-standard-2`.
                                          type: string
                                        minCPUPlatform:
                                          description: Optional. Specifies the minimum
                                            cpu platform for the Instance Group. See
                                            [Dataproc -> Minimum CPU Platform](https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                          type: string
                                        minNumInstances:
                                          description: |-
                                            Optional. The minimum number of primary worker instances to create.
                                             If `min_num_instances` is set, cluster creation will succeed if
                                             the number of primary workers created is at least equal to the
                                             `min_num_instances` number.

                                             Example: Cluster creation request with `num_instances` = `5` and
                                             `min_num_instances` = `3`:

                                             *  If 4 VMs are created and 1 instance fails,
                                                the failed VM is deleted. The cluster is
                                                resized to 4 instances and placed in a `RUNNING` state.
                                             *  If 2 instances are created and 3 instances fail,
                                                the cluster in placed in an `ERROR` state. The failed VMs
                                                are not deleted.
                                          format: int32
                                          type: integer
                                        numInstances:
                                          description: Optional. The number of VM
                                            instances in the instance group. For [HA
                                            cluster](/dataproc/docs/concepts/configuring-clusters/high-availability)
                                            [master_config](#FIELDS.master_config)
                                            groups, **must be set to 3**. For standard
                                            cluster [master_config](#FIELDS.master_config)
                                            groups, **must be set to 1**.
                                          format: int32
                                          type: integer
                                        preemptibility:
                                          description: |-
                                            Optional. Specifies the preemptibility of the instance group.

                                             The default value for master and worker groups is
                                             `NON_PREEMPTIBLE`. This default cannot be changed.

                                             The default value for secondary instances is
                                             `PREEMPTIBLE`.
                                          type: string
                                        startupConfig:
                                          description: Optional. Configuration to
                                            handle the startup of instances during
                                            cluster create and update process.
                                          properties:
                                            requiredRegistrationFraction:
                                              description: Optional. The config setting
                                                to enable cluster creation/ updation
                                                to be successful only after required_registration_fraction
                                                of instances are up and running. This
                                                configuration is applicable to only
                                                secondary workers for now. The cluster
                                                will fail if required_registration_fraction
                                                of instances are not available. This
                                                will include instance creation, agent
                                                registration, and service registration
                                                (if enabled).
                                              type: number
                                          type: object
                                      type: object
                                    roles:
                                      description: Required. Node group roles.
                                      items:
                                        type: string
                                      type: array
                                  type: object
                                nodeGroupID:
                                  description: |-
                                    Optional. A node group ID. Generated if not specified.

                                     The ID must contain only letters (a-z, A-Z), numbers (0-9),
                                     underscores (_), and hyphens (-). Cannot begin or end with underscore
                                     or hyphen. Must consist of from 3 to 33 characters.
                                  type: string
                              type: object
                            type: array
                          configBucket:
                            description: Optional. A Cloud Storage bucket used to
                              stage job dependencies, config files, and job driver
                              console output. If you do not specify a staging bucket,
                              Cloud Dataproc will determine a Cloud Storage location
                              (US, ASIA, or EU) for your cluster's staging bucket
                              according to the Compute Engine zone where your cluster
                              is deployed, and then create and manage this project-level,
                              per-location bucket (see [Dataproc staging and temp
                              buckets](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
                              **This field requires a Cloud Storage bucket name, not
                              a `gs://...` URI to a Cloud Storage bucket.**
                            type: string
                          dataprocMetricConfig:
                            description: Optional. The config for Dataproc metrics.
                            properties:
                              metrics:
                                description: Required. Metrics sources to enable.
                                items:
                                  properties:
                                    metricOverrides:
                                      description: |-
                                        Optional. Specify one or more [Custom metrics]
                                         (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics)
                                         to collect for the metric course (for the `SPARK` metric source (any
                                         [Spark metric]
                                         (https://spark.apache.org/docs/latest/monitoring.html#metrics) can be
                                         specified).

                                         Provide metrics in the following format:
                                         <code><var>METRIC_SOURCE</var>:<var>INSTANCE</var>:<var>GROUP</var>:<var>METRIC</var></code>
                                         Use camelcase as appropriate.

                                         Examples:

                                         ```
                                         yarn:ResourceManager:QueueMetrics:AppsCompleted
                                         spark:driver:DAGScheduler:job.allJobs
                                         sparkHistoryServer:JVM:Memory:NonHeapMemoryUsage.committed
                                         hiveserver2:JVM:Memory:NonHeapMemoryUsage.used
                                         ```

                                         Notes:

                                         * Only the specified overridden metrics are collected for the
                                           metric source. For example, if one or more `spark:executive` metrics
                                           are listed as metric overrides, other `SPARK` metrics are not
                                           collected. The collection of the metrics for other enabled custom
                                           metric sources is unaffected. For example, if both `SPARK` and `YARN`
                                           metric sources are enabled, and overrides are provided for Spark
                                           metrics only, all YARN metrics are collected.
                                      items:
                                        type: string
                                      type: array
                                    metricSource:
                                      description: Required. A standard set of metrics
                                        is collected unless `metricOverrides` are
                                        specified for the metric source (see [Custom
                                        metrics] (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics)
                                        for more information).
                                      type: string
                                  type: object
                                type: array
                            type: object
                          encryptionConfig:
                            description: Optional. Encryption settings for the cluster.
                            properties:
                              gcePDKMSKeyName:
                                description: Optional. The Cloud KMS key resource
                                  name to use for persistent disk encryption for all
                                  instances in the cluster. See [Use CMEK with cluster
                                  data] (https://cloud.google.com//dataproc/docs/concepts/configuring-clusters/customer-managed-encryption#use_cmek_with_cluster_data)
                                  for more information.
                                type: string
                              kmsKey:
                                description: |-
                                  Optional. The Cloud KMS key resource name to use for cluster persistent
                                   disk and job argument encryption. See [Use CMEK with cluster data]
                                   (https://cloud.google.com//dataproc/docs/concepts/configuring-clusters/customer-managed-encryption#use_cmek_with_cluster_data)
                                   for more information.

                                   When this key resource name is provided, the following job arguments of
                                   the following job types submitted to the cluster are encrypted using CMEK:

                                   * [FlinkJob
                                   args](https://cloud.google.com/dataproc/docs/reference/rest/v1/FlinkJob)
                                   * [HadoopJob
                                   args](https://cloud.google.com/dataproc/docs/reference/rest/v1/HadoopJob)
                                   * [SparkJob
                                   args](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkJob)
                                   * [SparkRJob
                                   args](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkRJob)
                                   * [PySparkJob
                                   args](https://cloud.google.com/dataproc/docs/reference/rest/v1/PySparkJob)
                                   * [SparkSqlJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkSqlJob)
                                     scriptVariables and queryList.queries
                                   * [HiveJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/HiveJob)
                                     scriptVariables and queryList.queries
                                   * [PigJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/PigJob)
                                     scriptVariables and queryList.queries
                                   * [PrestoJob](https://cloud.google.com/dataproc/docs/reference/rest/v1/PrestoJob)
                                     scriptVariables and queryList.queries
                                type: string
                            type: object
                          endpointConfig:
                            description: Optional. Port/endpoint configuration for
                              this cluster
                            properties:
                              enableHTTPPortAccess:
                                description: Optional. If true, enable http access
                                  to specific ports on the cluster from external sources.
                                  Defaults to false.
                                type: boolean
                            type: object
                          gceClusterConfig:
                            description: Optional. The shared Compute Engine config
                              settings for all instances in a cluster.
                            properties:
                              confidentialInstanceConfig:
                                description: Optional. Confidential Instance Config
                                  for clusters using [Confidential VMs](https://cloud.google.com/compute/confidential-vm/docs).
                                properties:
                                  enableConfidentialCompute:
                                    description: Optional. Defines whether the instance
                                      should have confidential compute enabled.
                                    type: boolean
                                type: object
                              internalIPOnly:
                                description: |-
                                  Optional. This setting applies to subnetwork-enabled networks. It is set to
                                   `true` by default in clusters created with image versions 2.2.x.

                                   When set to `true`:

                                   * All cluster VMs have internal IP addresses.
                                   * [Google Private Access]
                                   (https://cloud.google.com/vpc/docs/private-google-access)
                                   must be enabled to access Dataproc and other Google Cloud APIs.
                                   * Off-cluster dependencies must be configured to be accessible
                                   without external IP addresses.

                                   When set to `false`:

                                   * Cluster VMs are not restricted to internal IP addresses.
                                   * Ephemeral external IP addresses are assigned to each cluster VM.
                                type: boolean
                              metadata:
                                additionalProperties:
                                  type: string
                                description: Optional. The Compute Engine metadata
                                  entries to add to all instances (see [Project and
                                  instance metadata](https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
                                type: object
                              networkURI:
                                description: |-
                                  Optional. The Compute Engine network to be used for machine
                                   communications. Cannot be specified with subnetwork_uri. If neither
                                   `network_uri` nor `subnetwork_uri` is specified, the "default" network of
                                   the project is used, if it exists. Cannot be a "Custom Subnet Network" (see
                                   [Using Subnetworks](https://cloud.google.com/compute/docs/subnetworks) for
                                   more information).

                                   A full URL, partial URI, or short name are valid. Examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/networks/default`
                                   * `projects/[project_id]/global/networks/default`
                                   * `default`
                                type: string
                              nodeGroupAffinity:
                                description: Optional. Node Group Affinity for sole-tenant
                                  clusters.
                                properties:
                                  nodeGroupURI:
                                    description: |-
                                      Required. The URI of a
                                       sole-tenant [node group
                                       resource](https://cloud.google.com/compute/docs/reference/rest/v1/nodeGroups)
                                       that the cluster will be created on.

                                       A full URL, partial URI, or node group name are valid. Examples:

                                       * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/nodeGroups/node-group-1`
                                       * `projects/[project_id]/zones/[zone]/nodeGroups/node-group-1`
                                       * `node-group-1`
                                    type: string
                                type: object
                              privateIPV6GoogleAccess:
                                description: Optional. The type of IPv6 access for
                                  a cluster.
                                type: string
                              reservationAffinity:
                                description: Optional. Reservation Affinity for consuming
                                  Zonal reservation.
                                properties:
                                  consumeReservationType:
                                    description: Optional. Type of reservation to
                                      consume
                                    type: string
                                  key:
                                    description: Optional. Corresponds to the label
                                      key of reservation resource.
                                    type: string
                                  values:
                                    description: Optional. Corresponds to the label
                                      values of reservation resource.
                                    items:
                                      type: string
                                    type: array
                                type: object
                              serviceAccount:
                                description: |-
                                  Optional. The [Dataproc service
                                   account](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#service_accounts_in_dataproc)
                                   (also see [VM Data Plane
                                   identity](https://cloud.google.com/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity))
                                   used by Dataproc cluster VM instances to access Google Cloud Platform
                                   services.

                                   If not specified, the
                                   [Compute Engine default service
                                   account](https://cloud.google.com/compute/docs/access/service-accounts#default_service_account)
                                   is used.
                                type: string
                              serviceAccountScopes:
                                description: |-
                                  Optional. The URIs of service account scopes to be included in
                                   Compute Engine instances. The following base set of scopes is always
                                   included:

                                   * https://www.googleapis.com/auth/cloud.useraccounts.readonly
                                   * https://www.googleapis.com/auth/devstorage.read_write
                                   * https://www.googleapis.com/auth/logging.write

                                   If no scopes are specified, the following defaults are also provided:

                                   * https://www.googleapis.com/auth/bigquery
                                   * https://www.googleapis.com/auth/bigtable.admin.table
                                   * https://www.googleapis.com/auth/bigtable.data
                                   * https://www.googleapis.com/auth/devstorage.full_control
                                items:
                                  type: string
                                type: array
                              shieldedInstanceConfig:
                                description: Optional. Shielded Instance Config for
                                  clusters using [Compute Engine Shielded VMs](https://cloud.google.com/security/shielded-cloud/shielded-vm).
                                properties:
                                  enableIntegrityMonitoring:
                                    description: Optional. Defines whether instances
                                      have integrity monitoring enabled.
                                    type: boolean
                                  enableSecureBoot:
                                    description: Optional. Defines whether instances
                                      have Secure Boot enabled.
                                    type: boolean
                                  enableVTPM:
                                    description: Optional. Defines whether instances
                                      have the vTPM enabled.
                                    type: boolean
                                type: object
                              subnetworkURI:
                                description: |-
                                  Optional. The Compute Engine subnetwork to be used for machine
                                   communications. Cannot be specified with network_uri.

                                   A full URL, partial URI, or short name are valid. Examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/regions/[region]/subnetworks/sub0`
                                   * `projects/[project_id]/regions/[region]/subnetworks/sub0`
                                   * `sub0`
                                type: string
                              tags:
                                description: The Compute Engine network tags to add
                                  to all instances (see [Tagging instances](https://cloud.google.com/vpc/docs/add-remove-network-tags)).
                                items:
                                  type: string
                                type: array
                              zoneURI:
                                description: |-
                                  Optional. The Compute Engine zone where the Dataproc cluster will be
                                   located. If omitted, the service will pick a zone in the cluster's Compute
                                   Engine region. On a get request, zone will always be present.

                                   A full URL, partial URI, or short name are valid. Examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]`
                                   * `projects/[project_id]/zones/[zone]`
                                   * `[zone]`
                                type: string
                            type: object
                          initializationActions:
                            description: |-
                              Optional. Commands to execute on each node after config is
                               completed. By default, executables are run on master and all worker nodes.
                               You can test a node's `role` metadata to run an executable on
                               a master or worker node, as shown below using `curl` (you can also use
                               `wget`):

                                   ROLE=$(curl -H Metadata-Flavor:Google
                                   http://metadata/computeMetadata/v1/instance/attributes/dataproc-role)
                                   if [[ "${ROLE}" == 'Master' ]]; then
                                     ... master specific actions ...
                                   else
                                     ... worker specific actions ...
                                   fi
                            items:
                              properties:
                                executableFile:
                                  description: Required. Cloud Storage URI of executable
                                    file.
                                  type: string
                                executionTimeout:
                                  description: |-
                                    Optional. Amount of time executable has to complete. Default is
                                     10 minutes (see JSON representation of
                                     [Duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).

                                     Cluster creation fails with an explanatory error message (the
                                     name of the executable that caused the error and the exceeded timeout
                                     period) if the executable is not completed at end of the timeout period.
                                  type: string
                              type: object
                            type: array
                          lifecycleConfig:
                            description: Optional. Lifecycle setting for the cluster.
                            properties:
                              autoDeleteTTL:
                                description: Optional. The lifetime duration of cluster.
                                  The cluster will be auto-deleted at the end of this
                                  period. Minimum value is 10 minutes; maximum value
                                  is 14 days (see JSON representation of [Duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                type: string
                              autoDeleteTime:
                                description: Optional. The time when cluster will
                                  be auto-deleted (see JSON representation of [Timestamp](https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                type: string
                              idleDeleteTTL:
                                description: Optional. The duration to keep the cluster
                                  alive while idling (when no jobs are running). Passing
                                  this threshold will cause the cluster to be deleted.
                                  Minimum value is 5 minutes; maximum value is 14
                                  days (see JSON representation of [Duration](https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                type: string
                            type: object
                          masterConfig:
                            description: Optional. The Compute Engine config settings
                              for the cluster's master instance.
                            properties:
                              accelerators:
                                description: Optional. The Compute Engine accelerator
                                  configuration for these instances.
                                items:
                                  properties:
                                    acceleratorCount:
                                      description: The number of the accelerator cards
                                        of this type exposed to this instance.
                                      format: int32
                                      type: integer
                                    acceleratorTypeURI:
                                      description: |-
                                        Full URL, partial URI, or short name of the accelerator type resource to
                                         expose to this instance. See
                                         [Compute Engine
                                         AcceleratorTypes](https://cloud.google.com/compute/docs/reference/v1/acceleratorTypes).

                                         Examples:

                                         * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/acceleratorTypes/nvidia-tesla-t4`
                                         * `projects/[project_id]/zones/[zone]/acceleratorTypes/nvidia-tesla-t4`
                                         * `nvidia-tesla-t4`

                                         **Auto Zone Exception**: If you are using the Dataproc
                                         [Auto Zone
                                         Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                         feature, you must use the short name of the accelerator type
                                         resource, for example, `nvidia-tesla-t4`.
                                      type: string
                                  type: object
                                type: array
                              diskConfig:
                                description: Optional. Disk option config settings.
                                properties:
                                  bootDiskProvisionedIops:
                                    description: 'Optional. Indicates how many IOPS
                                      to provision for the disk. This sets the number
                                      of I/O operations per second that the disk can
                                      handle. Note: This field is only supported if
                                      boot_disk_type is hyperdisk-balanced.'
                                    format: int64
                                    type: integer
                                  bootDiskProvisionedThroughput:
                                    description: 'Optional. Indicates how much throughput
                                      to provision for the disk. This sets the number
                                      of throughput mb per second that the disk can
                                      handle. Values must be greater than or equal
                                      to 1. Note: This field is only supported if
                                      boot_disk_type is hyperdisk-balanced.'
                                    format: int64
                                    type: integer
                                  bootDiskSizeGB:
                                    description: Optional. Size in GB of the boot
                                      disk (default is 500GB).
                                    format: int32
                                    type: integer
                                  bootDiskType:
                                    description: 'Optional. Type of the boot disk
                                      (default is "pd-standard"). Valid values: "pd-balanced"
                                      (Persistent Disk Balanced Solid State Drive),
                                      "pd-ssd" (Persistent Disk Solid State Drive),
                                      or "pd-standard" (Persistent Disk Hard Disk
                                      Drive). See [Disk types](https://cloud.google.com/compute/docs/disks#disk-types).'
                                    type: string
                                  localSsdInterface:
                                    description: 'Optional. Interface type of local
                                      SSDs (default is "scsi"). Valid values: "scsi"
                                      (Small Computer System Interface), "nvme" (Non-Volatile
                                      Memory Express). See [local SSD performance](https://cloud.google.com/compute/docs/disks/local-ssd#performance).'
                                    type: string
                                  numLocalSsds:
                                    description: |-
                                      Optional. Number of attached SSDs, from 0 to 8 (default is 0).
                                       If SSDs are not attached, the boot disk is used to store runtime logs and
                                       [HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data.
                                       If one or more SSDs are attached, this runtime bulk
                                       data is spread across them, and the boot disk contains only basic
                                       config and installed binaries.

                                       Note: Local SSD options may vary by machine type and number of vCPUs
                                       selected.
                                    format: int32
                                    type: integer
                                type: object
                              imageURI:
                                description: |-
                                  Optional. The Compute Engine image resource used for cluster instances.

                                   The URI can represent an image or image family.

                                   Image examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/images/[image-id]`
                                   * `projects/[project_id]/global/images/[image-id]`
                                   * `image-id`

                                   Image family examples. Dataproc will use the most recent
                                   image from the family:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/images/family/[custom-image-family-name]`
                                   * `projects/[project_id]/global/images/family/[custom-image-family-name]`

                                   If the URI is unspecified, it will be inferred from
                                   `SoftwareConfig.image_version` or the system default.
                                type: string
                              instanceFlexibilityPolicy:
                                description: Optional. Instance flexibility Policy
                                  allowing a mixture of VM shapes and provisioning
                                  models.
                                properties:
                                  instanceSelectionList:
                                    description: Optional. List of instance selection
                                      options that the group will use when creating
                                      new VMs.
                                    items:
                                      properties:
                                        machineTypes:
                                          description: Optional. Full machine-type
                                            names, e.g. "n1-standard-16".
                                          items:
                                            type: string
                                          type: array
                                        rank:
                                          description: Optional. Preference of this
                                            instance selection. Lower number means
                                            higher preference. Dataproc will first
                                            try to create a VM based on the machine-type
                                            with priority rank and fallback to next
                                            rank based on availability. Machine types
                                            and instance selections with the same
                                            priority have the same preference.
                                          format: int32
                                          type: integer
                                      type: object
                                    type: array
                                  provisioningModelMix:
                                    description: Optional. Defines how the Group selects
                                      the provisioning model to ensure required reliability.
                                    properties:
                                      standardCapacityBase:
                                        description: Optional. The base capacity that
                                          will always use Standard VMs to avoid risk
                                          of more preemption than the minimum capacity
                                          you need. Dataproc will create only standard
                                          VMs until it reaches standard_capacity_base,
                                          then it will start using standard_capacity_percent_above_base
                                          to mix Spot with Standard VMs. eg. If 15
                                          instances are requested and standard_capacity_base
                                          is 5, Dataproc will create 5 standard VMs
                                          and then start mixing spot and standard
                                          VMs for remaining 10 instances.
                                        format: int32
                                        type: integer
                                      standardCapacityPercentAboveBase:
                                        description: Optional. The percentage of target
                                          capacity that should use Standard VM. The
                                          remaining percentage will use Spot VMs.
                                          The percentage applies only to the capacity
                                          above standard_capacity_base. eg. If 15
                                          instances are requested and standard_capacity_base
                                          is 5 and standard_capacity_percent_above_base
                                          is 30, Dataproc will create 5 standard VMs
                                          and then start mixing spot and standard
                                          VMs for remaining 10 instances. The mix
                                          will be 30% standard and 70% spot.
                                        format: int32
                                        type: integer
                                    type: object
                                type: object
                              machineTypeURI:
                                description: |-
                                  Optional. The Compute Engine machine type used for cluster instances.

                                   A full URL, partial URI, or short name are valid. Examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/machineTypes/n1-standard-2`
                                   * `projects/[project_id]/zones/[zone]/machineTypes/n1-standard-2`
                                   * `n1-standard-2`

                                   **Auto Zone Exception**: If you are using the Dataproc
                                   [Auto Zone
                                   Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                   feature, you must use the short name of the machine type
                                   resource, for example, `n1-standard-2`.
                                type: string
                              minCPUPlatform:
                                description: Optional. Specifies the minimum cpu platform
                                  for the Instance Group. See [Dataproc -> Minimum
                                  CPU Platform](https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                type: string
                              minNumInstances:
                                description: |-
                                  Optional. The minimum number of primary worker instances to create.
                                   If `min_num_instances` is set, cluster creation will succeed if
                                   the number of primary workers created is at least equal to the
                                   `min_num_instances` number.

                                   Example: Cluster creation request with `num_instances` = `5` and
                                   `min_num_instances` = `3`:

                                   *  If 4 VMs are created and 1 instance fails,
                                      the failed VM is deleted. The cluster is
                                      resized to 4 instances and placed in a `RUNNING` state.
                                   *  If 2 instances are created and 3 instances fail,
                                      the cluster in placed in an `ERROR` state. The failed VMs
                                      are not deleted.
                                format: int32
                                type: integer
                              numInstances:
                                description: Optional. The number of VM instances
                                  in the instance group. For [HA cluster](/dataproc/docs/concepts/configuring-clusters/high-availability)
                                  [master_config](#FIELDS.master_config) groups, **must
                                  be set to 3**. For standard cluster [master_config](#FIELDS.master_config)
                                  groups, **must be set to 1**.
                                format: int32
                                type: integer
                              preemptibility:
                                description: |-
                                  Optional. Specifies the preemptibility of the instance group.

                                   The default value for master and worker groups is
                                   `NON_PREEMPTIBLE`. This default cannot be changed.

                                   The default value for secondary instances is
                                   `PREEMPTIBLE`.
                                type: string
                              startupConfig:
                                description: Optional. Configuration to handle the
                                  startup of instances during cluster create and update
                                  process.
                                properties:
                                  requiredRegistrationFraction:
                                    description: Optional. The config setting to enable
                                      cluster creation/ updation to be successful
                                      only after required_registration_fraction of
                                      instances are up and running. This configuration
                                      is applicable to only secondary workers for
                                      now. The cluster will fail if required_registration_fraction
                                      of instances are not available. This will include
                                      instance creation, agent registration, and service
                                      registration (if enabled).
                                    type: number
                                type: object
                            type: object
                          metastoreConfig:
                            description: Optional. Metastore configuration.
                            properties:
                              dataprocMetastoreService:
                                description: |-
                                  Required. Resource name of an existing Dataproc Metastore service.

                                   Example:

                                   * `projects/[project_id]/locations/[dataproc_region]/services/[service-name]`
                                type: string
                            type: object
                          secondaryWorkerConfig:
                            description: Optional. The Compute Engine config settings
                              for a cluster's secondary worker instances
                            properties:
                              accelerators:
                                description: Optional. The Compute Engine accelerator
                                  configuration for these instances.
                                items:
                                  properties:
                                    acceleratorCount:
                                      description: The number of the accelerator cards
                                        of this type exposed to this instance.
                                      format: int32
                                      type: integer
                                    acceleratorTypeURI:
                                      description: |-
                                        Full URL, partial URI, or short name of the accelerator type resource to
                                         expose to this instance. See
                                         [Compute Engine
                                         AcceleratorTypes](https://cloud.google.com/compute/docs/reference/v1/acceleratorTypes).

                                         Examples:

                                         * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/acceleratorTypes/nvidia-tesla-t4`
                                         * `projects/[project_id]/zones/[zone]/acceleratorTypes/nvidia-tesla-t4`
                                         * `nvidia-tesla-t4`

                                         **Auto Zone Exception**: If you are using the Dataproc
                                         [Auto Zone
                                         Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                         feature, you must use the short name of the accelerator type
                                         resource, for example, `nvidia-tesla-t4`.
                                      type: string
                                  type: object
                                type: array
                              diskConfig:
                                description: Optional. Disk option config settings.
                                properties:
                                  bootDiskProvisionedIops:
                                    description: 'Optional. Indicates how many IOPS
                                      to provision for the disk. This sets the number
                                      of I/O operations per second that the disk can
                                      handle. Note: This field is only supported if
                                      boot_disk_type is hyperdisk-balanced.'
                                    format: int64
                                    type: integer
                                  bootDiskProvisionedThroughput:
                                    description: 'Optional. Indicates how much throughput
                                      to provision for the disk. This sets the number
                                      of throughput mb per second that the disk can
                                      handle. Values must be greater than or equal
                                      to 1. Note: This field is only supported if
                                      boot_disk_type is hyperdisk-balanced.'
                                    format: int64
                                    type: integer
                                  bootDiskSizeGB:
                                    description: Optional. Size in GB of the boot
                                      disk (default is 500GB).
                                    format: int32
                                    type: integer
                                  bootDiskType:
                                    description: 'Optional. Type of the boot disk
                                      (default is "pd-standard"). Valid values: "pd-balanced"
                                      (Persistent Disk Balanced Solid State Drive),
                                      "pd-ssd" (Persistent Disk Solid State Drive),
                                      or "pd-standard" (Persistent Disk Hard Disk
                                      Drive). See [Disk types](https://cloud.google.com/compute/docs/disks#disk-types).'
                                    type: string
                                  localSsdInterface:
                                    description: 'Optional. Interface type of local
                                      SSDs (default is "scsi"). Valid values: "scsi"
                                      (Small Computer System Interface), "nvme" (Non-Volatile
                                      Memory Express). See [local SSD performance](https://cloud.google.com/compute/docs/disks/local-ssd#performance).'
                                    type: string
                                  numLocalSsds:
                                    description: |-
                                      Optional. Number of attached SSDs, from 0 to 8 (default is 0).
                                       If SSDs are not attached, the boot disk is used to store runtime logs and
                                       [HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data.
                                       If one or more SSDs are attached, this runtime bulk
                                       data is spread across them, and the boot disk contains only basic
                                       config and installed binaries.

                                       Note: Local SSD options may vary by machine type and number of vCPUs
                                       selected.
                                    format: int32
                                    type: integer
                                type: object
                              imageURI:
                                description: |-
                                  Optional. The Compute Engine image resource used for cluster instances.

                                   The URI can represent an image or image family.

                                   Image examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/images/[image-id]`
                                   * `projects/[project_id]/global/images/[image-id]`
                                   * `image-id`

                                   Image family examples. Dataproc will use the most recent
                                   image from the family:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/images/family/[custom-image-family-name]`
                                   * `projects/[project_id]/global/images/family/[custom-image-family-name]`

                                   If the URI is unspecified, it will be inferred from
                                   `SoftwareConfig.image_version` or the system default.
                                type: string
                              instanceFlexibilityPolicy:
                                description: Optional. Instance flexibility Policy
                                  allowing a mixture of VM shapes and provisioning
                                  models.
                                properties:
                                  instanceSelectionList:
                                    description: Optional. List of instance selection
                                      options that the group will use when creating
                                      new VMs.
                                    items:
                                      properties:
                                        machineTypes:
                                          description: Optional. Full machine-type
                                            names, e.g. "n1-standard-16".
                                          items:
                                            type: string
                                          type: array
                                        rank:
                                          description: Optional. Preference of this
                                            instance selection. Lower number means
                                            higher preference. Dataproc will first
                                            try to create a VM based on the machine-type
                                            with priority rank and fallback to next
                                            rank based on availability. Machine types
                                            and instance selections with the same
                                            priority have the same preference.
                                          format: int32
                                          type: integer
                                      type: object
                                    type: array
                                  provisioningModelMix:
                                    description: Optional. Defines how the Group selects
                                      the provisioning model to ensure required reliability.
                                    properties:
                                      standardCapacityBase:
                                        description: Optional. The base capacity that
                                          will always use Standard VMs to avoid risk
                                          of more preemption than the minimum capacity
                                          you need. Dataproc will create only standard
                                          VMs until it reaches standard_capacity_base,
                                          then it will start using standard_capacity_percent_above_base
                                          to mix Spot with Standard VMs. eg. If 15
                                          instances are requested and standard_capacity_base
                                          is 5, Dataproc will create 5 standard VMs
                                          and then start mixing spot and standard
                                          VMs for remaining 10 instances.
                                        format: int32
                                        type: integer
                                      standardCapacityPercentAboveBase:
                                        description: Optional. The percentage of target
                                          capacity that should use Standard VM. The
                                          remaining percentage will use Spot VMs.
                                          The percentage applies only to the capacity
                                          above standard_capacity_base. eg. If 15
                                          instances are requested and standard_capacity_base
                                          is 5 and standard_capacity_percent_above_base
                                          is 30, Dataproc will create 5 standard VMs
                                          and then start mixing spot and standard
                                          VMs for remaining 10 instances. The mix
                                          will be 30% standard and 70% spot.
                                        format: int32
                                        type: integer
                                    type: object
                                type: object
                              machineTypeURI:
                                description: |-
                                  Optional. The Compute Engine machine type used for cluster instances.

                                   A full URL, partial URI, or short name are valid. Examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/machineTypes/n1-standard-2`
                                   * `projects/[project_id]/zones/[zone]/machineTypes/n1-standard-2`
                                   * `n1-standard-2`

                                   **Auto Zone Exception**: If you are using the Dataproc
                                   [Auto Zone
                                   Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                   feature, you must use the short name of the machine type
                                   resource, for example, `n1-standard-2`.
                                type: string
                              minCPUPlatform:
                                description: Optional. Specifies the minimum cpu platform
                                  for the Instance Group. See [Dataproc -> Minimum
                                  CPU Platform](https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                type: string
                              minNumInstances:
                                description: |-
                                  Optional. The minimum number of primary worker instances to create.
                                   If `min_num_instances` is set, cluster creation will succeed if
                                   the number of primary workers created is at least equal to the
                                   `min_num_instances` number.

                                   Example: Cluster creation request with `num_instances` = `5` and
                                   `min_num_instances` = `3`:

                                   *  If 4 VMs are created and 1 instance fails,
                                      the failed VM is deleted. The cluster is
                                      resized to 4 instances and placed in a `RUNNING` state.
                                   *  If 2 instances are created and 3 instances fail,
                                      the cluster in placed in an `ERROR` state. The failed VMs
                                      are not deleted.
                                format: int32
                                type: integer
                              numInstances:
                                description: Optional. The number of VM instances
                                  in the instance group. For [HA cluster](/dataproc/docs/concepts/configuring-clusters/high-availability)
                                  [master_config](#FIELDS.master_config) groups, **must
                                  be set to 3**. For standard cluster [master_config](#FIELDS.master_config)
                                  groups, **must be set to 1**.
                                format: int32
                                type: integer
                              preemptibility:
                                description: |-
                                  Optional. Specifies the preemptibility of the instance group.

                                   The default value for master and worker groups is
                                   `NON_PREEMPTIBLE`. This default cannot be changed.

                                   The default value for secondary instances is
                                   `PREEMPTIBLE`.
                                type: string
                              startupConfig:
                                description: Optional. Configuration to handle the
                                  startup of instances during cluster create and update
                                  process.
                                properties:
                                  requiredRegistrationFraction:
                                    description: Optional. The config setting to enable
                                      cluster creation/ updation to be successful
                                      only after required_registration_fraction of
                                      instances are up and running. This configuration
                                      is applicable to only secondary workers for
                                      now. The cluster will fail if required_registration_fraction
                                      of instances are not available. This will include
                                      instance creation, agent registration, and service
                                      registration (if enabled).
                                    type: number
                                type: object
                            type: object
                          securityConfig:
                            description: Optional. Security settings for the cluster.
                            properties:
                              identityConfig:
                                description: Optional. Identity related configuration,
                                  including service account based secure multi-tenancy
                                  user mappings.
                                properties:
                                  userServiceAccountMapping:
                                    additionalProperties:
                                      type: string
                                    description: Required. Map of user to service
                                      account.
                                    type: object
                                type: object
                              kerberosConfig:
                                description: Optional. Kerberos related configuration.
                                properties:
                                  crossRealmTrustAdminServer:
                                    description: Optional. The admin server (IP or
                                      hostname) for the remote trusted realm in a
                                      cross realm trust relationship.
                                    type: string
                                  crossRealmTrustKdc:
                                    description: Optional. The KDC (IP or hostname)
                                      for the remote trusted realm in a cross realm
                                      trust relationship.
                                    type: string
                                  crossRealmTrustRealm:
                                    description: Optional. The remote realm the Dataproc
                                      on-cluster KDC will trust, should the user enable
                                      cross realm trust.
                                    type: string
                                  crossRealmTrustSharedPasswordURI:
                                    description: Optional. The Cloud Storage URI of
                                      a KMS encrypted file containing the shared password
                                      between the on-cluster Kerberos realm and the
                                      remote trusted realm, in a cross realm trust
                                      relationship.
                                    type: string
                                  enableKerberos:
                                    description: 'Optional. Flag to indicate whether
                                      to Kerberize the cluster (default: false). Set
                                      this field to true to enable Kerberos on a cluster.'
                                    type: boolean
                                  kdcDbKeyURI:
                                    description: Optional. The Cloud Storage URI of
                                      a KMS encrypted file containing the master key
                                      of the KDC database.
                                    type: string
                                  keyPasswordURI:
                                    description: Optional. The Cloud Storage URI of
                                      a KMS encrypted file containing the password
                                      to the user provided key. For the self-signed
                                      certificate, this password is generated by Dataproc.
                                    type: string
                                  keystorePasswordURI:
                                    description: Optional. The Cloud Storage URI of
                                      a KMS encrypted file containing the password
                                      to the user provided keystore. For the self-signed
                                      certificate, this password is generated by Dataproc.
                                    type: string
                                  keystoreURI:
                                    description: Optional. The Cloud Storage URI of
                                      the keystore file used for SSL encryption. If
                                      not provided, Dataproc will provide a self-signed
                                      certificate.
                                    type: string
                                  kmsKeyURI:
                                    description: Optional. The URI of the KMS key
                                      used to encrypt sensitive files.
                                    type: string
                                  realm:
                                    description: Optional. The name of the on-cluster
                                      Kerberos realm. If not specified, the uppercased
                                      domain of hostnames will be the realm.
                                    type: string
                                  rootPrincipalPasswordURI:
                                    description: Optional. The Cloud Storage URI of
                                      a KMS encrypted file containing the root principal
                                      password.
                                    type: string
                                  tgtLifetimeHours:
                                    description: Optional. The lifetime of the ticket
                                      granting ticket, in hours. If not specified,
                                      or user specifies 0, then default value 10 will
                                      be used.
                                    format: int32
                                    type: integer
                                  truststorePasswordURI:
                                    description: Optional. The Cloud Storage URI of
                                      a KMS encrypted file containing the password
                                      to the user provided truststore. For the self-signed
                                      certificate, this password is generated by Dataproc.
                                    type: string
                                  truststoreURI:
                                    description: Optional. The Cloud Storage URI of
                                      the truststore file used for SSL encryption.
                                      If not provided, Dataproc will provide a self-signed
                                      certificate.
                                    type: string
                                type: object
                            type: object
                          softwareConfig:
                            description: Optional. The config settings for cluster
                              software.
                            properties:
                              imageVersion:
                                description: Optional. The version of software inside
                                  the cluster. It must be one of the supported [Dataproc
                                  Versions](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#supported-dataproc-image-versions),
                                  such as "1.2" (including a subminor version, such
                                  as "1.2.29"), or the ["preview" version](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions).
                                  If unspecified, it defaults to the latest Debian
                                  version.
                                type: string
                              optionalComponents:
                                description: Optional. The set of components to activate
                                  on the cluster.
                                items:
                                  type: string
                                type: array
                              properties:
                                additionalProperties:
                                  type: string
                                description: |-
                                  Optional. The properties to set on daemon config files.

                                   Property keys are specified in `prefix:property` format, for example
                                   `core:hadoop.tmp.dir`. The following are supported prefixes
                                   and their mappings:

                                   * capacity-scheduler: `capacity-scheduler.xml`
                                   * core:   `core-site.xml`
                                   * distcp: `distcp-default.xml`
                                   * hdfs:   `hdfs-site.xml`
                                   * hive:   `hive-site.xml`
                                   * mapred: `mapred-site.xml`
                                   * pig:    `pig.properties`
                                   * spark:  `spark-defaults.conf`
                                   * yarn:   `yarn-site.xml`

                                   For more information, see [Cluster
                                   properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
                                type: object
                            type: object
                          tempBucket:
                            description: Optional. A Cloud Storage bucket used to
                              store ephemeral cluster and jobs data, such as Spark
                              and MapReduce history files. If you do not specify a
                              temp bucket, Dataproc will determine a Cloud Storage
                              location (US, ASIA, or EU) for your cluster's temp bucket
                              according to the Compute Engine zone where your cluster
                              is deployed, and then create and manage this project-level,
                              per-location bucket. The default bucket has a TTL of
                              90 days, but you can use any TTL (or none) if you specify
                              a bucket (see [Dataproc staging and temp buckets](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
                              **This field requires a Cloud Storage bucket name, not
                              a `gs://...` URI to a Cloud Storage bucket.**
                            type: string
                          workerConfig:
                            description: Optional. The Compute Engine config settings
                              for the cluster's worker instances.
                            properties:
                              accelerators:
                                description: Optional. The Compute Engine accelerator
                                  configuration for these instances.
                                items:
                                  properties:
                                    acceleratorCount:
                                      description: The number of the accelerator cards
                                        of this type exposed to this instance.
                                      format: int32
                                      type: integer
                                    acceleratorTypeURI:
                                      description: |-
                                        Full URL, partial URI, or short name of the accelerator type resource to
                                         expose to this instance. See
                                         [Compute Engine
                                         AcceleratorTypes](https://cloud.google.com/compute/docs/reference/v1/acceleratorTypes).

                                         Examples:

                                         * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/acceleratorTypes/nvidia-tesla-t4`
                                         * `projects/[project_id]/zones/[zone]/acceleratorTypes/nvidia-tesla-t4`
                                         * `nvidia-tesla-t4`

                                         **Auto Zone Exception**: If you are using the Dataproc
                                         [Auto Zone
                                         Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                         feature, you must use the short name of the accelerator type
                                         resource, for example, `nvidia-tesla-t4`.
                                      type: string
                                  type: object
                                type: array
                              diskConfig:
                                description: Optional. Disk option config settings.
                                properties:
                                  bootDiskProvisionedIops:
                                    description: 'Optional. Indicates how many IOPS
                                      to provision for the disk. This sets the number
                                      of I/O operations per second that the disk can
                                      handle. Note: This field is only supported if
                                      boot_disk_type is hyperdisk-balanced.'
                                    format: int64
                                    type: integer
                                  bootDiskProvisionedThroughput:
                                    description: 'Optional. Indicates how much throughput
                                      to provision for the disk. This sets the number
                                      of throughput mb per second that the disk can
                                      handle. Values must be greater than or equal
                                      to 1. Note: This field is only supported if
                                      boot_disk_type is hyperdisk-balanced.'
                                    format: int64
                                    type: integer
                                  bootDiskSizeGB:
                                    description: Optional. Size in GB of the boot
                                      disk (default is 500GB).
                                    format: int32
                                    type: integer
                                  bootDiskType:
                                    description: 'Optional. Type of the boot disk
                                      (default is "pd-standard"). Valid values: "pd-balanced"
                                      (Persistent Disk Balanced Solid State Drive),
                                      "pd-ssd" (Persistent Disk Solid State Drive),
                                      or "pd-standard" (Persistent Disk Hard Disk
                                      Drive). See [Disk types](https://cloud.google.com/compute/docs/disks#disk-types).'
                                    type: string
                                  localSsdInterface:
                                    description: 'Optional. Interface type of local
                                      SSDs (default is "scsi"). Valid values: "scsi"
                                      (Small Computer System Interface), "nvme" (Non-Volatile
                                      Memory Express). See [local SSD performance](https://cloud.google.com/compute/docs/disks/local-ssd#performance).'
                                    type: string
                                  numLocalSsds:
                                    description: |-
                                      Optional. Number of attached SSDs, from 0 to 8 (default is 0).
                                       If SSDs are not attached, the boot disk is used to store runtime logs and
                                       [HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data.
                                       If one or more SSDs are attached, this runtime bulk
                                       data is spread across them, and the boot disk contains only basic
                                       config and installed binaries.

                                       Note: Local SSD options may vary by machine type and number of vCPUs
                                       selected.
                                    format: int32
                                    type: integer
                                type: object
                              imageURI:
                                description: |-
                                  Optional. The Compute Engine image resource used for cluster instances.

                                   The URI can represent an image or image family.

                                   Image examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/images/[image-id]`
                                   * `projects/[project_id]/global/images/[image-id]`
                                   * `image-id`

                                   Image family examples. Dataproc will use the most recent
                                   image from the family:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/global/images/family/[custom-image-family-name]`
                                   * `projects/[project_id]/global/images/family/[custom-image-family-name]`

                                   If the URI is unspecified, it will be inferred from
                                   `SoftwareConfig.image_version` or the system default.
                                type: string
                              instanceFlexibilityPolicy:
                                description: Optional. Instance flexibility Policy
                                  allowing a mixture of VM shapes and provisioning
                                  models.
                                properties:
                                  instanceSelectionList:
                                    description: Optional. List of instance selection
                                      options that the group will use when creating
                                      new VMs.
                                    items:
                                      properties:
                                        machineTypes:
                                          description: Optional. Full machine-type
                                            names, e.g. "n1-standard-16".
                                          items:
                                            type: string
                                          type: array
                                        rank:
                                          description: Optional. Preference of this
                                            instance selection. Lower number means
                                            higher preference. Dataproc will first
                                            try to create a VM based on the machine-type
                                            with priority rank and fallback to next
                                            rank based on availability. Machine types
                                            and instance selections with the same
                                            priority have the same preference.
                                          format: int32
                                          type: integer
                                      type: object
                                    type: array
                                  provisioningModelMix:
                                    description: Optional. Defines how the Group selects
                                      the provisioning model to ensure required reliability.
                                    properties:
                                      standardCapacityBase:
                                        description: Optional. The base capacity that
                                          will always use Standard VMs to avoid risk
                                          of more preemption than the minimum capacity
                                          you need. Dataproc will create only standard
                                          VMs until it reaches standard_capacity_base,
                                          then it will start using standard_capacity_percent_above_base
                                          to mix Spot with Standard VMs. eg. If 15
                                          instances are requested and standard_capacity_base
                                          is 5, Dataproc will create 5 standard VMs
                                          and then start mixing spot and standard
                                          VMs for remaining 10 instances.
                                        format: int32
                                        type: integer
                                      standardCapacityPercentAboveBase:
                                        description: Optional. The percentage of target
                                          capacity that should use Standard VM. The
                                          remaining percentage will use Spot VMs.
                                          The percentage applies only to the capacity
                                          above standard_capacity_base. eg. If 15
                                          instances are requested and standard_capacity_base
                                          is 5 and standard_capacity_percent_above_base
                                          is 30, Dataproc will create 5 standard VMs
                                          and then start mixing spot and standard
                                          VMs for remaining 10 instances. The mix
                                          will be 30% standard and 70% spot.
                                        format: int32
                                        type: integer
                                    type: object
                                type: object
                              machineTypeURI:
                                description: |-
                                  Optional. The Compute Engine machine type used for cluster instances.

                                   A full URL, partial URI, or short name are valid. Examples:

                                   * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]/machineTypes/n1-standard-2`
                                   * `projects/[project_id]/zones/[zone]/machineTypes/n1-standard-2`
                                   * `n1-standard-2`

                                   **Auto Zone Exception**: If you are using the Dataproc
                                   [Auto Zone
                                   Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement)
                                   feature, you must use the short name of the machine type
                                   resource, for example, `n1-standard-2`.
                                type: string
                              minCPUPlatform:
                                description: Optional. Specifies the minimum cpu platform
                                  for the Instance Group. See [Dataproc -> Minimum
                                  CPU Platform](https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
                                type: string
                              minNumInstances:
                                description: |-
                                  Optional. The minimum number of primary worker instances to create.
                                   If `min_num_instances` is set, cluster creation will succeed if
                                   the number of primary workers created is at least equal to the
                                   `min_num_instances` number.

                                   Example: Cluster creation request with `num_instances` = `5` and
                                   `min_num_instances` = `3`:

                                   *  If 4 VMs are created and 1 instance fails,
                                      the failed VM is deleted. The cluster is
                                      resized to 4 instances and placed in a `RUNNING` state.
                                   *  If 2 instances are created and 3 instances fail,
                                      the cluster in placed in an `ERROR` state. The failed VMs
                                      are not deleted.
                                format: int32
                                type: integer
                              numInstances:
                                description: Optional. The number of VM instances
                                  in the instance group. For [HA cluster](/dataproc/docs/concepts/configuring-clusters/high-availability)
                                  [master_config](#FIELDS.master_config) groups, **must
                                  be set to 3**. For standard cluster [master_config](#FIELDS.master_config)
                                  groups, **must be set to 1**.
                                format: int32
                                type: integer
                              preemptibility:
                                description: |-
                                  Optional. Specifies the preemptibility of the instance group.

                                   The default value for master and worker groups is
                                   `NON_PREEMPTIBLE`. This default cannot be changed.

                                   The default value for secondary instances is
                                   `PREEMPTIBLE`.
                                type: string
                              startupConfig:
                                description: Optional. Configuration to handle the
                                  startup of instances during cluster create and update
                                  process.
                                properties:
                                  requiredRegistrationFraction:
                                    description: Optional. The config setting to enable
                                      cluster creation/ updation to be successful
                                      only after required_registration_fraction of
                                      instances are up and running. This configuration
                                      is applicable to only secondary workers for
                                      now. The cluster will fail if required_registration_fraction
                                      of instances are not available. This will include
                                      instance creation, agent registration, and service
                                      registration (if enabled).
                                    type: number
                                type: object
                            type: object
                        type: object
                      labels:
                        additionalProperties:
                          type: string
                        description: |-
                          Optional. The labels to associate with this cluster.

                           Label keys must be between 1 and 63 characters long, and must conform to
                           the following PCRE regular expression:
                           [\p{Ll}\p{Lo}][\p{Ll}\p{Lo}\p{N}_-]{0,62}

                           Label values must be between 1 and 63 characters long, and must conform to
                           the following PCRE regular expression: [\p{Ll}\p{Lo}\p{N}_-]{0,63}

                           No more than 32 labels can be associated with a given cluster.
                        type: object
                    type: object
                type: object
              projectRef:
                description: Required.
                oneOf:
                - not:
                    required:
                    - external
                  required:
                  - name
                - not:
                    anyOf:
                    - required:
                      - name
                    - required:
                      - namespace
                  required:
                  - external
                properties:
                  external:
                    description: The `projectID` field of a project, when not managed
                      by Config Connector.
                    type: string
                  kind:
                    description: The kind of the Project resource; optional but must
                      be `Project` if provided.
                    type: string
                  name:
                    description: The `name` field of a `Project` resource.
                    type: string
                  namespace:
                    description: The `namespace` field of a `Project` resource.
                    type: string
                type: object
              resourceID:
                description: The DataprocWorkflowTemplate name. If not given, the
                  metadata.name will be used.
                type: string
              version:
                description: |-
                  Optional. Used to perform a consistent read-modify-write.

                   This field should be left blank for a `CreateWorkflowTemplate` request. It
                   is required for an `UpdateWorkflowTemplate` request, and must match the
                   current server version. A typical update template flow would fetch the
                   current template with a `GetWorkflowTemplate` request, which will return
                   the current template with the `version` field filled in with the
                   current server version. The user updates other fields in the template,
                   then returns it as part of the `UpdateWorkflowTemplate` request.
                format: int32
                type: integer
            required:
            - placement
            type: object
          status:
            description: DataprocWorkflowTemplateStatus defines the config connector
              machine state of DataprocWorkflowTemplate
            properties:
              conditions:
                description: Conditions represent the latest available observations
                  of the object's current state.
                items:
                  properties:
                    lastTransitionTime:
                      description: Last time the condition transitioned from one status
                        to another.
                      type: string
                    message:
                      description: Human-readable message indicating details about
                        last transition.
                      type: string
                    reason:
                      description: Unique, one-word, CamelCase reason for the condition's
                        last transition.
                      type: string
                    status:
                      description: Status is the status of the condition. Can be True,
                        False, Unknown.
                      type: string
                    type:
                      description: Type is the type of the condition.
                      type: string
                  type: object
                type: array
              externalRef:
                description: A unique specifier for the DataprocWorkflowTemplate resource
                  in GCP.
                type: string
              observedGeneration:
                description: ObservedGeneration is the generation of the resource
                  that was most recently observed by the Config Connector controller.
                  If this is equal to metadata.generation, then that means that the
                  current reported status reflects the most recent desired state of
                  the resource.
                format: int64
                type: integer
              observedState:
                description: ObservedState is the state of the resource as most recently
                  observed in GCP.
                properties:
                  createTime:
                    description: Output only. The time template was created.
                    type: string
                  name:
                    description: |-
                      Output only. The resource name of the workflow template, as described
                       in https://cloud.google.com/apis/design/resource_names.

                       * For `projects.regions.workflowTemplates`, the resource name of the
                         template has the following format:
                         `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}`

                       * For `projects.locations.workflowTemplates`, the resource name of the
                         template has the following format:
                         `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
                    type: string
                  placement:
                    description: Required. WorkflowTemplate scheduling information.
                    properties:
                      managedCluster:
                        description: A cluster that is managed by the workflow.
                        properties:
                          config:
                            description: Required. The cluster configuration.
                            properties:
                              endpointConfig:
                                description: Optional. Port/endpoint configuration
                                  for this cluster
                                properties:
                                  httpPorts:
                                    additionalProperties:
                                      type: string
                                    description: Output only. The map of port descriptions
                                      to URLs. Will only be populated if enable_http_port_access
                                      is true.
                                    type: object
                                type: object
                              lifecycleConfig:
                                description: Optional. Lifecycle setting for the cluster.
                                properties:
                                  idleStartTime:
                                    description: Output only. The time when cluster
                                      became idle (most recent job finished) and became
                                      eligible for deletion due to idleness (see JSON
                                      representation of [Timestamp](https://developers.google.com/protocol-buffers/docs/proto3#json)).
                                    type: string
                                type: object
                              masterConfig:
                                description: Optional. The Compute Engine config settings
                                  for the cluster's master instance.
                                properties:
                                  instanceFlexibilityPolicy:
                                    description: Optional. Instance flexibility Policy
                                      allowing a mixture of VM shapes and provisioning
                                      models.
                                    properties:
                                      instanceSelectionResults:
                                        description: Output only. A list of instance
                                          selection results in the group.
                                        items:
                                          type: object
                                        type: array
                                    type: object
                                  instanceNames:
                                    description: Output only. The list of instance
                                      names. Dataproc derives the names from `cluster_name`,
                                      `num_instances`, and the instance group.
                                    items:
                                      type: string
                                    type: array
                                  instanceReferences:
                                    description: Output only. List of references to
                                      Compute Engine instances.
                                    items:
                                      properties:
                                        instanceID:
                                          description: The unique identifier of the
                                            Compute Engine instance.
                                          type: string
                                        instanceName:
                                          description: The user-friendly name of the
                                            Compute Engine instance.
                                          type: string
                                        publicEciesKey:
                                          description: The public ECIES key used for
                                            sharing data with this instance.
                                          type: string
                                        publicKey:
                                          description: The public RSA key used for
                                            sharing data with this instance.
                                          type: string
                                      type: object
                                    type: array
                                  isPreemptible:
                                    description: Output only. Specifies that this
                                      instance group contains preemptible instances.
                                    type: boolean
                                  managedGroupConfig:
                                    description: Output only. The config for Compute
                                      Engine Instance Group Manager that manages this
                                      group. This is only used for preemptible instance
                                      groups.
                                    type: object
                                type: object
                            type: object
                        type: object
                    type: object
                  updateTime:
                    description: Output only. The time template was last updated.
                    type: string
                type: object
            type: object
        required:
        - spec
        type: object
    served: true
    storage: true
    subresources:
      status: {}
