// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Config Connector and manual
//     changes will be clobbered when the file is regenerated.
//
// ----------------------------------------------------------------------------

// *** DISCLAIMER ***
// Config Connector's go-client for CRDs is currently in ALPHA, which means
// that future versions of the go-client may include breaking changes.
// Please try it out and give us feedback!

package v1alpha1

import (
	"github.com/GoogleCloudPlatform/k8s-config-connector/pkg/clients/generated/apis/k8s/v1alpha1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

type TaskBatch struct {
	/* Optional. Total number of job executors. Executor Count should be between 2 and 100. [Default=2] */
	// +optional
	ExecutorsCount *int32 `json:"executorsCount,omitempty"`

	/* Optional. Max configurable executors. If max_executors_count > executors_count, then auto-scaling is enabled. Max Executor Count should be between 2 and 1000. [Default=1000] */
	// +optional
	MaxExecutorsCount *int32 `json:"maxExecutorsCount,omitempty"`
}

type TaskContainerImage struct {
	/* Optional. Container image to use. */
	// +optional
	Image *string `json:"image,omitempty"`

	/* Optional. A list of Java JARS to add to the classpath. Valid input includes Cloud Storage URIs to Jar binaries. For example, gs://bucket-name/my/path/to/file.jar */
	// +optional
	JavaJars []string `json:"javaJars,omitempty"`

	/* Optional. Override to common configuration of open source components installed on the Dataproc cluster. The properties to set on daemon config files. Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. For more information, see [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties). */
	// +optional
	Properties map[string]string `json:"properties,omitempty"`

	/* Optional. A list of python packages to be installed. Valid formats include Cloud Storage URI to a PIP installable library. For example, gs://bucket-name/my/path/to/lib.tar.gz */
	// +optional
	PythonPackages []string `json:"pythonPackages,omitempty"`
}

type TaskExecutionSpec struct {
	/* Optional. The arguments to pass to the task. The args can use placeholders of the format ${placeholder} as part of key/value string. These will be interpolated before passing the args to the driver. Currently supported placeholders: - ${task_id} - ${job_time} To pass positional args, set the key as TASK_ARGS. The value should be a comma-separated string of all the positional arguments. To use a delimiter other than comma, refer to https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of other keys being present in the args, then TASK_ARGS will be passed as the last argument. */
	// +optional
	Args map[string]string `json:"args,omitempty"`

	/* Optional. The Cloud KMS key to use for encryption, of the form: `projects/{project_number}/locations/{location_id}/keyRings/{key-ring-name}/cryptoKeys/{key-name}`. */
	// +optional
	KmsKeyRef *v1alpha1.ResourceRef `json:"kmsKeyRef,omitempty"`

	/* Optional. The maximum duration after which the job execution is expired. */
	// +optional
	MaxJobExecutionLifetime *string `json:"maxJobExecutionLifetime,omitempty"`

	/* Optional. The project in which jobs are run. By default, the project containing the Lake is used. If a project is provided, the [ExecutionSpec.service_account][google.cloud.dataplex.v1.Task.ExecutionSpec.service_account] must belong to this project. */
	// +optional
	ProjectRef *v1alpha1.ResourceRef `json:"projectRef,omitempty"`

	/* Required. Service account to use to execute a task. If not provided, the default Compute service account for the project is used. */
	ServiceAccountRef v1alpha1.ResourceRef `json:"serviceAccountRef"`
}

type TaskInfrastructureSpec struct {
	/* Compute resources needed for a Task when using Dataproc Serverless. */
	// +optional
	Batch *TaskBatch `json:"batch,omitempty"`

	/* Container Image Runtime Configuration. */
	// +optional
	ContainerImage *TaskContainerImage `json:"containerImage,omitempty"`

	/* Vpc network. */
	// +optional
	VpcNetwork *TaskVpcNetwork `json:"vpcNetwork,omitempty"`
}

type TaskNotebook struct {
	/* Optional. Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip. */
	// +optional
	ArchiveURIs []string `json:"archiveURIs,omitempty"`

	/* Optional. Cloud Storage URIs of files to be placed in the working directory of each executor. */
	// +optional
	FileURIs []string `json:"fileURIs,omitempty"`

	/* Optional. Infrastructure specification for the execution. */
	// +optional
	InfrastructureSpec *TaskInfrastructureSpec `json:"infrastructureSpec,omitempty"`

	/* Required. Path to input notebook. This can be the Cloud Storage URI of the notebook file or the path to a Notebook Content. The execution args are accessible as environment variables (`TASK_key=value`). */
	Notebook string `json:"notebook"`
}

type TaskSpark struct {
	/* Optional. Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip. */
	// +optional
	ArchiveURIs []string `json:"archiveURIs,omitempty"`

	/* Optional. Cloud Storage URIs of files to be placed in the working directory of each executor. */
	// +optional
	FileURIs []string `json:"fileURIs,omitempty"`

	/* Optional. Infrastructure specification for the execution. */
	// +optional
	InfrastructureSpec *TaskInfrastructureSpec `json:"infrastructureSpec,omitempty"`

	/* The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in `jar_file_uris`. The execution args are passed in as a sequence of named process arguments (`--key=value`). */
	// +optional
	MainClass *string `json:"mainClass,omitempty"`

	/* The Cloud Storage URI of the jar file that contains the main class. The execution args are passed in as a sequence of named process arguments (`--key=value`). */
	// +optional
	MainJarFileURI *string `json:"mainJarFileURI,omitempty"`

	/* The Gcloud Storage URI of the main Python file to use as the driver. Must be a .py file. The execution args are passed in as a sequence of named process arguments (`--key=value`). */
	// +optional
	PythonScriptFile *string `json:"pythonScriptFile,omitempty"`

	/* The query text. The execution args are used to declare a set of script variables (`set key="value";`). */
	// +optional
	SqlScript *string `json:"sqlScript,omitempty"`

	/* A reference to a query file. This should be the Cloud Storage URI of the query file. The execution args are used to declare a set of script variables (`set key="value";`). */
	// +optional
	SqlScriptFile *string `json:"sqlScriptFile,omitempty"`
}

type TaskTriggerSpec struct {
	/* Optional. Prevent the task from executing. This does not cancel already running tasks. It is intended to temporarily disable RECURRING tasks. */
	// +optional
	Disabled *bool `json:"disabled,omitempty"`

	/* Optional. Number of retry attempts before aborting. Set to zero to never attempt to retry a failed task. */
	// +optional
	MaxRetries *int32 `json:"maxRetries,omitempty"`

	/* Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for running tasks periodically. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, `CRON_TZ=America/New_York 1 * * * *`, or `TZ=America/New_York 1 * * * *`. This field is required for RECURRING tasks. */
	// +optional
	Schedule *string `json:"schedule,omitempty"`

	/* Optional. The first run of the task will be after this time. If not specified, the task will run shortly after being submitted if ON_DEMAND and based on the schedule if RECURRING. */
	// +optional
	StartTime *string `json:"startTime,omitempty"`

	/* Required. Immutable. Trigger type of the user-specified Task. */
	// +optional
	Type *string `json:"type,omitempty"`
}

type TaskVpcNetwork struct {
	/* Optional. The Cloud VPC network in which the job is run. By default, the Cloud VPC network named Default within the project is used. */
	// +optional
	Network *string `json:"network,omitempty"`

	/* Optional. List of network tags to apply to the job. */
	// +optional
	NetworkTags []string `json:"networkTags,omitempty"`

	/* Optional. The Cloud VPC sub-network in which the job is run. */
	// +optional
	SubNetwork *string `json:"subNetwork,omitempty"`
}

type DataplexTaskSpec struct {
	/* Optional. Description of the task. */
	// +optional
	Description *string `json:"description,omitempty"`

	/* Optional. User friendly display name. */
	// +optional
	DisplayName *string `json:"displayName,omitempty"`

	/* Required. Spec related to how a task is executed. */
	ExecutionSpec TaskExecutionSpec `json:"executionSpec"`

	/* LakeRef defines the resource reference to DataplexLake, which "External" field holds the GCP identifier for the KRM object. */
	// +optional
	LakeRef *v1alpha1.ResourceRef `json:"lakeRef,omitempty"`

	/* Config related to running scheduled Notebooks. Exactly one of spark or notebook must be set. */
	// +optional
	Notebook *TaskNotebook `json:"notebook,omitempty"`

	/* The DataplexTask name. If not given, the metadata.name will be used. */
	// +optional
	ResourceID *string `json:"resourceID,omitempty"`

	/* Config related to running custom Spark tasks. Exactly one of spark or notebook must be set. */
	// +optional
	Spark *TaskSpark `json:"spark,omitempty"`

	/* Required. Spec related to how often and when a task should be triggered. */
	// +optional
	TriggerSpec *TaskTriggerSpec `json:"triggerSpec,omitempty"`
}

type TaskExecutionSpecStatus struct {
	/* The arguments to pass to the task. The args can use placeholders of the format ${placeholder} as part of key/value string. These will be interpolated before passing the args to the driver. Currently supported placeholders: - ${task_id} - ${job_time} To pass positional args, set the key as TASK_ARGS. The value should be a comma-separated string of all the positional arguments. To use a delimiter other than comma, refer to https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of other keys being present in the args, then TASK_ARGS will be passed as the last argument. */
	// +optional
	Args map[string]string `json:"args,omitempty"`

	/* The Cloud KMS key to use for encryption, of the form: `projects/{project_number}/locations/{location_id}/keyRings/{key-ring-name}/cryptoKeys/{key-name}`. */
	// +optional
	KmsKey *string `json:"kmsKey,omitempty"`

	/* The maximum duration after which the job execution is expired. */
	// +optional
	MaxJobExecutionLifetime *string `json:"maxJobExecutionLifetime,omitempty"`

	/* The project in which jobs are run. By default, the project containing the Lake is used. If a project is provided, the [ExecutionSpec.service_account][google.cloud.dataplex.v1.Task.ExecutionSpec.service_account] must belong to this project. */
	// +optional
	Project *string `json:"project,omitempty"`

	/* Service account to use to execute a task. If not provided, the default Compute service account for the project is used. */
	ServiceAccount string `json:"serviceAccount"`
}

type TaskExecutionStatusStatus struct {
	/* Output only. latest job execution */
	// +optional
	LatestJob *TaskLatestJobStatus `json:"latestJob,omitempty"`

	/* Output only. Last update time of the status. */
	// +optional
	UpdateTime *string `json:"updateTime,omitempty"`
}

type TaskLatestJobStatus struct {
	/* Output only. The time when the job ended. */
	// +optional
	EndTime *string `json:"endTime,omitempty"`

	/* Output only. Spec related to how a task is executed. */
	// +optional
	ExecutionSpec *TaskExecutionSpecStatus `json:"executionSpec,omitempty"`

	/* Output only. User-defined labels for the task. */
	// +optional
	Labels map[string]string `json:"labels,omitempty"`

	/* Output only. Additional information about the current state. */
	// +optional
	Message *string `json:"message,omitempty"`

	/* Output only. The relative resource name of the job, of the form: `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}/jobs/{job_id}`. */
	// +optional
	Name *string `json:"name,omitempty"`

	/* Output only. The number of times the job has been retried (excluding the initial attempt). */
	// +optional
	RetryCount *int32 `json:"retryCount,omitempty"`

	/* Output only. The underlying service running a job. */
	// +optional
	Service *string `json:"service,omitempty"`

	/* Output only. The full resource name for the job run under a particular service. */
	// +optional
	ServiceJob *string `json:"serviceJob,omitempty"`

	/* Output only. The time when the job was started. */
	// +optional
	StartTime *string `json:"startTime,omitempty"`

	/* Output only. Execution state for the job. */
	// +optional
	State *string `json:"state,omitempty"`

	/* Output only. Job execution trigger. */
	// +optional
	Trigger *string `json:"trigger,omitempty"`

	/* Output only. System generated globally unique ID for the job. */
	// +optional
	Uid *string `json:"uid,omitempty"`
}

type TaskObservedStateStatus struct {
	/* Output only. The time when the task was created. */
	// +optional
	CreateTime *string `json:"createTime,omitempty"`

	/* Status of the task execution (e.g. Jobs). */
	// +optional
	ExecutionStatus *TaskExecutionStatusStatus `json:"executionStatus,omitempty"`

	/* Output only. Current state of the task. */
	// +optional
	State *string `json:"state,omitempty"`

	/* Output only. System generated globally unique ID for the task. This ID will be different if the task is deleted and re-created with the same name. */
	// +optional
	Uid *string `json:"uid,omitempty"`

	/* Output only. The time when the task was last updated. */
	// +optional
	UpdateTime *string `json:"updateTime,omitempty"`
}

type DataplexTaskStatus struct {
	/* Conditions represent the latest available observations of the
	   DataplexTask's current state. */
	Conditions []v1alpha1.Condition `json:"conditions,omitempty"`
	/* A unique specifier for the DataplexTask resource in GCP. */
	// +optional
	ExternalRef *string `json:"externalRef,omitempty"`

	/* ObservedGeneration is the generation of the resource that was most recently observed by the Config Connector controller. If this is equal to metadata.generation, then that means that the current reported status reflects the most recent desired state of the resource. */
	// +optional
	ObservedGeneration *int64 `json:"observedGeneration,omitempty"`

	/* ObservedState is the state of the resource as most recently observed in GCP. */
	// +optional
	ObservedState *TaskObservedStateStatus `json:"observedState,omitempty"`
}

// +genclient
// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
// +kubebuilder:resource:categories=gcp,shortName=gcpdataplextask;gcpdataplextasks
// +kubebuilder:subresource:status
// +kubebuilder:metadata:labels="cnrm.cloud.google.com/managed-by-kcc=true";"cnrm.cloud.google.com/system=true"
// +kubebuilder:printcolumn:name="Age",JSONPath=".metadata.creationTimestamp",type="date"
// +kubebuilder:printcolumn:name="Ready",JSONPath=".status.conditions[?(@.type=='Ready')].status",type="string",description="When 'True', the most recent reconcile of the resource succeeded"
// +kubebuilder:printcolumn:name="Status",JSONPath=".status.conditions[?(@.type=='Ready')].reason",type="string",description="The reason for the value in 'Ready'"
// +kubebuilder:printcolumn:name="Status Age",JSONPath=".status.conditions[?(@.type=='Ready')].lastTransitionTime",type="date",description="The last transition time for the value in 'Status'"

// DataplexTask is the Schema for the dataplex API
// +k8s:openapi-gen=true
type DataplexTask struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	Spec   DataplexTaskSpec   `json:"spec,omitempty"`
	Status DataplexTaskStatus `json:"status,omitempty"`
}

// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object

// DataplexTaskList contains a list of DataplexTask
type DataplexTaskList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []DataplexTask `json:"items"`
}

func init() {
	SchemeBuilder.Register(&DataplexTask{}, &DataplexTaskList{})
}
