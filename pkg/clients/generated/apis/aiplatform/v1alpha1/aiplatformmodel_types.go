// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Config Connector and manual
//     changes will be clobbered when the file is regenerated.
//
// ----------------------------------------------------------------------------

// *** DISCLAIMER ***
// Config Connector's go-client for CRDs is currently in ALPHA, which means
// that future versions of the go-client may include breaking changes.
// Please try it out and give us feedback!

package v1alpha1

import (
	"github.com/GoogleCloudPlatform/k8s-config-connector/pkg/clients/generated/apis/k8s/v1alpha1"
	apiextensionsv1 "k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

var _ = apiextensionsv1.JSON{}

type ModelBaseModelSource struct {
	/* Information about the base model of Genie models. */
	// +optional
	GenieSource *ModelGenieSource `json:"genieSource,omitempty"`

	/* Source information of Model Garden models. */
	// +optional
	ModelGardenSource *ModelModelGardenSource `json:"modelGardenSource,omitempty"`
}

type ModelBlurBaselineConfig struct {
	/* The standard deviation of the blur kernel for the blurred baseline. The same blurring parameter is used for both the height and the width dimension. If not set, the method defaults to the zero (i.e. black for images) baseline. */
	// +optional
	MaxBlurSigma *float64 `json:"maxBlurSigma,omitempty"`
}

type ModelContainerSpec struct {
	/* Immutable. Specifies arguments for the command that runs when the container
	starts. This overrides the container's
	[`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify
	this field as an array of executable and arguments, similar to a Docker
	`CMD`'s "default parameters" form.

	If you don't specify this field but do specify the
	[command][google.cloud.aiplatform.v1.ModelContainerSpec.command] field,
	then the command from the `command` field runs without any additional
	arguments. See the [Kubernetes documentation about how the `command` and
	`args` fields interact with a container's `ENTRYPOINT` and
	`CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).

	If you don't specify this field and don't specify the `command` field,
	then the container's
	[`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and
	`CMD` determine what runs based on their default behavior. See the Docker
	documentation about [how `CMD` and `ENTRYPOINT`
	interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).

	In this field, you can reference [environment variables
	set by Vertex
	AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
	and environment variables set in the
	[env][google.cloud.aiplatform.v1.ModelContainerSpec.env] field. You cannot
	reference environment variables set in the Docker image. In order for
	environment variables to be expanded, reference them by using the following
	syntax: <code>$(<var>VARIABLE_NAME</var>)</code> Note that this differs
	from Bash variable expansion, which does not use parentheses. If a variable
	cannot be resolved, the reference in the input string is used unchanged. To
	avoid variable expansion, you can escape this syntax with `$$`; for
	example: <code>$$(<var>VARIABLE_NAME</var>)</code> This field corresponds
	to the `args` field of the Kubernetes Containers [v1 core
	API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core). */
	// +optional
	Args []string `json:"args,omitempty"`

	/* Immutable. Specifies the command that runs when the container starts. This
	overrides the container's
	[ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint).
	Specify this field as an array of executable and arguments, similar to a
	Docker `ENTRYPOINT`'s "exec" form, not its "shell" form.

	If you do not specify this field, then the container's `ENTRYPOINT` runs,
	in conjunction with the
	[args][google.cloud.aiplatform.v1.ModelContainerSpec.args] field or the
	container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd),
	if either exists. If this field is not specified and the container does not
	have an `ENTRYPOINT`, then refer to the Docker documentation about [how
	`CMD` and `ENTRYPOINT`
	interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact).

	If you specify this field, then you can also specify the `args` field to
	provide additional arguments for this command. However, if you specify this
	field, then the container's `CMD` is ignored. See the
	[Kubernetes documentation about how the
	`command` and `args` fields interact with a container's `ENTRYPOINT` and
	`CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes).

	In this field, you can reference [environment variables set by Vertex
	AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables)
	and environment variables set in the
	[env][google.cloud.aiplatform.v1.ModelContainerSpec.env] field. You cannot
	reference environment variables set in the Docker image. In order for
	environment variables to be expanded, reference them by using the following
	syntax: <code>$(<var>VARIABLE_NAME</var>)</code> Note that this differs
	from Bash variable expansion, which does not use parentheses. If a variable
	cannot be resolved, the reference in the input string is used unchanged. To
	avoid variable expansion, you can escape this syntax with `$$`; for
	example: <code>$$(<var>VARIABLE_NAME</var>)</code> This field corresponds
	to the `command` field of the Kubernetes Containers [v1 core
	API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core). */
	// +optional
	Command []string `json:"command,omitempty"`

	/* Immutable. Deployment timeout. Limit for deployment timeout is 2 hours. */
	// +optional
	DeploymentTimeout *string `json:"deploymentTimeout,omitempty"`

	/* Immutable. List of environment variables to set in the container. After the
	container starts running, code running in the container can read these
	environment variables.

	Additionally, the
	[command][google.cloud.aiplatform.v1.ModelContainerSpec.command] and
	[args][google.cloud.aiplatform.v1.ModelContainerSpec.args] fields can
	reference these variables. Later entries in this list can also reference
	earlier entries. For example, the following example sets the variable
	`VAR_2` to have the value `foo bar`:

	```json
	[
	{
	"name": "VAR_1",
	"value": "foo"
	},
	{
	"name": "VAR_2",
	"value": "$(VAR_1) bar"
	}
	]
	```

	If you switch the order of the variables in the example, then the expansion
	does not occur.

	This field corresponds to the `env` field of the Kubernetes Containers
	[v1 core
	API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core). */
	// +optional
	Env []ModelEnv `json:"env,omitempty"`

	/* Immutable. List of ports to expose from the container. Vertex AI sends gRPC
	prediction requests that it receives to the first port on this list. Vertex
	AI also sends liveness and health checks to this port.

	If you do not specify this field, gRPC requests to the container will be
	disabled.

	Vertex AI does not use ports other than the first one listed. This field
	corresponds to the `ports` field of the Kubernetes Containers v1 core API. */
	// +optional
	GrpcPorts []ModelGrpcPorts `json:"grpcPorts,omitempty"`

	/* Immutable. Specification for Kubernetes readiness probe. */
	// +optional
	HealthProbe *ModelHealthProbe `json:"healthProbe,omitempty"`

	/* Immutable. HTTP path on the container to send health checks to. Vertex AI
	intermittently sends GET requests to this path on the container's IP
	address and port to check that the container is healthy. Read more about
	[health
	checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health).

	For example, if you set this field to `/bar`, then Vertex AI
	intermittently sends a GET request to the `/bar` path on the port of your
	container specified by the first value of this `ModelContainerSpec`'s
	[ports][google.cloud.aiplatform.v1.ModelContainerSpec.ports] field.

	If you don't specify this field, it defaults to the following value when
	you [deploy this Model to an
	Endpoint][google.cloud.aiplatform.v1.EndpointService.DeployModel]:
	<code>/v1/endpoints/<var>ENDPOINT</var>/deployedModels/<var>DEPLOYED_MODEL</var>:predict</code>
	The placeholders in this value are replaced as follows:

	* <var>ENDPOINT</var>: The last segment (following `endpoints/`)of the
	Endpoint.name][] field of the Endpoint where this Model has been
	deployed. (Vertex AI makes this value available to your container code
	as the [`AIP_ENDPOINT_ID` environment
	variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)

	* <var>DEPLOYED_MODEL</var>:
	[DeployedModel.id][google.cloud.aiplatform.v1.DeployedModel.id] of the
	`DeployedModel`.
	(Vertex AI makes this value available to your container code as the
	[`AIP_DEPLOYED_MODEL_ID` environment
	variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) */
	// +optional
	HealthRoute *string `json:"healthRoute,omitempty"`

	/* Required. Immutable. URI of the Docker image to be used as the custom
	container for serving predictions. This URI must identify an image in
	Artifact Registry or Container Registry. Learn more about the [container
	publishing
	requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing),
	including permissions requirements for the Vertex AI Service Agent.

	The container image is ingested upon
	[ModelService.UploadModel][google.cloud.aiplatform.v1.ModelService.UploadModel],
	stored internally, and this original path is afterwards not used.

	To learn about the requirements for the Docker image itself, see
	[Custom container
	requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#).

	You can use the URI to one of Vertex AI's [pre-built container images for
	prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers)
	in this field. */
	// +optional
	ImageURI *string `json:"imageURI,omitempty"`

	/* Immutable. List of ports to expose from the container. Vertex AI sends any
	prediction requests that it receives to the first port on this list. Vertex
	AI also sends
	[liveness and health
	checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness)
	to this port.

	If you do not specify this field, it defaults to following value:

	```json
	[
	{
	"containerPort": 8080
	}
	]
	```

	Vertex AI does not use ports other than the first one listed. This field
	corresponds to the `ports` field of the Kubernetes Containers
	[v1 core
	API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core). */
	// +optional
	Ports []ModelPorts `json:"ports,omitempty"`

	/* Immutable. HTTP path on the container to send prediction requests to.
	Vertex AI forwards requests sent using
	[projects.locations.endpoints.predict][google.cloud.aiplatform.v1.PredictionService.Predict]
	to this path on the container's IP address and port. Vertex AI then returns
	the container's response in the API response.

	For example, if you set this field to `/foo`, then when Vertex AI
	receives a prediction request, it forwards the request body in a POST
	request to the `/foo` path on the port of your container specified by the
	first value of this `ModelContainerSpec`'s
	[ports][google.cloud.aiplatform.v1.ModelContainerSpec.ports] field.

	If you don't specify this field, it defaults to the following value when
	you [deploy this Model to an
	Endpoint][google.cloud.aiplatform.v1.EndpointService.DeployModel]:
	<code>/v1/endpoints/<var>ENDPOINT</var>/deployedModels/<var>DEPLOYED_MODEL</var>:predict</code>
	The placeholders in this value are replaced as follows:

	* <var>ENDPOINT</var>: The last segment (following `endpoints/`)of the
	Endpoint.name][] field of the Endpoint where this Model has been
	deployed. (Vertex AI makes this value available to your container code
	as the [`AIP_ENDPOINT_ID` environment
	variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)

	* <var>DEPLOYED_MODEL</var>:
	[DeployedModel.id][google.cloud.aiplatform.v1.DeployedModel.id] of the
	`DeployedModel`.
	(Vertex AI makes this value available to your container code
	as the [`AIP_DEPLOYED_MODEL_ID` environment
	variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) */
	// +optional
	PredictRoute *string `json:"predictRoute,omitempty"`

	/* Immutable. The amount of the VM memory to reserve as the shared memory for the model in megabytes. */
	// +optional
	SharedMemorySizeMb *int64 `json:"sharedMemorySizeMb,omitempty"`

	/* Immutable. Specification for Kubernetes startup probe. */
	// +optional
	StartupProbe *ModelStartupProbe `json:"startupProbe,omitempty"`
}

type ModelDataStats struct {
	/* Number of Annotations that are used for evaluating this Model. If the Model is evaluated multiple times, this will be the number of test Annotations used by the first evaluation. If the Model is not evaluated, the number is 0. */
	// +optional
	TestAnnotationsCount *int64 `json:"testAnnotationsCount,omitempty"`

	/* Number of DataItems that were used for evaluating this Model. If the Model is evaluated multiple times, this will be the number of test DataItems used by the first evaluation. If the Model is not evaluated, the number is 0. */
	// +optional
	TestDataItemsCount *int64 `json:"testDataItemsCount,omitempty"`

	/* Number of Annotations that are used for training this Model. */
	// +optional
	TrainingAnnotationsCount *int64 `json:"trainingAnnotationsCount,omitempty"`

	/* Number of DataItems that were used for training this Model. */
	// +optional
	TrainingDataItemsCount *int64 `json:"trainingDataItemsCount,omitempty"`

	/* Number of Annotations that are used for validating this Model during training. */
	// +optional
	ValidationAnnotationsCount *int64 `json:"validationAnnotationsCount,omitempty"`

	/* Number of DataItems that were used for validating this Model during training. */
	// +optional
	ValidationDataItemsCount *int64 `json:"validationDataItemsCount,omitempty"`
}

type ModelEncodedBaselines struct {
	/* Represents a boolean value. */
	// +optional
	BoolValue *bool `json:"boolValue,omitempty"`

	/* Represents a null value. */
	// +optional
	NullValue *string `json:"nullValue,omitempty"`

	/* Represents a double value. */
	// +optional
	NumberValue *float64 `json:"numberValue,omitempty"`

	/* Represents a string value. */
	// +optional
	StringValue *string `json:"stringValue,omitempty"`

	/* Represents a structured value. */
	// +optional
	StructValue map[string]string `json:"structValue,omitempty"`
}

type ModelEncryptionSpec struct {
	/* Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created. */
	// +optional
	KmsKeyName *string `json:"kmsKeyName,omitempty"`
}

type ModelEnv struct {
	/* Required. Name of the environment variable. Must be a valid C identifier. */
	// +optional
	Name *string `json:"name,omitempty"`

	/* Required. Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. */
	// +optional
	Value *string `json:"value,omitempty"`
}

type ModelExampleGCSSource struct {
	/* The format in which instances are given, if not specified, assume it's JSONL format. Currently only JSONL format is supported. */
	// +optional
	DataFormat *string `json:"dataFormat,omitempty"`

	/* The Cloud Storage location for the input instances. */
	// +optional
	GcsSource *ModelGcsSource `json:"gcsSource,omitempty"`
}

type ModelExamples struct {
	/* The Cloud Storage input instances. */
	// +optional
	ExampleGCSSource *ModelExampleGCSSource `json:"exampleGCSSource,omitempty"`

	/* The full configuration for the generated index, the semantics are the same as [metadata][google.cloud.aiplatform.v1.Index.metadata] and should match [NearestNeighborSearchConfig](https://cloud.google.com/vertex-ai/docs/explainable-ai/configuring-explanations-example-based#nearest-neighbor-search-config). */
	// +optional
	NearestNeighborSearchConfig *ModelNearestNeighborSearchConfig `json:"nearestNeighborSearchConfig,omitempty"`

	/* The number of neighbors to return when querying for examples. */
	// +optional
	NeighborCount *int32 `json:"neighborCount,omitempty"`

	/* Simplified preset configuration, which automatically sets configuration values based on the desired query speed-precision trade-off and modality. */
	// +optional
	Presets *ModelPresets `json:"presets,omitempty"`
}

type ModelExec struct {
	/* Command is the command line to execute inside the container, the working directory for the command is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy. */
	// +optional
	Command []string `json:"command,omitempty"`
}

type ModelExplanationSpec struct {
	/* Optional. Metadata describing the Model's input and output for explanation. */
	// +optional
	Metadata *ModelMetadata `json:"metadata,omitempty"`

	/* Required. Parameters that configure explaining of the Model's predictions. */
	// +optional
	Parameters *ModelParameters `json:"parameters,omitempty"`
}

type ModelFeatureNoiseSigma struct {
	/* Noise sigma per feature. No noise is added to features that are not set. */
	// +optional
	NoiseSigma []ModelNoiseSigma `json:"noiseSigma,omitempty"`
}

type ModelFeatureValueDomain struct {
	/* The maximum permissible value for this feature. */
	// +optional
	MaxValue *float64 `json:"maxValue,omitempty"`

	/* The minimum permissible value for this feature. */
	// +optional
	MinValue *float64 `json:"minValue,omitempty"`

	/* If this input feature has been normalized to a mean value of 0, the original_mean specifies the mean value of the domain prior to normalization. */
	// +optional
	OriginalMean *float64 `json:"originalMean,omitempty"`

	/* If this input feature has been normalized to a standard deviation of 1.0, the original_stddev specifies the standard deviation of the domain prior to normalization. */
	// +optional
	OriginalStddev *float64 `json:"originalStddev,omitempty"`
}

type ModelGcsSource struct {
	/* Required. Google Cloud Storage URI(-s) to the input file(s). May contain wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames. */
	// +optional
	Uris []string `json:"uris,omitempty"`
}

type ModelGenieSource struct {
	/* Required. The public base model URI. */
	// +optional
	BaseModelURI *string `json:"baseModelURI,omitempty"`
}

type ModelGrpcPorts struct {
	/* The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive. */
	// +optional
	ContainerPort *int32 `json:"containerPort,omitempty"`
}

type ModelHealthProbe struct {
	/* ExecAction probes the health of a container by executing a command. */
	// +optional
	Exec *ModelExec `json:"exec,omitempty"`

	/* How often (in seconds) to perform the probe. Default to 10 seconds.
	Minimum value is 1. Must be less than timeout_seconds.

	Maps to Kubernetes probe argument 'periodSeconds'. */
	// +optional
	PeriodSeconds *int32 `json:"periodSeconds,omitempty"`

	/* Number of seconds after which the probe times out. Defaults to 1 second.
	Minimum value is 1. Must be greater or equal to period_seconds.

	Maps to Kubernetes probe argument 'timeoutSeconds'. */
	// +optional
	TimeoutSeconds *int32 `json:"timeoutSeconds,omitempty"`
}

type ModelIndexDisplayNameMapping struct {
	/* Represents a boolean value. */
	// +optional
	BoolValue *bool `json:"boolValue,omitempty"`

	/* Represents a null value. */
	// +optional
	NullValue *string `json:"nullValue,omitempty"`

	/* Represents a double value. */
	// +optional
	NumberValue *float64 `json:"numberValue,omitempty"`

	/* Represents a string value. */
	// +optional
	StringValue *string `json:"stringValue,omitempty"`

	/* Represents a structured value. */
	// +optional
	StructValue map[string]string `json:"structValue,omitempty"`
}

type ModelInputBaselines struct {
	/* Represents a boolean value. */
	// +optional
	BoolValue *bool `json:"boolValue,omitempty"`

	/* Represents a null value. */
	// +optional
	NullValue *string `json:"nullValue,omitempty"`

	/* Represents a double value. */
	// +optional
	NumberValue *float64 `json:"numberValue,omitempty"`

	/* Represents a string value. */
	// +optional
	StringValue *string `json:"stringValue,omitempty"`

	/* Represents a structured value. */
	// +optional
	StructValue map[string]string `json:"structValue,omitempty"`
}

type ModelInputs struct {
	/* Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor. */
	// +optional
	DenseShapeTensorName *string `json:"denseShapeTensorName,omitempty"`

	/* A list of baselines for the encoded tensor.

	The shape of each baseline should match the shape of the encoded tensor.
	If a scalar is provided, Vertex AI broadcasts to the same shape as the
	encoded tensor. */
	// +optional
	EncodedBaselines []ModelEncodedBaselines `json:"encodedBaselines,omitempty"`

	/* Encoded tensor is a transformation of the input tensor. Must be provided
	if choosing
	[Integrated Gradients
	attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution]
	or [XRAI
	attribution][google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution]
	and the input tensor is not differentiable.

	An encoded tensor is generated if the input tensor is encoded by a lookup
	table. */
	// +optional
	EncodedTensorName *string `json:"encodedTensorName,omitempty"`

	/* Defines how the feature is encoded into the input tensor. Defaults to IDENTITY. */
	// +optional
	Encoding *string `json:"encoding,omitempty"`

	/* The domain details of the input feature value. Like min/max, original mean or standard deviation if normalized. */
	// +optional
	FeatureValueDomain *ModelFeatureValueDomain `json:"featureValueDomain,omitempty"`

	/* Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in [Attribution.feature_attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions], keyed by the group name. */
	// +optional
	GroupName *string `json:"groupName,omitempty"`

	/* A list of feature names for each index in the input tensor. Required when the input [InputMetadata.encoding][google.cloud.aiplatform.v1.ExplanationMetadata.InputMetadata.encoding] is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR. */
	// +optional
	IndexFeatureMapping []string `json:"indexFeatureMapping,omitempty"`

	/* Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor. */
	// +optional
	IndicesTensorName *string `json:"indicesTensorName,omitempty"`

	/* Baseline inputs for this feature.

	If no baseline is specified, Vertex AI chooses the baseline for this
	feature. If multiple baselines are specified, Vertex AI returns the
	average attributions across them in
	[Attribution.feature_attributions][google.cloud.aiplatform.v1.Attribution.feature_attributions].

	For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape
	of each baseline must match the shape of the input tensor. If a scalar is
	provided, we broadcast to the same shape as the input tensor.

	For custom images, the element of the baselines must be in the same
	format as the feature's input in the
	[instance][google.cloud.aiplatform.v1.ExplainRequest.instances][]. The
	schema of any single instance may be specified via Endpoint's
	DeployedModels' [Model's][google.cloud.aiplatform.v1.DeployedModel.model]
	[PredictSchemata's][google.cloud.aiplatform.v1.Model.predict_schemata]
	[instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri]. */
	// +optional
	InputBaselines []ModelInputBaselines `json:"inputBaselines,omitempty"`

	/* Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow. */
	// +optional
	InputTensorName *string `json:"inputTensorName,omitempty"`

	/* Modality of the feature. Valid values are: numeric, image. Defaults to numeric. */
	// +optional
	Modality *string `json:"modality,omitempty"`

	/* Visualization configurations for image explanation. */
	// +optional
	Visualization *ModelVisualization `json:"visualization,omitempty"`
}

type ModelIntegratedGradientsAttribution struct {
	/* Config for IG with blur baseline.

	When enabled, a linear path from the maximally blurred image to the input
	image is created. Using a blurred baseline instead of zero (black image) is
	motivated by the BlurIG approach explained here:
	https://arxiv.org/abs/2004.03383 */
	// +optional
	BlurBaselineConfig *ModelBlurBaselineConfig `json:"blurBaselineConfig,omitempty"`

	/* Config for SmoothGrad approximation of gradients.

	When enabled, the gradients are approximated by averaging the gradients
	from noisy samples in the vicinity of the inputs. Adding
	noise can help improve the computed gradients. Refer to this paper for more
	details: https://arxiv.org/pdf/1706.03825.pdf */
	// +optional
	SmoothGradConfig *ModelSmoothGradConfig `json:"smoothGradConfig,omitempty"`

	/* Required. The number of steps for approximating the path integral.
	A good value to start is 50 and gradually increase until the
	sum to diff property is within the desired error range.

	Valid range of its value is [1, 100], inclusively. */
	// +optional
	StepCount *int32 `json:"stepCount,omitempty"`
}

type ModelMetadata struct {
	/* Represents a boolean value. */
	// +optional
	BoolValue *bool `json:"boolValue,omitempty"`

	/* Represents a null value. */
	// +optional
	NullValue *string `json:"nullValue,omitempty"`

	/* Represents a double value. */
	// +optional
	NumberValue *float64 `json:"numberValue,omitempty"`

	/* Represents a string value. */
	// +optional
	StringValue *string `json:"stringValue,omitempty"`

	/* Represents a structured value. */
	// +optional
	StructValue map[string]string `json:"structValue,omitempty"`
}

type ModelModelGardenSource struct {
	/* Required. The model garden source model resource name. */
	// +optional
	PublicModelName *string `json:"publicModelName,omitempty"`
}

type ModelNearestNeighborSearchConfig struct {
	/* Represents a boolean value. */
	// +optional
	BoolValue *bool `json:"boolValue,omitempty"`

	/* Represents a null value. */
	// +optional
	NullValue *string `json:"nullValue,omitempty"`

	/* Represents a double value. */
	// +optional
	NumberValue *float64 `json:"numberValue,omitempty"`

	/* Represents a string value. */
	// +optional
	StringValue *string `json:"stringValue,omitempty"`

	/* Represents a structured value. */
	// +optional
	StructValue map[string]string `json:"structValue,omitempty"`
}

type ModelNoiseSigma struct {
	/* The name of the input feature for which noise sigma is provided. The features are defined in [explanation metadata inputs][google.cloud.aiplatform.v1.ExplanationMetadata.inputs]. */
	// +optional
	Name *string `json:"name,omitempty"`

	/* This represents the standard deviation of the Gaussian kernel that will be used to add noise to the feature prior to computing gradients. Similar to [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma] but represents the noise added to the current feature. Defaults to 0.1. */
	// +optional
	Sigma *float64 `json:"sigma,omitempty"`
}

type ModelOutputs struct {
	/* Specify a field name in the prediction to look for the display name.

	Use this if the prediction contains the display names for the outputs.

	The display names in the prediction must have the same shape of the
	outputs, so that it can be located by
	[Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]
	for a specific output. */
	// +optional
	DisplayNameMappingKey *string `json:"displayNameMappingKey,omitempty"`

	/* Static mapping between the index and display name.

	Use this if the outputs are a deterministic n-dimensional array, e.g. a
	list of scores of all the classes in a pre-defined order for a
	multi-classification Model. It's not feasible if the outputs are
	non-deterministic, e.g. the Model produces top-k classes or sort the
	outputs by their values.

	The shape of the value must be an n-dimensional array of strings. The
	number of dimensions must match that of the outputs to be explained.
	The
	[Attribution.output_display_name][google.cloud.aiplatform.v1.Attribution.output_display_name]
	is populated by locating in the mapping with
	[Attribution.output_index][google.cloud.aiplatform.v1.Attribution.output_index]. */
	// +optional
	IndexDisplayNameMapping *ModelIndexDisplayNameMapping `json:"indexDisplayNameMapping,omitempty"`

	/* Name of the output tensor. Required and is only applicable to Vertex AI provided images for Tensorflow. */
	// +optional
	OutputTensorName *string `json:"outputTensorName,omitempty"`
}

type ModelParameters struct {
	/* Example-based explanations that returns the nearest neighbors from the provided dataset. */
	// +optional
	Examples *ModelExamples `json:"examples,omitempty"`

	/* An attribution method that computes Aumann-Shapley values taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365 */
	// +optional
	IntegratedGradientsAttribution *ModelIntegratedGradientsAttribution `json:"integratedGradientsAttribution,omitempty"`

	/* An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features. Refer to this paper for model details: https://arxiv.org/abs/1306.4265. */
	// +optional
	SampledShapleyAttribution *ModelSampledShapleyAttribution `json:"sampledShapleyAttribution,omitempty"`

	/* If populated, returns attributions for top K indices of outputs (defaults to 1). Only applies to Models that predicts more than one outputs (e,g, multi-class Models). When set to -1, returns explanations for all outputs. */
	// +optional
	TopK *int32 `json:"topK,omitempty"`

	/* An attribution method that redistributes Integrated Gradients
	attribution to segmented regions, taking advantage of the model's fully
	differentiable structure. Refer to this paper for
	more details: https://arxiv.org/abs/1906.02825

	XRAI currently performs better on natural images, like a picture of a
	house or an animal. If the images are taken in artificial environments,
	like a lab or manufacturing line, or from diagnostic equipment, like
	x-rays or quality-control cameras, use Integrated Gradients instead. */
	// +optional
	XraiAttribution *ModelXraiAttribution `json:"xraiAttribution,omitempty"`
}

type ModelPorts struct {
	/* The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive. */
	// +optional
	ContainerPort *int32 `json:"containerPort,omitempty"`
}

type ModelPredictSchemata struct {
	/* Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single instance, which are used in [PredictRequest.instances][google.cloud.aiplatform.v1.PredictRequest.instances], [ExplainRequest.instances][google.cloud.aiplatform.v1.ExplainRequest.instances] and [BatchPredictionJob.input_config][google.cloud.aiplatform.v1.BatchPredictionJob.input_config]. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access. */
	// +optional
	InstanceSchemaURI *string `json:"instanceSchemaURI,omitempty"`

	/* Immutable. Points to a YAML file stored on Google Cloud Storage describing the parameters of prediction and explanation via [PredictRequest.parameters][google.cloud.aiplatform.v1.PredictRequest.parameters], [ExplainRequest.parameters][google.cloud.aiplatform.v1.ExplainRequest.parameters] and [BatchPredictionJob.model_parameters][google.cloud.aiplatform.v1.BatchPredictionJob.model_parameters]. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no parameters are supported, then it is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access. */
	// +optional
	ParametersSchemaURI *string `json:"parametersSchemaURI,omitempty"`

	/* Immutable. Points to a YAML file stored on Google Cloud Storage describing the format of a single prediction produced by this Model, which are returned via [PredictResponse.predictions][google.cloud.aiplatform.v1.PredictResponse.predictions], [ExplainResponse.explanations][google.cloud.aiplatform.v1.ExplainResponse.explanations], and [BatchPredictionJob.output_config][google.cloud.aiplatform.v1.BatchPredictionJob.output_config]. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access. */
	// +optional
	PredictionSchemaURI *string `json:"predictionSchemaURI,omitempty"`
}

type ModelPresets struct {
	/* The modality of the uploaded model, which automatically configures the distance measurement and feature normalization for the underlying example index and queries. If your model does not precisely fit one of these types, it is okay to choose the closest type. */
	// +optional
	Modality *string `json:"modality,omitempty"`

	/* Preset option controlling parameters for speed-precision trade-off when querying for examples. If omitted, defaults to `PRECISE`. */
	// +optional
	Query *string `json:"query,omitempty"`
}

type ModelSampledShapleyAttribution struct {
	/* Required. The number of feature permutations to consider when approximating
	the Shapley values.

	Valid range of its value is [1, 50], inclusively. */
	// +optional
	PathCount *int32 `json:"pathCount,omitempty"`
}

type ModelSmoothGradConfig struct {
	/* This is similar to [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma], but provides additional flexibility. A separate noise sigma can be provided for each feature, which is useful if their distributions are different. No noise is added to features that are not set. If this field is unset, [noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.noise_sigma] will be used for all features. */
	// +optional
	FeatureNoiseSigma *ModelFeatureNoiseSigma `json:"featureNoiseSigma,omitempty"`

	/* This is a single float value and will be used to add noise to all the
	features. Use this field when all features are normalized to have the
	same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where
	features are normalized to have 0-mean and 1-variance. Learn more about
	[normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization).

	For best results the recommended value is about 10% - 20% of the standard
	deviation of the input feature. Refer to section 3.2 of the SmoothGrad
	paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1.

	If the distribution is different per feature, set
	[feature_noise_sigma][google.cloud.aiplatform.v1.SmoothGradConfig.feature_noise_sigma]
	instead for each feature. */
	// +optional
	NoiseSigma *ModelNoiseSigma `json:"noiseSigma,omitempty"`

	/* The number of gradient samples to use for approximation. The higher this number, the more accurate the gradient is, but the runtime complexity increases by this factor as well. Valid range of its value is [1, 50]. Defaults to 3. */
	// +optional
	NoisySampleCount *int32 `json:"noisySampleCount,omitempty"`
}

type ModelStartupProbe struct {
	/* ExecAction probes the health of a container by executing a command. */
	// +optional
	Exec *ModelExec `json:"exec,omitempty"`

	/* How often (in seconds) to perform the probe. Default to 10 seconds.
	Minimum value is 1. Must be less than timeout_seconds.

	Maps to Kubernetes probe argument 'periodSeconds'. */
	// +optional
	PeriodSeconds *int32 `json:"periodSeconds,omitempty"`

	/* Number of seconds after which the probe times out. Defaults to 1 second.
	Minimum value is 1. Must be greater or equal to period_seconds.

	Maps to Kubernetes probe argument 'timeoutSeconds'. */
	// +optional
	TimeoutSeconds *int32 `json:"timeoutSeconds,omitempty"`
}

type ModelVisualization struct {
	/* Excludes attributions below the specified percentile, from the highlighted areas. Defaults to 62. */
	// +optional
	ClipPercentLowerbound *float64 `json:"clipPercentLowerbound,omitempty"`

	/* Excludes attributions above the specified percentile from the highlighted areas. Using the clip_percent_upperbound and clip_percent_lowerbound together can be useful for filtering out noise and making it easier to see areas of strong attribution. Defaults to 99.9. */
	// +optional
	ClipPercentUpperbound *float64 `json:"clipPercentUpperbound,omitempty"`

	/* The color scheme used for the highlighted areas.

	Defaults to PINK_GREEN for
	[Integrated Gradients
	attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution],
	which shows positive attributions in green and negative in pink.

	Defaults to VIRIDIS for
	[XRAI
	attribution][google.cloud.aiplatform.v1.ExplanationParameters.xrai_attribution],
	which highlights the most influential regions in yellow and the least
	influential in blue. */
	// +optional
	ColorMap *string `json:"colorMap,omitempty"`

	/* How the original image is displayed in the visualization. Adjusting the overlay can help increase visual clarity if the original image makes it difficult to view the visualization. Defaults to NONE. */
	// +optional
	OverlayType *string `json:"overlayType,omitempty"`

	/* Whether to only highlight pixels with positive contributions, negative or both. Defaults to POSITIVE. */
	// +optional
	Polarity *string `json:"polarity,omitempty"`

	/* Type of the image visualization. Only applicable to [Integrated Gradients attribution][google.cloud.aiplatform.v1.ExplanationParameters.integrated_gradients_attribution]. OUTLINES shows regions of attribution, while PIXELS shows per-pixel attribution. Defaults to OUTLINES. */
	// +optional
	Type *string `json:"type,omitempty"`
}

type ModelXraiAttribution struct {
	/* Config for XRAI with blur baseline.

	When enabled, a linear path from the maximally blurred image to the input
	image is created. Using a blurred baseline instead of zero (black image) is
	motivated by the BlurIG approach explained here:
	https://arxiv.org/abs/2004.03383 */
	// +optional
	BlurBaselineConfig *ModelBlurBaselineConfig `json:"blurBaselineConfig,omitempty"`

	/* Config for SmoothGrad approximation of gradients.

	When enabled, the gradients are approximated by averaging the gradients
	from noisy samples in the vicinity of the inputs. Adding
	noise can help improve the computed gradients. Refer to this paper for more
	details: https://arxiv.org/pdf/1706.03825.pdf */
	// +optional
	SmoothGradConfig *ModelSmoothGradConfig `json:"smoothGradConfig,omitempty"`

	/* Required. The number of steps for approximating the path integral.
	A good value to start is 50 and gradually increase until the
	sum to diff property is met within the desired error range.

	Valid range of its value is [1, 100], inclusively. */
	// +optional
	StepCount *int32 `json:"stepCount,omitempty"`
}

type AIPlatformModelSpec struct {
	/* Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not required for AutoML Models. */
	// +optional
	ArtifactURI *string `json:"artifactURI,omitempty"`

	/* Optional. User input field to specify the base model source. Currently it only supports specifying the Model Garden models and Genie models. */
	// +optional
	BaseModelSource *ModelBaseModelSource `json:"baseModelSource,omitempty"`

	/* Input only. The specification of the container that is to be used when deploying this Model. The specification is ingested upon [ModelService.UploadModel][google.cloud.aiplatform.v1.ModelService.UploadModel], and all binaries it contains are copied and stored internally by Vertex AI. Not required for AutoML Models. */
	// +optional
	ContainerSpec *ModelContainerSpec `json:"containerSpec,omitempty"`

	/* Stats of data used for training or evaluating the Model.

	Only populated when the Model is trained by a TrainingPipeline with
	[data_input_config][google.cloud.aiplatform.v1.TrainingPipeline.input_data_config]. */
	// +optional
	DataStats *ModelDataStats `json:"dataStats,omitempty"`

	/* The description of the Model. */
	// +optional
	Description *string `json:"description,omitempty"`

	/* Required. The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters. */
	// +optional
	DisplayName *string `json:"displayName,omitempty"`

	/* Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key. */
	// +optional
	EncryptionSpec *ModelEncryptionSpec `json:"encryptionSpec,omitempty"`

	/* The default explanation specification for this Model.

	The Model can be used for
	[requesting
	explanation][google.cloud.aiplatform.v1.PredictionService.Explain] after
	being [deployed][google.cloud.aiplatform.v1.EndpointService.DeployModel] if
	it is populated. The Model can be used for [batch
	explanation][google.cloud.aiplatform.v1.BatchPredictionJob.generate_explanation]
	if it is populated.

	All fields of the explanation_spec can be overridden by
	[explanation_spec][google.cloud.aiplatform.v1.DeployedModel.explanation_spec]
	of
	[DeployModelRequest.deployed_model][google.cloud.aiplatform.v1.DeployModelRequest.deployed_model],
	or
	[explanation_spec][google.cloud.aiplatform.v1.BatchPredictionJob.explanation_spec]
	of [BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob].

	If the default explanation specification is not set for this Model, this
	Model can still be used for
	[requesting
	explanation][google.cloud.aiplatform.v1.PredictionService.Explain] by
	setting
	[explanation_spec][google.cloud.aiplatform.v1.DeployedModel.explanation_spec]
	of
	[DeployModelRequest.deployed_model][google.cloud.aiplatform.v1.DeployModelRequest.deployed_model]
	and for [batch
	explanation][google.cloud.aiplatform.v1.BatchPredictionJob.generate_explanation]
	by setting
	[explanation_spec][google.cloud.aiplatform.v1.BatchPredictionJob.explanation_spec]
	of [BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob]. */
	// +optional
	ExplanationSpec *ModelExplanationSpec `json:"explanationSpec,omitempty"`

	/* The labels with user-defined metadata to organize your Models.

	Label keys and values can be no longer than 64 characters
	(Unicode codepoints), can only contain lowercase letters, numeric
	characters, underscores and dashes. International characters are allowed.

	See https://goo.gl/xmQnxf for more information and examples of labels. */
	// +optional
	Labels map[string]string `json:"labels,omitempty"`

	/* Immutable. The location where the model should reside. */
	Location string `json:"location"`

	/* Immutable. An additional information about the Model; the schema of the metadata can be found in [metadata_schema][google.cloud.aiplatform.v1.Model.metadata_schema_uri]. Unset if the Model does not have any additional information. */
	// +optional
	Metadata *ModelMetadata `json:"metadata,omitempty"`

	/* Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access. */
	// +optional
	MetadataSchemaURI *string `json:"metadataSchemaURI,omitempty"`

	/* Optional. This field is populated if the model is produced by a pipeline job. */
	// +optional
	PipelineJob *string `json:"pipelineJob,omitempty"`

	/* The schemata that describe formats of the Model's predictions and explanations as given and returned via [PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict] and [PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain]. */
	// +optional
	PredictSchemata *ModelPredictSchemata `json:"predictSchemata,omitempty"`

	/* The project that this resource belongs to. */
	ProjectRef v1alpha1.ResourceRef `json:"projectRef"`

	/* The AIPlatformModel name. If not given, the metadata.name will be used. */
	// +optional
	ResourceID *string `json:"resourceID,omitempty"`

	/* User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model. */
	// +optional
	VersionAliases []string `json:"versionAliases,omitempty"`

	/* The description of this version. */
	// +optional
	VersionDescription *string `json:"versionDescription,omitempty"`
}

type ModelDeployedModelsStatus struct {
	/* Immutable. An ID of a DeployedModel in the above Endpoint. */
	// +optional
	DeployedModelID *string `json:"deployedModelID,omitempty"`

	/* Immutable. A resource name of an Endpoint. */
	// +optional
	Endpoint *string `json:"endpoint,omitempty"`
}

type ModelModelSourceInfoStatus struct {
	/* If this Model is copy of another Model. If true then [source_type][google.cloud.aiplatform.v1.ModelSourceInfo.source_type] pertains to the original. */
	// +optional
	Copy *bool `json:"copy,omitempty"`

	/* Type of the model source. */
	// +optional
	SourceType *string `json:"sourceType,omitempty"`
}

type ModelObservedStateStatus struct {
	/* Output only. Timestamp when this Model was uploaded into Vertex AI. */
	// +optional
	CreateTime *string `json:"createTime,omitempty"`

	/* Output only. The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations. */
	// +optional
	DeployedModels []ModelDeployedModelsStatus `json:"deployedModels,omitempty"`

	/* Output only. The resource name of the Artifact that was created in MetadataStore when creating the Model. The Artifact resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`. */
	// +optional
	MetadataArtifact *string `json:"metadataArtifact,omitempty"`

	/* Output only. Source of a model. It can either be automl training pipeline, custom training pipeline, BigQuery ML, or saved and tuned from Genie or Model Garden. */
	// +optional
	ModelSourceInfo *ModelModelSourceInfoStatus `json:"modelSourceInfo,omitempty"`

	/* Output only. If this Model is a copy of another Model, this contains info about the original. */
	// +optional
	OriginalModelInfo *ModelOriginalModelInfoStatus `json:"originalModelInfo,omitempty"`

	/* Output only. Reserved for future use. */
	// +optional
	SatisfiesPzi *bool `json:"satisfiesPzi,omitempty"`

	/* Output only. Reserved for future use. */
	// +optional
	SatisfiesPzs *bool `json:"satisfiesPzs,omitempty"`

	/* Output only. When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the [Endpoint.deployed_models][google.cloud.aiplatform.v1.Endpoint.deployed_models] object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an [Endpoint][google.cloud.aiplatform.v1.Endpoint] and does not support online predictions ([PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict] or [PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain]). Such a Model can serve predictions by using a [BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob], if it has at least one entry each in [supported_input_storage_formats][google.cloud.aiplatform.v1.Model.supported_input_storage_formats] and [supported_output_storage_formats][google.cloud.aiplatform.v1.Model.supported_output_storage_formats]. */
	// +optional
	SupportedDeploymentResourcesTypes []string `json:"supportedDeploymentResourcesTypes,omitempty"`

	/* Output only. The formats in which this Model may be exported. If empty, this Model is not available for export. */
	// +optional
	SupportedExportFormats []ModelSupportedExportFormatsStatus `json:"supportedExportFormats,omitempty"`

	/* Output only. The formats this Model supports in
	[BatchPredictionJob.input_config][google.cloud.aiplatform.v1.BatchPredictionJob.input_config].
	If
	[PredictSchemata.instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri]
	exists, the instances should be given as per that schema.

	The possible formats are:

	* `jsonl`
	The JSON Lines format, where each instance is a single line. Uses
	[GcsSource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.gcs_source].

	* `csv`
	The CSV format, where each instance is a single comma-separated line.
	The first line in the file is the header, containing comma-separated field
	names. Uses
	[GcsSource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.gcs_source].

	* `tf-record`
	The TFRecord format, where each instance is a single record in tfrecord
	syntax. Uses
	[GcsSource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.gcs_source].

	* `tf-record-gzip`
	Similar to `tf-record`, but the file is gzipped. Uses
	[GcsSource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.gcs_source].

	* `bigquery`
	Each instance is a single row in BigQuery. Uses
	[BigQuerySource][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig.bigquery_source].

	* `file-list`
	Each line of the file is the location of an instance to process, uses
	`gcs_source` field of the
	[InputConfig][google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig]
	object.

	If this Model doesn't support any of these formats it means it cannot be
	used with a
	[BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob].
	However, if it has
	[supported_deployment_resources_types][google.cloud.aiplatform.v1.Model.supported_deployment_resources_types],
	it could serve online predictions by using
	[PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict]
	or
	[PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain]. */
	// +optional
	SupportedInputStorageFormats []string `json:"supportedInputStorageFormats,omitempty"`

	/* Output only. The formats this Model supports in
	[BatchPredictionJob.output_config][google.cloud.aiplatform.v1.BatchPredictionJob.output_config].
	If both
	[PredictSchemata.instance_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.instance_schema_uri]
	and
	[PredictSchemata.prediction_schema_uri][google.cloud.aiplatform.v1.PredictSchemata.prediction_schema_uri]
	exist, the predictions are returned together with their instances. In other
	words, the prediction has the original instance data first, followed by the
	actual prediction content (as per the schema).

	The possible formats are:

	* `jsonl`
	The JSON Lines format, where each prediction is a single line. Uses
	[GcsDestination][google.cloud.aiplatform.v1.BatchPredictionJob.OutputConfig.gcs_destination].

	* `csv`
	The CSV format, where each prediction is a single comma-separated line.
	The first line in the file is the header, containing comma-separated field
	names. Uses
	[GcsDestination][google.cloud.aiplatform.v1.BatchPredictionJob.OutputConfig.gcs_destination].

	* `bigquery`
	Each prediction is a single row in a BigQuery table, uses
	[BigQueryDestination][google.cloud.aiplatform.v1.BatchPredictionJob.OutputConfig.bigquery_destination]
	.

	If this Model doesn't support any of these formats it means it cannot be
	used with a
	[BatchPredictionJob][google.cloud.aiplatform.v1.BatchPredictionJob].
	However, if it has
	[supported_deployment_resources_types][google.cloud.aiplatform.v1.Model.supported_deployment_resources_types],
	it could serve online predictions by using
	[PredictionService.Predict][google.cloud.aiplatform.v1.PredictionService.Predict]
	or
	[PredictionService.Explain][google.cloud.aiplatform.v1.PredictionService.Explain]. */
	// +optional
	SupportedOutputStorageFormats []string `json:"supportedOutputStorageFormats,omitempty"`

	/* Output only. The resource name of the TrainingPipeline that uploaded this Model, if any. */
	// +optional
	TrainingPipeline *string `json:"trainingPipeline,omitempty"`

	/* Output only. Timestamp when this Model was most recently updated. */
	// +optional
	UpdateTime *string `json:"updateTime,omitempty"`

	/* Output only. Timestamp when this version was created. */
	// +optional
	VersionCreateTime *string `json:"versionCreateTime,omitempty"`

	/* Output only. Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation. */
	// +optional
	VersionID *string `json:"versionID,omitempty"`

	/* Output only. Timestamp when this version was most recently updated. */
	// +optional
	VersionUpdateTime *string `json:"versionUpdateTime,omitempty"`
}

type ModelOriginalModelInfoStatus struct {
}

type ModelSupportedExportFormatsStatus struct {
}

type AIPlatformModelStatus struct {
	/* Conditions represent the latest available observations of the
	   AIPlatformModel's current state. */
	Conditions []v1alpha1.Condition `json:"conditions,omitempty"`
	/* A unique specifier for the AIPlatformModel resource in GCP. */
	// +optional
	ExternalRef *string `json:"externalRef,omitempty"`

	/* ObservedGeneration is the generation of the resource that was most recently observed by the Config Connector controller. If this is equal to metadata.generation, then that means that the current reported status reflects the most recent desired state of the resource. */
	// +optional
	ObservedGeneration *int64 `json:"observedGeneration,omitempty"`

	/* ObservedState is the state of the resource as most recently observed in GCP. */
	// +optional
	ObservedState *ModelObservedStateStatus `json:"observedState,omitempty"`
}

// +genclient
// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object
// +kubebuilder:resource:categories=gcp,shortName=gcpaiplatformmodel;gcpaiplatformmodels
// +kubebuilder:subresource:status
// +kubebuilder:metadata:labels="cnrm.cloud.google.com/managed-by-kcc=true"
// +kubebuilder:metadata:labels="cnrm.cloud.google.com/system=true"
// +kubebuilder:printcolumn:name="Age",JSONPath=".metadata.creationTimestamp",type="date"
// +kubebuilder:printcolumn:name="Ready",JSONPath=".status.conditions[?(@.type=='Ready')].status",type="string",description="When 'True', the most recent reconcile of the resource succeeded"
// +kubebuilder:printcolumn:name="Status",JSONPath=".status.conditions[?(@.type=='Ready')].reason",type="string",description="The reason for the value in 'Ready'"
// +kubebuilder:printcolumn:name="Status Age",JSONPath=".status.conditions[?(@.type=='Ready')].lastTransitionTime",type="date",description="The last transition time for the value in 'Status'"

// AIPlatformModel is the Schema for the aiplatform API
// +k8s:openapi-gen=true
type AIPlatformModel struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	Spec   AIPlatformModelSpec   `json:"spec,omitempty"`
	Status AIPlatformModelStatus `json:"status,omitempty"`
}

// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object

// AIPlatformModelList contains a list of AIPlatformModel
type AIPlatformModelList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []AIPlatformModel `json:"items"`
}

func init() {
	SchemeBuilder.Register(&AIPlatformModel{}, &AIPlatformModelList{})
}
