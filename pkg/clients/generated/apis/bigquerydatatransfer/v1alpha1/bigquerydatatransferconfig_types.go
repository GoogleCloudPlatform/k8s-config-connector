// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    AUTO GENERATED CODE     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Config Connector and manual
//     changes will be clobbered when the file is regenerated.
//
// ----------------------------------------------------------------------------

// *** DISCLAIMER ***
// Config Connector's go-client for CRDs is currently in ALPHA, which means
// that future versions of the go-client may include breaking changes.
// Please try it out and give us feedback!

package v1alpha1

import (
	"github.com/GoogleCloudPlatform/k8s-config-connector/pkg/clients/generated/apis/k8s/v1alpha1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

type ConfigEmailPreferences struct {
	/* If true, email notifications will be sent on transfer run failures. */
	EnableFailureEmail bool `json:"enableFailureEmail"`
}

type ConfigScheduleOptions struct {
	/* If true, automatic scheduling of data transfer runs for this
	configuration will be disabled. The runs can be started on ad-hoc
	basis using transferConfigs.startManualRuns API. When automatic
	scheduling is disabled, the TransferConfig.schedule field will
	be ignored. */
	// +optional
	DisableAutoScheduling *bool `json:"disableAutoScheduling,omitempty"`

	/* Defines time to stop scheduling transfer runs. A transfer run cannot be
	scheduled at or after the end time. The end time can be changed at any
	moment. The time when a data transfer can be triggered manually is not
	limited by this option. */
	// +optional
	EndTime *string `json:"endTime,omitempty"`

	/* Specifies time to start scheduling transfer runs. The first run will be
	scheduled at or after the start time according to a recurrence pattern
	defined in the schedule string. The start time can be changed at any
	moment. The time when a data transfer can be triggered manually is not
	limited by this option. */
	// +optional
	StartTime *string `json:"startTime,omitempty"`
}

type ConfigSecretAccessKey struct {
	/* Value of the field. Cannot be used if 'valueFrom' is specified. */
	// +optional
	Value *string `json:"value,omitempty"`

	/* Source for the field's value. Cannot be used if 'value' is specified. */
	// +optional
	ValueFrom *ConfigValueFrom `json:"valueFrom,omitempty"`
}

type ConfigSensitiveParams struct {
	/* The Secret Access Key of the AWS account transferring data from. */
	SecretAccessKey ConfigSecretAccessKey `json:"secretAccessKey"`
}

type ConfigValueFrom struct {
	/* Reference to a value with the given key in the given Secret in the resource's namespace. */
	// +optional
	SecretKeyRef *v1alpha1.SecretKeyRef `json:"secretKeyRef,omitempty"`
}

type BigQueryDataTransferConfigSpec struct {
	/* The number of days to look back to automatically refresh the data.
	For example, if dataRefreshWindowDays = 10, then every day BigQuery
	reingests data for [today-10, today-1], rather than ingesting data for
	just [today-1]. Only valid if the data source supports the feature.
	Set the value to 0 to use the default value. */
	// +optional
	DataRefreshWindowDays *int `json:"dataRefreshWindowDays,omitempty"`

	/* Immutable. The data source id. Cannot be changed once the transfer config is created. */
	DataSourceId string `json:"dataSourceId"`

	/* The BigQuery target dataset id. */
	// +optional
	DestinationDatasetId *string `json:"destinationDatasetId,omitempty"`

	/* When set to true, no runs are scheduled for a given transfer. */
	// +optional
	Disabled *bool `json:"disabled,omitempty"`

	/* The user specified display name for the transfer config. */
	DisplayName string `json:"displayName"`

	/* Email notifications will be sent according to these preferences to the
	email address of the user who owns this transfer config. */
	// +optional
	EmailPreferences *ConfigEmailPreferences `json:"emailPreferences,omitempty"`

	/* Immutable. The geographic location where the transfer config should reside.
	Examples: US, EU, asia-northeast1. The default value is US. */
	// +optional
	Location *string `json:"location,omitempty"`

	/* Pub/Sub topic where notifications will be sent after transfer runs
	associated with this transfer config finish. */
	// +optional
	NotificationPubsubTopic *string `json:"notificationPubsubTopic,omitempty"`

	Params map[string]string `json:"params"`

	/* The project that this resource belongs to. */
	ProjectRef v1alpha1.ResourceRef `json:"projectRef"`

	/* Immutable. Optional. The service-generated name of the resource. Used for acquisition only. Leave unset to create a new resource. */
	// +optional
	ResourceID *string `json:"resourceID,omitempty"`

	/* Data transfer schedule. If the data source does not support a custom
	schedule, this should be empty. If it is empty, the default value for
	the data source will be used. The specified times are in UTC. Examples
	of valid format: 1st,3rd monday of month 15:30, every wed,fri of jan,
	jun 13:15, and first sunday of quarter 00:00. See more explanation
	about the format here:
	https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format
	NOTE: the granularity should be at least 8 hours, or less frequent. */
	// +optional
	Schedule *string `json:"schedule,omitempty"`

	/* Options customizing the data transfer schedule. */
	// +optional
	ScheduleOptions *ConfigScheduleOptions `json:"scheduleOptions,omitempty"`

	/* Different parameters are configured primarily using the the 'params' field on this
	resource. This block contains the parameters which contain secrets or passwords so that they can be marked
	sensitive and hidden from plan output. The name of the field, eg: secret_access_key, will be the key
	in the 'params' map in the api request.

	Credentials may not be specified in both locations and will cause an error. Changing from one location
	to a different credential configuration in the config will require an apply to update state. */
	// +optional
	SensitiveParams *ConfigSensitiveParams `json:"sensitiveParams,omitempty"`

	/* Service account email. If this field is set, transfer config will
	be created with this service account credentials. It requires that
	requesting user calling this API has permissions to act as this service account. */
	// +optional
	ServiceAccountName *string `json:"serviceAccountName,omitempty"`
}

type BigQueryDataTransferConfigStatus struct {
	/* Conditions represent the latest available observations of the
	   BigQueryDataTransferConfig's current state. */
	Conditions []v1alpha1.Condition `json:"conditions,omitempty"`
	/* The resource name of the transfer config. Transfer config names have the
	form projects/{projectId}/locations/{location}/transferConfigs/{configId}
	or projects/{projectId}/transferConfigs/{configId},
	where configId is usually a uuid, but this is not required.
	The name is ignored when creating a transfer config. */
	// +optional
	Name *string `json:"name,omitempty"`

	/* ObservedGeneration is the generation of the resource that was most recently observed by the Config Connector controller. If this is equal to metadata.generation, then that means that the current reported status reflects the most recent desired state of the resource. */
	// +optional
	ObservedGeneration *int `json:"observedGeneration,omitempty"`
}

// +genclient
// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object

// BigQueryDataTransferConfig is the Schema for the bigquerydatatransfer API
// +k8s:openapi-gen=true
type BigQueryDataTransferConfig struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`

	Spec   BigQueryDataTransferConfigSpec   `json:"spec,omitempty"`
	Status BigQueryDataTransferConfigStatus `json:"status,omitempty"`
}

// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object

// BigQueryDataTransferConfigList contains a list of BigQueryDataTransferConfig
type BigQueryDataTransferConfigList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []BigQueryDataTransferConfig `json:"items"`
}

func init() {
	SchemeBuilder.Register(&BigQueryDataTransferConfig{}, &BigQueryDataTransferConfigList{})
}
